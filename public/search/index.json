[{"content":"","date":"2023-03-27T00:00:00Z","permalink":"/p/rshiny/","title":"å¼€å‘æˆ‘çš„Rshinyåº”ç”¨"},{"content":"Introduction å®åŸºå› ç»„ï¼ˆMetagenomeï¼‰æ˜¯æŒ‡å¯¹ä¸€ä¸ªç”Ÿæ€ç³»ç»Ÿä¸­çš„æ‰€æœ‰å¾®ç”Ÿç‰©è¿›è¡ŒDNAåˆ†æçš„è¿‡ç¨‹ï¼Œå¯ä»¥å¸®åŠ©ç ”ç©¶äººå‘˜äº†è§£å¾®ç”Ÿç‰©çš„å¤šæ ·æ€§ã€åŠŸèƒ½å’Œäº’ä½œå…³ç³»ã€‚\nå®åŸºå› ç»„çš„åº”ç”¨éå¸¸å¹¿æ³›ï¼ŒåŒ…æ‹¬ï¼š\nç”Ÿç‰©å¤šæ ·æ€§ç ”ç©¶ï¼šé€šè¿‡å¯¹å®åŸºå› ç»„è¿›è¡Œåˆ†æï¼Œå¯ä»¥äº†è§£ä¸åŒç”Ÿæ€ç³»ç»Ÿä¸­å¾®ç”Ÿç‰©çš„å¤šæ ·æ€§å’Œåˆ†å¸ƒæƒ…å†µã€‚\nç”Ÿæ€å­¦ç ”ç©¶ï¼šå®åŸºå› ç»„å¯ä»¥å¸®åŠ©ç ”ç©¶äººå‘˜äº†è§£å¾®ç”Ÿç‰©åœ¨ç”Ÿæ€ç³»ç»Ÿä¸­çš„åŠŸèƒ½ã€äº’ä½œå…³ç³»å’Œç”Ÿæ€ä½ç­‰ã€‚\nç”Ÿç‰©æŠ€æœ¯ï¼šå®åŸºå› ç»„å¯ä»¥ç”¨äºç­›é€‰å…·æœ‰ç‰¹å®šåŠŸèƒ½çš„å¾®ç”Ÿç‰©ï¼Œä¾‹å¦‚ï¼Œå¯»æ‰¾èƒ½å¤Ÿé™è§£æœ‰å®³ç‰©è´¨çš„å¾®ç”Ÿç‰©ã€‚\nå®åŸºå› ç»„çš„åˆ†æä¸€èˆ¬åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤ï¼š\nDNAæå–ä¸å»ºåº“ã€‚\né«˜é€šé‡æµ‹åºï¼šä½¿ç”¨é«˜é€šé‡æµ‹åºæŠ€æœ¯å¯¹æ‰©å¢åçš„DNAè¿›è¡Œæµ‹åºï¼Œå¾—åˆ°åŸå§‹åºåˆ—æ•°æ®ã€‚\næ•°æ®æ¸…æ´—å’Œç»„è£…ï¼šå¯¹åŸå§‹æ•°æ®è¿›è¡Œè´¨é‡æ§åˆ¶ã€å»é™¤ä½è´¨é‡åºåˆ—å’Œå†—ä½™åºåˆ—ï¼Œå°†åºåˆ—æ‹¼æ¥æˆè¾ƒé•¿çš„è¿ç»­åºåˆ—ï¼ˆcontigsï¼‰ã€‚\nåŸºå› æ³¨é‡Šï¼šå°†contigsä¸­çš„åŸºå› è¿›è¡Œæ³¨é‡Šï¼Œå¾—åˆ°åŸºå› åŠŸèƒ½ä¿¡æ¯ã€‚\næ•°æ®åˆ†æï¼šäº†è§£å¾®ç”Ÿç‰©å¤šæ ·æ€§ã€ç¾¤è½ç»“æ„ã€åŠŸèƒ½ç‰¹å¾ç­‰ä¿¡æ¯ï¼ˆæ›´å¤šæ˜¯æŒ‡è·å–äº†ç‰©ç§ä¸°åº¦è¡¨æˆ–åŠŸèƒ½ä¸°åº¦è¡¨ä¹‹åçš„è¿›ä¸€æ­¥åˆ†æï¼‰ã€‚\nMAGs binningï¼Œ è¿›åŒ–åŠ¨æ€ç­‰è¿›ä¸€æ­¥åˆ†æ\nè¿™æ˜¯æˆ‘å¸¸ç”¨çš„ä¸€å¥—åŸºæœ¬æµç¨‹(Figure 1)ï¼Œå½“ç„¶åœ¨é¢å¯¹ä¸åŒé¡¹ç›®æ—¶åº”è¯¥æœ‰ä¸åŒçš„ä¾§é‡ç‚¹å’Œé€‚ç”¨çš„åˆ†ææ–¹æ³•ï¼Œå¯ä»¥åœ¨æ­¤åŸºç¡€ä¸Šæ·»åŠ æˆ–ä¿®æ”¹ã€‚\næœ€æ—©è¿™æ–¹é¢çš„åˆ†ææˆ‘éƒ½æ˜¯å‚è€ƒåˆ˜æ°¸é‘«è€å¸ˆçš„EasyMetagenome,ç°åœ¨è¿™å¥—æµç¨‹ä¹Ÿå‘æ–‡ç« äº† (1)ï¼Œå€¼å¾—å‚è€ƒï¼Œå¯¹ä¸Šæ‰‹16Sæµ‹åºæ•°æ®æˆ–å®åŸºå› ç»„æ•°æ®éƒ½å¾ˆæœ‰å¸®åŠ©ã€‚\nFigure 1: Basic workflow preprocess ç»å¤§å¤šæ•°è¿™é‡Œä»‹ç»çš„è½¯ä»¶éƒ½æ˜¯ä»…æ”¯æŒlinuxå¹³å°çš„ï¼Œæˆ‘ä»¬åšæµ‹åºæ–‡ä»¶çš„ä¸Šæ¸¸åˆ†æä¹Ÿè‚¯å®šæ˜¯åœ¨æœåŠ¡å™¨ä¸Šåšï¼Œä¸ªäººPCä¸€èˆ¬å¾ˆéš¾æ»¡è¶³éœ€æ±‚ï¼Œæ‰€ä»¥åœ¨åšè¿™äº›åˆ†æå‰å¿…é¡»å…ˆå­¦ä¹ linuxåŸºç¡€çŸ¥è¯†å¦‚æ–‡ä»¶ç³»ç»Ÿï¼Œshellè„šæœ¬ç¼–å†™ï¼Œè½¯ä»¶å®‰è£…ç­‰ã€‚\nå®‰è£…è½¯ä»¶å»ºè®®ä½¿ç”¨condaæˆ–mambaï¼ˆæ–°å»ºç¯å¢ƒå’Œç®¡ç†ï¼‰ï¼Œæœ‰å¾ˆå¤šå‚è€ƒæ–¹æ³•ã€‚\næˆ‘ä»¬æœåŠ¡å™¨ä½¿ç”¨çš„æ˜¯slurmä½œä¸šç®¡ç†ç³»ç»Ÿï¼Œå°½é‡å…ˆå­¦ä¹ ä¸€ä¸‹slurmçš„ä½¿ç”¨å†å°è¯•æäº¤ä½œä¸šã€‚\nä¸€èˆ¬æŠŠæ‰€æœ‰æ ·æœ¬çš„æµ‹åºåŒç«¯æ–‡ä»¶æ”¾åœ¨ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸‹\nè´¨æ§ï¼šfastp 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #!/bin/bash #SBATCH --job-name=fastp #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/fastp/log/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/fastp/log/%x_%a.err #SBATCH --array=1-33 #SBATCH --partition=short #SBATCH --cpus-per-task=8 echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` echo \u0026#34;SLURM_ARRAY_TASK_ID: \u0026#34; $SLURM_ARRAY_TASK_ID sample=$(head -n $SLURM_ARRAY_TASK_ID ~/work/asthma/data/namelist | tail -1) #sample=$(head -n 1 namelist | tail -1) echo handling: $sample #################### fastp -w 8 -i ~/work/asthma/data/$sample/$sample\u0026#39;_f1.fastq\u0026#39; -o ${i}_1 \\ -I ~/work/asthma/data/$sample/$sample\u0026#39;_r2.fastq\u0026#39; -O ${i}_2 -j ~/work/asthma/fastp/${i}.json #delete outputfile rm -rf ${i}_1 ${i}_2 #################### echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s åé¢æ¥ä¸€ä¸ªpythonè„šæœ¬å°±å¯ä»¥ç»Ÿè®¡å¸¸ç”¨æŒ‡æ ‡äº†ã€‚\næŠŠæ‰€æœ‰çš„.jsonæ–‡ä»¶ç§»åˆ°ä¸€ä¸ªæ–‡ä»¶å¤¹é‡Œï¼Œreport/ä¸‹ï¼Œå°±å¯ä»¥ç»Ÿè®¡äº†ã€‚\nå»å®¿ä¸»ï¼šbowtie2 å…¶å®å°±æ˜¯å°†åºåˆ—æ¯”å¯¹åˆ°äººç±»åŸºå› ç»„ä¸Šï¼Œæ²¡æœ‰æ¯”å¯¹åˆ°çš„åºåˆ—æ•´åˆæˆæ–°æ–‡ä»¶å°±æ˜¯å»å®¿ä¸»åçš„äº†ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #!/bin/bash #SBATCH --job-name=rm_human #SBATCH --output=/share/home/jianglab/pengchen/work/meta/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/meta/%x_%a.err #SBATCH --cpus-per-task=32 #SBATCH --partition=short echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` ############# for i in C1 C2 do bowtie2 -p 32 -x ~/db/humangenome/hg38 -1 seq/${i}_1.fq.gz \\ -2 seq/${i}_2.fq.gz -S ${i}.sam --un-conc ${i}.fq --very-sensitive done ############## echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s åŸºæœ¬ä¿¡æ¯ç»Ÿè®¡ å¯ä»¥ç”¨FastqCountï¼š\n1 2 3 4 ~/biosoft/FastqCount-master/FastqCount_v0.5 xx.fastq.gz Total Reads Total Bases N Bases Q20 Q30 GC 11568822 (11.57 M) 1702829127 (1.70 G) 0.00% 98.00% 94.00% 54.00% reads-based ç‰©ç§æ³¨é‡Šï¼škraken2 Kraken 2æ˜¯ä¸€ä¸ªç”¨äºå¯¹é«˜é€šé‡æµ‹åºæ•°æ®è¿›è¡Œåˆ†ç±»å’Œæ ‡è¯†ç‰©ç§çš„è½¯ä»¶ã€‚å®ƒä½¿ç”¨å‚è€ƒæ•°æ®åº“ä¸­çš„åŸºå› ç»„åºåˆ—æ¥è¿›è¡Œåˆ†ç±»ï¼Œå¹¶ä½¿ç”¨k-meræ–¹æ³•æ¥å®ç°å¿«é€Ÿå’Œå‡†ç¡®çš„åˆ†ç±»ã€‚\nä½¿ç”¨Kraken 2è¿›è¡ŒåŸºæœ¬åˆ†ç±»çš„ç®€å•æ­¥éª¤ï¼š\nå‡†å¤‡å‚è€ƒæ•°æ®åº“ï¼šKraken 2éœ€è¦ä¸€ä¸ªå‚è€ƒæ•°æ®åº“ï¼Œä»¥ä¾¿å¯¹æµ‹åºæ•°æ®è¿›è¡Œåˆ†ç±»ã€‚å¯ä»¥ä»NCBIã€Ensemblæˆ–å…¶ä»–æ•°æ®åº“ä¸‹è½½ç›¸åº”çš„åŸºå› ç»„åºåˆ—ï¼Œå¹¶ä½¿ç”¨Kraken 2å†…ç½®çš„å·¥å…·æ¥æ„å»ºæ•°æ®åº“ã€‚\nå®‰è£…Kraken 2ï¼šå¯ä»¥ä»Kraken 2å®˜æ–¹ç½‘ç«™ä¸‹è½½å¹¶å®‰è£…Kraken 2è½¯ä»¶ã€‚\nè¿è¡ŒKraken 2ï¼šä½¿ç”¨Kraken 2å¯¹æµ‹åºæ•°æ®è¿›è¡Œåˆ†ç±»éœ€è¦ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š\nkraken2 \\--db \\\u0026lt;path_to_database\\\u0026gt; \\\u0026lt;input_file\\\u0026gt; \\--output \\\u0026lt;output_file\\\u0026gt;\nè¿™é‡Œï¼Œ**\u0026lt;path_to_database\u0026gt;æ˜¯å‚è€ƒæ•°æ®åº“çš„è·¯å¾„ï¼Œ\u0026lt;input_file\u0026gt;æ˜¯éœ€è¦è¿›è¡Œåˆ†ç±»çš„è¾“å…¥æ–‡ä»¶ï¼Œ\u0026lt;output_file\u0026gt;**æ˜¯è¾“å‡ºæ–‡ä»¶çš„åç§°ã€‚Kraken 2å°†è¾“å‡ºä¸€ä¸ªåˆ†ç±»æŠ¥å‘Šæ–‡ä»¶å’Œä¸€ä¸ªåºåˆ—æ–‡ä»¶ã€‚\nkraken2-build --standard --threads 24 --db ./\n\u0026ndash;standardæ ‡å‡†æ¨¡å¼ä¸‹åªä¸‹è½½5ç§æ•°æ®åº“ï¼šå¤èŒarchaeaã€ç»†èŒbacteriaã€äººç±»humanã€è½½ä½“UniVec_Coreã€ç—…æ¯’viralã€‚ä¹Ÿå¯é€‰ç›´æ¥ä¸‹è½½ä½œè€…æ„å»ºçš„ç´¢å¼•ï¼Œè¿˜åŒ…æ‹¬brackençš„ç´¢å¼•ã€‚\nè¿™ä¸ªkrakenæ•°æ®åº“æ˜¯å¯ä»¥è‡ªå·±æ„å»ºçš„ï¼Œæ‰€ä»¥é€‚ç”¨äºå„ç§é¡¹ç›®çš„ç‰©ç§æ³¨é‡Šï¼Œæˆ‘åšçš„æ¯”è¾ƒå¤šçš„æ˜¯ç¯å¢ƒæ ·æœ¬çš„å®åŸºå› ç»„ï¼Œå°±å¯èƒ½éœ€è¦æ›´å…¨é¢çš„ç‰©ç§æ•°æ®åº“ï¼ˆç”šè‡³é™¤äº†å„ç§å¾®ç”Ÿç‰©ï¼Œè¿˜è¦åŠ¨æ¤ç‰©æ•°æ®ç­‰ï¼‰ï¼Œå®éªŒå®¤çš„WXå¸ˆå§æ”¶é›†æ„å»ºäº†ä¸€ä¸ªè¶…å¤§çš„ç‰©ç§åº“ã€‚\néœ€è¦æ³¨æ„çš„æ˜¯krakenè¿è¡Œè‡³å°‘è¦æä¾›æ•°æ®åº“å¤§å°çš„å†…å­˜å¤§å°ï¼ˆè¿è¡Œå†…å­˜ï¼‰ï¼Œå› ä¸ºå®ƒä¼šæŠŠæ•´ä¸ªæ•°æ®åº“è½½å…¥å†…å­˜åè¿›è¡Œåºåˆ—çš„æ³¨é‡Šï¼Œæ‰€ä»¥å¦‚æœå‘ç°æ— æ³•è½½å…¥æ•°æ®åº“çš„æŠ¥é”™ï¼Œå¯ä»¥å°è¯•è°ƒå¤§å†…å­˜èµ„æºã€‚\nkrakenè½¯ä»¶è¿è¡Œæ—¶è½½å…¥æ•°æ®åº“æ˜¯ä¸€ä¸ªååˆ†è€—æ—¶çš„æ­¥éª¤ï¼Œè€Œæ¯æ¡åºåˆ—çš„é‰´å®šæ—¶é—´å·®ä¸å¤šï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥å°†å¾ˆå¤šæ ·æœ¬çš„fastqæ–‡ä»¶åˆå¹¶æˆä¸€ä¸ªå¤§æ–‡ä»¶åè¾“å…¥krakenæ³¨é‡Šï¼Œä¹‹åå†æŒ‰ç…§åºåˆ—çš„æ•°é‡æ‹†åˆ†ç»“æœæ–‡ä»¶ï¼Œè¿™æ ·å¤šä¸ªæ ·æœ¬ä¹Ÿåªéœ€è¦è½½å…¥ä¸€æ¬¡æ•°æ®åº“ï¼ŒèŠ‚çœæ—¶é—´ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #!/bin/bash #SBATCH --job-name=kraken2M #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/kraken/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/kraken/%x_%a.err #SBATCH --time=14-00:00:00 #SBATCH --partition=mem #SBATCH --cpus-per-task=32 #SBATCH --mem-per-cpu=100G fqp=~/work/asthma/data/CRR205159/ python /share/home/jianglab/shared/krakenDB/K2ols/kraken2M.py -t 32 \\ -i ${fqp} \\ -c 0.05 \\ -s _f1.fastq,_r2.fastq \\ -o ~/work/asthma/kraken/ \\ -d /share/home/jianglab/shared/krakenDB/mydb2 \\ -k ~/miniconda3/envs/waste/bin/kraken2 \\ -kt /share/home/jianglab/shared/krakenDB/K2ols/KrakenTools è¾“å‡ºæ–‡ä»¶æ ¼å¼ Krakenæ ‡å‡†è¾“å‡ºæ ¼å¼\näº”åˆ—è¡¨ output\nC/Uä»£è¡¨åˆ†ç±»classifiedæˆ–éåˆ†ç±»unclassifed\nåºåˆ—ID\nç‰©ç§æ³¨é‡Š\næ¯”åºåˆ—æ³¨é‡Šçš„åŒºåŸŸï¼Œå¦‚98|94ä»£è¡¨å·¦ç«¯98bpï¼Œå³ç«¯94bpæ¯”å¯¹è‡³æ•°æ®åº“\nLCAæ¯”å¯¹ç»“æœï¼Œå¦‚â€562:13 561:4â€ä»£è¡¨13 k-meræ¯”å¯¹è‡³ç‰©ç§#562ï¼Œ4 k-meræ¯”å¯¹è‡³#561ç‰©ç§\næŠ¥å‘Šè¾“å‡ºæ ¼å¼ report\nåŒ…æ‹¬6åˆ—ï¼Œæ–¹ä¾¿æ•´ç†ä¸‹æ¸¸åˆ†æã€‚\nç™¾åˆ†æ¯”\ncount\ncountæœ€ä¼˜\n(U)nclassified, (R)oot, (D)omain, (K)ingdom, (P)hylum, (C)lass, (O)rder, (F)amily, (G)enus, or (S)pecies. â€œG2â€ä»£è¡¨ä½äºå±ä¸€ç§é—´\nNCBIç‰©ç§ID\nç§‘å­¦ç‰©ç§å\nå¸¸ç”¨çš„ç‰©ç§ä¸°åº¦è¡¨æ ¼å¼é™¤äº†kraken reportï¼Œè¿˜æœ‰mpaï¼Œspfï¼Œkronaç­‰æ ¼å¼ï¼Œå…³äºkrakenç»“æœçš„æ•´ç†ä»¥åŠæ ¼å¼è½¬æ¢æ–¹å¼ï¼Œæœ‰ä¸€äº›ç°æˆçš„è„šæœ¬æˆ–è€…è‡ªå·±å†™ã€‚\nKrakenTools (jhu.edu) å°±æ˜¯ä¸€å¥—å¾ˆå¥½ç”¨çš„krakenå·¥å…·åŒ…ï¼Œå…¶ä¸­å¸¸ç”¨çš„æœ‰ï¼š\nextract_kraken_reads.py æ­¤ç¨‹åºæå–è¯»å–åœ¨ä»»ä½•ç”¨æˆ·æŒ‡å®šçš„åˆ†ç±»idå¤„åˆ†ç±»çš„å†…å®¹ã€‚ç”¨æˆ·å¿…é¡»æŒ‡å®šKrakenè¾“å‡ºæ–‡ä»¶ã€åºåˆ—æ–‡ä»¶å’Œè‡³å°‘ä¸€ä¸ªåˆ†ç±»æ³•IDã€‚ä¸‹é¢æŒ‡å®šäº†å…¶ä»–é€‰é¡¹ã€‚æˆªè‡³2021å¹´4æœˆ19æ—¥ï¼Œæ­¤è„šæœ¬ä¸KrakenUniq/Kraken2UniqæŠ¥å‘Šå…¼å®¹ã€‚\ncombine_kreports.py This script combines multiple Kraken reports into a combined report file.\npython combine_kreports.py\n-r 1.KREPORT 2.KREPORT\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;Kraken-style reports to combine\n-o COMBINED.KREPORT\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;Output file\nkreport2krona.py This program takes a Kraken report file and prints out a krona-compatible TEXT file\næ¢æˆkronaæ–‡ä»¶å¥½ç”»å›¾ã€‚å˜¿å˜¿\nkronaè£…äº†ä¸€ä¸ªexcelçš„æ’ä»¶å¯ä»¥å¾ˆå®¹æ˜“ç”»å›¾\npython kreport2krona.py\n-r/\u0026ndash;report MYFILE.KREPORT\u0026hellip;.â€¦.Kraken report file\n-o/\u0026ndash;output MYFILE.KRONA\u0026hellip;\u0026hellip;.â€¦Output Krona text file\nthen, ktImportText MYSAMPLE.krona -o MYSAMPLE.krona.html\nå¥½çœ‹çš„ç½‘é¡µå°±å‡ºæ¥äº†ã€‚\nkreport2mpa.py This program takes a Kraken report file and prints out a mpa (MetaPhlAn) -style TEXT file\npython kreport2mpa.py\n-r/\u0026ndash;report MYFILE.KREPORT\u0026hellip;.â€¦.Kraken report file\n-o/\u0026ndash;output MYFILE.MPA.TXT\u0026hellip;.â€¦.Output MPA-STYLE text file\ncombine_mpa.py python combine_mpa.py\n-i/\u0026ndash;input MYFILE1.MPA MYFILE2.MPA\u0026hellip;.â€¦Multiple MPA-STYLE text files (separated by spaces)\n-o/\u0026ndash;output MYFILE.COMBINED.MPA\u0026hellip;\u0026hellip;.â€¦Output MPA-STYLE text file\nThis program combines multiple outputs from kreport2mpa.py. Files to be combined must have been generated using the same kreport2mpa.py options.\npython combine_mpa.py -i -o --intermediate-ranks\nHUMAnN HUMAnN2ï¼ˆThe HMP Unified Metabolic Analysis Network 2ï¼‰æ˜¯ä¸€æ¬¾ç”¨äºåˆ†æäººç±»å¾®ç”Ÿç‰©ç»„çš„åŠŸèƒ½å’Œä»£è°¢èƒ½åŠ›çš„å·¥å…·ã€‚å®ƒé€šè¿‡å°†å®åŸºå› ç»„åºåˆ—ä¸å‚è€ƒåŸºå› ç»„æ•°æ®åº“æ¯”å¯¹ï¼Œåˆ©ç”¨MetaCycä»£è°¢é€šè·¯æ•°æ®åº“å’ŒUniRefè›‹ç™½è´¨åºåˆ—æ•°æ®åº“ï¼Œåˆ†æå¾®ç”Ÿç‰©ç»„åœ¨åŠŸèƒ½å’Œä»£è°¢é€šè·¯æ°´å¹³ä¸Šçš„ç»„æˆå’Œæ´»æ€§ã€‚HUMAnN2è¿˜æä¾›äº†å¤šæ ·æ€§åˆ†æã€å…³è”åˆ†æå’Œå¯è§†åŒ–å·¥å…·ï¼Œå¯ç”¨äºæ·±å…¥ç ”ç©¶äººç±»å¾®ç”Ÿç‰©ç»„å¯¹å®¿ä¸»å¥åº·çš„å½±å“å’Œæ²»ç–—ç­–ç•¥çš„åˆ¶å®šç­‰æ–¹é¢ã€‚\nHUMAnN2æ˜¯ç”±ç¾å›½å›½å®¶äººç±»å¾®ç”Ÿç‰©ç»„è®¡åˆ’ï¼ˆHMPï¼‰å¼€å‘çš„ï¼Œç›®å‰æœ€æ–°ç‰ˆæœ¬ä¸ºHUMAnN3ï¼Œäº2020å¹´å‘å¸ƒã€‚ä¸HUMAnN2ç›¸æ¯”ï¼ŒHUMAnN3æ”¹è¿›äº†åŸºå› å®¶æ—æ³¨é‡Šçš„æ–¹æ³•ï¼Œæé«˜äº†æ³¨é‡Šç²¾åº¦å’Œé€Ÿåº¦ï¼Œå¹¶æä¾›äº†æ–°çš„åŠŸèƒ½å’Œå·¥å…·ï¼Œå¦‚åŠŸèƒ½éŸ§åº¦åˆ†æã€ä»£è°¢æŒ‡çº¹è¯†åˆ«å’Œå¤šæ ·æ€§åˆ†æç­‰ã€‚\nä½†æ˜¯HUMAnN2çš„æ•°æ®åº“åŸºæœ¬éƒ½æ˜¯ä¸äººç›¸å…³çš„å¾®ç”Ÿç‰©ï¼Œæ¯”è¾ƒé€‚åˆåšå„ç§äººä½“å¾®ç”Ÿç‰©ç»„ï¼ˆè‚ é“ï¼Œè‚ºéƒ¨ï¼Œå£è…”ï¼Œçš®è‚¤ç­‰ç­‰ï¼‰ï¼Œå¯¹äºç¯å¢ƒæ ·æœ¬å¯èƒ½unclassifiedæ¯”è¾ƒå¤šã€‚\nHUMAnN2è¦æ±‚åŒç«¯åºåˆ—åˆå¹¶çš„æ–‡ä»¶ä½œä¸ºè¾“å…¥ï¼Œforå¾ªç¯æ ¹æ®å®éªŒè®¾è®¡æ ·æœ¬åæ‰¹é‡åŒç«¯åºåˆ—åˆå¹¶ã€‚\nç‰©ç§ç»„æˆè°ƒç”¨MetaPhlAn2, bowtie2æ¯”å¯¹è‡³æ ¸é…¸åºåˆ—ï¼Œè§£å†³æœ‰å“ªäº›å¾®ç”Ÿç‰©å­˜åœ¨çš„é—®é¢˜ï¼›\nåŠŸèƒ½ç»„æˆä¸ºhumann2è°ƒç”¨diamondæ¯”å¯¹è‡³è›‹ç™½åº“11Gbï¼Œè§£å†³è¿™äº›å¾®ç”Ÿç‰©å‚ä¸å“ªäº›åŠŸèƒ½é€šè·¯çš„é—®é¢˜ï¼›\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 cd alldata for i in `cat ~/work/asthma/data/namelist` do echo $i cat ${i}_f1.fastq ${i}_r2.fastq \u0026gt;${i}_paired.fastq done #!/bin/bash #SBATCH --job-name=humann2 #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/humann/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/humann/%x_%a.err #SBATCH --array=1-32 #SBATCH --cpus-per-task=24 #SBATCH --partition=cpu echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` ############## myarray=(`cat ~/work/asthma/data/namelist`) echo $SLURM_ARRAY_TASK_ID #this is your single file name sample=${myarray[${SLURM_ARRAY_TASK_ID}]} echo handling: $sample humann2 --input data/alldata/${sample}_paired.fastq \\ --output temp/humann2/ --threads 24 ## é“¾æ¥é‡è¦æ–‡ä»¶è‡³humann2ç›®å½• ln temp/humann2/${sample}_paired_humann2_temp/${sample}_paired_metaphlan_bugs_list.tsv temp/humann2/ ## åˆ é™¤ä¸´æ—¶æ–‡ä»¶ rm -rf temp/humann2/${sample}_paired_humann2_temp ############## echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s ## åˆå¹¶ã€ä¿®æ­£æ ·æœ¬åã€é¢„è§ˆ merge_metaphlan_tables2.py \\ temp/humann2/*_metaphlan_bugs_list.tsv | \\ sed \u0026#39;s/_metaphlan_bugs_list//g\u0026#39; \\ \u0026gt; metaphlan2/taxonomy.tsv contigs-based ç»„è£…ï¼šmegahit MegaHitæ˜¯ä¸€ä¸ªç”¨äºå¯¹é«˜é€šé‡æµ‹åºæ•°æ®è¿›è¡Œde novoç»„è£…çš„è½¯ä»¶ã€‚å®ƒä½¿ç”¨äº†ä¸€ç§åŸºäºçŸ­è¯»æ¯”å¯¹å’Œå›¾å½¢æ„å»ºçš„ç®—æ³•æ¥ç»„è£…åŸºå› ç»„ï¼Œå¯ä»¥é«˜æ•ˆåœ°å¤„ç†å¤§è§„æ¨¡çš„æ•°æ®é›†ã€‚ä»¥ä¸‹æ˜¯MegaHitçš„ä¸€äº›ä¼˜ç‚¹å’Œé€‚ç”¨æƒ…å†µï¼š\né€Ÿåº¦å¿«ï¼šMegaHitçš„ç®—æ³•éå¸¸é«˜æ•ˆï¼Œå¯ä»¥å¤„ç†å¤§è§„æ¨¡çš„æ•°æ®é›†ï¼Œé€šå¸¸æ¯”å…¶ä»–de novoç»„è£…å·¥å…·æ›´å¿«ã€‚\né«˜è´¨é‡çš„ç»„è£…ï¼šMegaHitåœ¨ç»„è£…ç»“æœçš„è¿é€šæ€§å’Œå‡†ç¡®æ€§æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨å¤„ç†é«˜GCå«é‡åŸºå› ç»„æ—¶æ•ˆæœæ˜¾è‘—ã€‚\né€‚ç”¨äºä¸åŒç±»å‹çš„æµ‹åºæ•°æ®ï¼šMegaHitæ”¯æŒå¤šç§ä¸åŒç±»å‹çš„æµ‹åºæ•°æ®ï¼ŒåŒ…æ‹¬ Illumina HiSeq/MiSeqã€IonTorrentå’ŒPacBioç­‰å¹³å°ã€‚\næ˜“äºä½¿ç”¨ï¼šMegaHitå…·æœ‰ç®€å•çš„å‘½ä»¤è¡Œè¯­æ³•ï¼Œæ–¹ä¾¿ç”¨æˆ·è¿›è¡Œç»„è£…æ“ä½œï¼Œä¸”å…·æœ‰ä¸­æ–­ç‚¹ï¼Œé¿å…å¤±è´¥åå…¨éƒ¨é‡è·‘ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #!/bin/bash #SBATCH --job-name=asthma_megahit #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/megahit/log/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/megahit/log/%x_%a.err #SBATCH --array=1-33 #SBATCH --partition=cpu #SBATCH --cpus-per-task=32 echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` echo \u0026#34;SLURM_ARRAY_TASK_ID: \u0026#34; $SLURM_ARRAY_TASK_ID sample=$(head -n $SLURM_ARRAY_TASK_ID ~/work/asthma/data/namelist | tail -1) #sample=$(head -n 1 namelist | tail -1) echo handling: $sample\t#################### megahit -t 32 -1 ~/work/asthma/data/$sample/$sample\u0026#39;_f1.fastq\u0026#39; \\ -2 ~/work/asthma/data/$sample/$sample\u0026#39;_r2.fastq\u0026#39; -o ~/work/asthma/megahit/$sample --out-prefix $sample #################### echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s ç»„è£…è¯„ä¼°ï¼šQUAST QUASTä»£è¡¨è´¨é‡è¯„ä¼°å·¥å…·ã€‚ QUASTå¯ä»¥ä½¿ç”¨å‚è€ƒåŸºå› ç»„ä»¥åŠä¸ä½¿ç”¨å‚è€ƒåŸºå› ç»„æ¥è¯„ä¼°è£…é…ã€‚ QUASTç”Ÿæˆè¯¦ç»†çš„æŠ¥å‘Šï¼Œè¡¨æ ¼å’Œå›¾è§£ï¼Œä»¥æ˜¾ç¤ºè£…é…çš„ä¸åŒæ–¹é¢ã€‚\nåŸºå› é¢„æµ‹ï¼šProdigal è¾“å…¥æ–‡ä»¶ï¼šæ‹¼è£…å¥½çš„åºåˆ—æ–‡ä»¶ megahit/final.contigs.fa\nè¾“å‡ºæ–‡ä»¶ï¼šprodigalé¢„æµ‹çš„åŸºå› åºåˆ— prodigal/gene.fa\nprodigalä¸æ”¯æŒå¤šçº¿ç¨‹è¿è¡Œï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥è‡ªè¡Œåˆ†å‰²åºåˆ—æ–‡ä»¶è°ƒç”¨å¤šä¸ªprodigalç¨‹åºåˆ†åˆ«è·‘å®ç°ä¼ªå¤šçº¿ç¨‹ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #!/bin/bash #SBATCH --job-name=prodigal #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/prodigal/log/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/prodigal/log/%x_%a.err #SBATCH --array=1-33 #SBATCH --partition=cpu #SBATCH --cpus-per-task=1 echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` echo \u0026#34;SLURM_ARRAY_TASK_ID: \u0026#34; $SLURM_ARRAY_TASK_ID sample=$(head -n $SLURM_ARRAY_TASK_ID ~/work/asthma/data/namelist | tail -1) #sample=$(head -n 1 namelist | tail -1) echo handling: $sample #################### prodigal -i ~/work/asthma/megahit/contigs/$sample.fa \\ -d ~/work/asthma/prodigal/$sample.gene.fa \\ -o ~/work/asthma/prodigal/$sample.gene.gff \\ -p meta -f gff grep \u0026#39;partial=00\u0026#39; ~/work/asthma/prodigal/$sample.gene.fa | cut -f1 -d \u0026#39; \u0026#39;| sed \u0026#39;s/\u0026gt;//\u0026#39; \u0026gt; ~/work/asthma/prodigal/$sample.fullid seqkit grep -f ~/work/asthma/prodigal/$sample.fullid ~/work/asthma/prodigal/$sample.gene.fa \u0026gt; ~/work/asthma/prodigal/fullgene/$sample.gene.fa #################### echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s ============================================================================ ## ç»Ÿè®¡åŸºå› æ•°é‡ grep -c \u0026#39;\u0026gt;\u0026#39; temp/prodigal/gene.fa ## ç»Ÿè®¡å®Œæ•´åŸºå› æ•°é‡ï¼Œæ•°æ®é‡å¤§å¯åªç”¨å®Œæ•´åŸºå› éƒ¨åˆ† grep -c \u0026#39;partial=00\u0026#39; temp/prodigal/gene.fa ## æå–å®Œæ•´åŸºå› (å®Œæ•´ç‰‡æ®µè·å¾—çš„åŸºå› å…¨ä¸ºå®Œæ•´ï¼Œå¦‚æˆç¯çš„ç»†èŒåŸºå› ç»„) grep \u0026#39;partial=00\u0026#39; temp/prodigal/gene.fa | cut -f1 -d \u0026#39; \u0026#39;| sed \u0026#39;s/\u0026gt;//\u0026#39; \u0026gt; temp/prodigal/full_length.id seqkit grep -f temp/prodigal/full_length.id temp/prodigal/gene.fa \u0026gt; temp/prodigal/full_length.fa seqkit stat temp/prodigal/full_length.fa å»å†—ä½™ï¼š Cd-hit ä¸Šé¢äº§ç”Ÿäº†nä¸ªæ ·æœ¬çš„åŸºå› é¢„æµ‹ç»“æœæ–‡ä»¶ï¼Œgene.faæ–‡ä»¶è¦æƒ³åŠæ³•æ•´åˆä¸ºä¸€ä¸ªæ–‡ä»¶å†å»å»å†—ä½™ã€‚\n1 2 3 4 5 6 7 8 9 10 #!/bin/bash #ä¿®æ”¹æ¯æ¡åºåˆ—çš„åç§°ï¼ŒåŠ ä¸Šæ ·æœ¬å for i in `cat ~/work/asthma/data/namelist` do echo $i sed -i \u0026#34;/\u0026gt;/s/\u0026gt;/\u0026gt;${i}_/\u0026#34; $i.gene.fa done echo \u0026#39;start merge\u0026#39; cat *.gene.fa\u0026gt;all.fullgene.fa echo \u0026#39;done\u0026#39; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #!/bin/bash #SBATCH --job-name=cdhit #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/%x_%a.err #SBATCH --cpus-per-task=32 #SBATCH --partition=short echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` ############## ## è¾“å…¥æ–‡ä»¶ï¼šprodigalé¢„æµ‹çš„åŸºå› åºåˆ— all.fullgene.fa ## è¾“å‡ºæ–‡ä»¶ï¼šå»å†—ä½™åçš„åŸºå› å’Œè›‹ç™½åºåˆ—ï¼šNR/nucleotide.fa;NR/protein.fa mkdir NR ## aSè¦†ç›–åº¦ï¼Œcç›¸ä¼¼åº¦ï¼ŒGå±€éƒ¨æ¯”å¯¹ï¼Œgæœ€ä¼˜è§£ï¼ŒTå¤šçº¿ç¨‹ï¼ŒMå†…å­˜0ä¸é™åˆ¶ ## 2ä¸‡åŸºå› 2mï¼Œ2åƒä¸‡éœ€è¦2000hï¼Œå¤šçº¿ç¨‹å¯åŠ é€Ÿ\tcd-hit-est -i prodigal/fullgene/all.fullgene.fa \\ -o NR/nucleotide.fa \\ -aS 0.9 -c 0.9 -G 0 -g 0 -T 0 -M 0 ## ç»Ÿè®¡éå†—ä½™åŸºå› æ•°é‡ï¼Œå•æ¬¡æ‹¼æ¥ç»“æœæ•°é‡ä¸‹é™ä¸å¤§ï¼Œå¤šæ‰¹æ‹¼æ¥å†—ä½™åº¦é«˜ echo \u0026#39;after remove, the number of genes: \u0026#39; grep -c \u0026#39;\u0026gt;\u0026#39; NR/nucleotide.fa ## ç¿»è¯‘æ ¸é…¸ä¸ºå¯¹åº”è›‹ç™½åºåˆ—ï¼Œemboss ## emboss transeqå·¥å…·ï¼Œ93.9 MB conda install emboss -y transeq -sequence NR/nucleotide.fa \\ -outseq NR/protein.fa -trim Y ## åºåˆ—åè‡ªåŠ¨æ·»åŠ äº†_1ï¼Œä¸ºä¸æ ¸é…¸å¯¹åº”è¦å»é™¤ sed -i \u0026#39;s/_1 / /\u0026#39; NR/protein.fa ############## echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s åŸºå› å®šé‡ï¼šsalmon å»ºç«‹ç´¢å¼• 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #!/bin/bash #SBATCH --job-name=salmon-index #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/%x_%a.err #SBATCH --cpus-per-task=32 #SBATCH --partition=short echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` ############## mkdir -p temp/salmon ## å»ºç´¢å¼•, -tåºåˆ—, -i ç´¢å¼•ï¼Œ10s salmon index \\ -t NR/nucleotide.fa \\ -p 32 \\ -i temp/salmon/index ############## echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s å¯¹æ¯ä¸ªæ ·æœ¬å®šé‡ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #!/bin/bash #SBATCH --job-name=salmon #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/salmon/log/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/salmon/log/%x_%a.err #SBATCH --array=1-33 #SBATCH --partition=cpu #SBATCH --cpus-per-task=32 echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` echo \u0026#34;SLURM_ARRAY_TASK_ID: \u0026#34; $SLURM_ARRAY_TASK_ID sample=$(head -n $SLURM_ARRAY_TASK_ID ~/work/asthma/data/namelist | tail -1) #sample=$(head -n 1 namelist | tail -1) echo handling: $sample #################### ## è¾“å…¥æ–‡ä»¶ï¼šå»å†—ä½™åçš„åŸºå› å’Œè›‹ç™½åºåˆ—ï¼šNR/nucleotide.fa ## è¾“å‡ºæ–‡ä»¶ï¼šSalmonå®šé‡åçš„ç»“æœï¼šsalmon/gene.count;salmon/gene.TPM ## å®šé‡ï¼Œlæ–‡åº“ç±»å‹è‡ªåŠ¨é€‰æ‹©ï¼Œpçº¿ç¨‹ï¼Œ--metaå®åŸºå› ç»„æ¨¡å¼ salmon quant \\ -i temp/salmon/index -l A -p 32 --meta \\ -1 data/alldata/${sample}_f1.fastq \\ -2 data/alldata/${sample}_r2.fastq \\ -o temp/salmon/${sample}.quant #################### echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s åˆå¹¶å„æ ·æœ¬ç»“æœ 1 2 3 4 5 6 7 8 9 10 11 12 ## åˆå¹¶ mkdir -p salmon salmon quantmerge \\ --quants temp/salmon/*.quant \\ -o salmon/gene.TPM salmon quantmerge \\ --quants temp/salmon/*.quant \\ --column NumReads -o salmon/gene.count sed -i \u0026#39;1 s/.quant//g\u0026#39; salmon/gene.* ## é¢„è§ˆç»“æœè¡¨æ ¼ head -n3 salmon/gene.* åŠŸèƒ½åŸºå› æ³¨é‡Š ä¸Šä¸€æ­¥å·²ç»æœ‰äº†æ‰€æœ‰çš„åŸºå› å’Œæ¯ä¸ªæ ·æœ¬æ‰€æœ‰åŸºå› çš„read countå®šé‡ç»“æœï¼Œæˆ‘ä»¬åªéœ€è¦å¯¹ä¸Šä¸€æ­¥çš„åŸºå› åºåˆ—ï¼ˆæˆ–è›‹ç™½è´¨åºåˆ—ï¼‰è¿›è¡Œä¸åŒæ•°æ®åº“çš„æ³¨é‡Šï¼ˆå¾ˆå¤šè½¯ä»¶éƒ½æ˜¯ç”¨diamondæ¯”å¯¹ï¼Œå¦‚æœæ²¡æœ‰ä¸“ç”¨è½¯ä»¶çš„æ•°æ®åº“æˆ‘ä»¬ä¹Ÿå¯ä»¥è‡ªå·±ç”¨diamondæ¯”å¯¹ï¼‰ï¼Œåˆå¹¶æ³¨é‡Šç»“æœå¾—åˆ°çš„å°±æ˜¯åŠŸèƒ½ä¸°åº¦è¡¨ã€‚\ndiamondé€‰æ‹©\u0026ndash;outfmt 6çš„è¾“å‡ºç»“æœå’Œblastpä¸€æ ·ï¼š\n1. qseqid query sequence id 2. sseqid subject (e.g., reference genome) sequence id 3. pident percentage of identical matches 4. length alignment length 5. mismatch number of mismatches 6. gapopen number of gap openings 7. qstart start of alignment in query 8. qend end of alignment in query 9. sstart start of alignment in subject 10. send end of alignment in subject 11. evalue expect value 12. bitscore bit score 1 eggNOG(COG/KEGG/CAZy) EggNOGæ•°æ®åº“æ”¶é›†äº†COGï¼ˆClusters of Orthologous Groups of proteinsï¼Œç›´ç³»åŒæºè›‹ç™½ç°‡ï¼‰,æ„æˆæ¯ä¸ªCOGçš„è›‹ç™½éƒ½æ˜¯è¢«å‡å®šä¸ºæ¥è‡ªäºä¸€ä¸ªç¥–å…ˆè›‹ç™½ï¼Œå› æ­¤æ˜¯orthologsæˆ–è€…æ˜¯paralogsã€‚é€šè¿‡æŠŠæ‰€æœ‰å®Œæ•´åŸºå› ç»„çš„ç¼–ç è›‹ç™½ä¸€ä¸ªä¸€ä¸ªçš„äº’ç›¸æ¯”è¾ƒç¡®å®šçš„ã€‚åœ¨è€ƒè™‘æ¥è‡ªä¸€ä¸ªç»™å®šåŸºå› ç»„çš„è›‹ç™½æ—¶ï¼Œè¿™ç§æ¯”è¾ƒå°†ç»™å‡ºæ¯ä¸ªå…¶ä»–åŸºå› ç»„çš„ä¸€ä¸ªæœ€ç›¸ä¼¼çš„è›‹ç™½ï¼ˆå› æ­¤éœ€è¦ç”¨å®Œæ•´çš„åŸºå› ç»„æ¥å®šä¹‰COGï¼‰ï¼Œè¿™äº›åŸºå› çš„æ¯ä¸€ä¸ªéƒ½è½®ç•ªåœ°è¢«è€ƒè™‘ã€‚å¦‚æœåœ¨è¿™äº›è›‹ç™½ï¼ˆæˆ–å­é›†ï¼‰ä¹‹é—´ä¸€ä¸ªç›¸äº’çš„æœ€ä½³åŒ¹é…å…³ç³»è¢«å‘ç°ï¼Œé‚£ä¹ˆé‚£äº›ç›¸äº’çš„æœ€ä½³åŒ¹é…å°†å½¢æˆä¸€ä¸ªCOGã€‚è¿™æ ·ï¼Œä¸€ä¸ªCOGä¸­çš„æˆå‘˜å°†ä¸è¿™ä¸ªCOGä¸­çš„å…¶ä»–æˆå‘˜æ¯”èµ·è¢«æ¯”è¾ƒçš„åŸºå› ç»„ä¸­çš„å…¶ä»–è›‹ç™½æ›´ç›¸åƒã€‚\nEggNOGé‡Œé¢åŒ…å«äº†GOï¼ŒKEGGï¼ŒCAZyç­‰ã€‚\n1 2 3 4 5 6 7 8 9 ## ä¸‹è½½å¸¸ç”¨æ•°æ®åº“ï¼Œæ³¨æ„è®¾ç½®ä¸‹è½½ä½ç½® mkdir -p ${db}/eggnog5 \u0026amp;\u0026amp; cd ${db}/eggnog5 ## -yé»˜è®¤åŒæ„ï¼Œ-få¼ºåˆ¶ä¸‹è½½ï¼Œeggnog.db.gz 7.9G+4.9G download_eggnog_data.py -y -f --data_dir ./ ## ä¸‹è½½æ–¹å¼2(å¯é€‰)ï¼šé“¾æ¥ç›´æ¥ä¸‹è½½ wget -c http://eggnog5.embl.de/download/emapperdb-5.0.0/eggnog.db.gz ## 7.9G wget -c http://eggnog5.embl.de/download/emapperdb-5.0.0/eggnog_proteins.dmnd.gz ## 4.9G gunzip *.gz 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #!/bin/bash #SBATCH --job-name=eggo #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/%x_%j.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/%x_%j.err #SBATCH --cpus-per-task=32 #SBATCH --partition=cpu echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` ############## #åˆ‡æ¢ç¯å¢ƒ ## diamondæ¯”å¯¹åŸºå› è‡³eggNOG 5.0æ•°æ®åº“, 1~9hï¼Œé»˜è®¤diamond 1e-3 mkdir -p temp/eggnog emapper.py --no_annot --no_file_comments --override \\ --data_dir ~/db/eggnog5 \\ -i NR/protein.fa \\ --cpu 32 -m diamond \\ -o temp/eggnog/protein ## æ¯”å¯¹ç»“æœåŠŸèƒ½æ³¨é‡Š, 1h emapper.py \\ --annotate_hits_table temp/eggnog/protein.emapper.seed_orthologs \\ --data_dir ~/db/eggnog5 \\ --cpu 32 --no_file_comments --override \\ -o temp/eggnog/output ## æ·»è¡¨å¤´, 1åˆ—ä¸ºIDï¼Œ9åˆ—KOï¼Œ16åˆ—CAZyï¼Œ21åˆ—COGï¼Œ22åˆ—æè¿° sed \u0026#39;1 i Name\\tortholog\\tevalue\\tscore\\ttaxonomic\\tprotein\\tGO\\tEC\\tKO\\tPathway\\tModule\\tReaction\\trclass\\tBRITE\\tTC\\tCAZy\\tBiGG\\ttax_scope\\tOG\\tbestOG\\tCOG\\tdescription\u0026#39; \\ temp/eggnog/output.emapper.annotations \\ \u0026gt; temp/eggnog/output ############## echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s 2 ç¢³æ°´åŒ–åˆç‰©dbCAN2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## dbCAN2 http://bcb.unl.edu/dbCAN2 ## åˆ›å»ºæ•°æ®åº“å­˜æ”¾ç›®å½•å¹¶è¿›å…¥ mkdir -p ${db}/dbCAN2 \u0026amp;\u0026amp; cd ${db}/dbCAN2 ## ä¸‹è½½åºåˆ—å’Œæè¿° wget -c http://bcb.unl.edu/dbCAN2/download/CAZyDB.07312020.fa wget -c http://bcb.unl.edu/dbCAN2/download/Databases/CAZyDB.07302020.fam-activities.txt ## å¤‡ç”¨æ•°æ®åº“ä¸‹è½½åœ°å€å¹¶è§£å‹ #wget -c http://210.75.224.110/db/dbcan2/CAZyDB.07312020.fa.gz #gunzip CAZyDB.07312020.fa.gz ## diamondå»ºç´¢å¼•ï¼Œ800Mï¼Œ1m diamond --version ## 0.8.22/2.0.5 time diamond makedb \\ --in CAZyDB.07312020.fa \\ --db CAZyDB.07312020 1 2 3 4 5 6 7 8 ## æ¯”å¯¹CAZyæ•°æ®åº“, ç”¨æ—¶2~18m; åŠ --sensitiveæ›´å…¨ä½†æ…¢è‡³1h mkdir -p temp/dbcan2 diamond blastp \\ --db ~/db/dbcan2/CAZyDB.07312020 \\ --query NR/protein.fa \\ --threads 64 -e 1e-5 --outfmt 6 \\ --max-target-seqs 1 --quiet \\ --out temp/dbcan2/gene_diamond.f6 3 ARGsï¼ˆCARDï¼‰ ## Github: https://github.com/arpcard/rgi\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #!/bin/bash #SBATCH --job-name=rgi #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/%x_%a.err #SBATCH --cpus-per-task=32 #SBATCH --partition=cpu echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` ############## mkdir -p card rgi main --input_sequence ~/work/asthma/temp/protein.fa \\ --output_file card/protein \\ --input_type protein --num_threads 32 \\ --clean --alignment_tool DIAMOND ############## echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s 4 æ¯’åŠ›å› å­VFDB å®˜ç½‘åœ°å€ï¼šhttp://www.mgc.ac.cn/VFs/ åœ¨å®˜ç½‘ä¸‹è½½æ•°æ®åº“æ—¶ï¼Œå¸¦æœ‰setA çš„åº“ä¸ºVFDBæ•°æ®åº“æ ¸å¿ƒåº“(set A)ï¼Œè€ŒsetBä¸ºå…¨åº“(setB), å…¶ä¸­setAä»…åŒ…å«ç»å®éªŒéªŒè¯è¿‡çš„æ¯’åŠ›åŸºå› ï¼Œè€ŒsetBåˆ™åœ¨setAçš„åŸºç¡€ä¸Šå¢åŠ äº†é¢„æµ‹çš„æ¯’åŠ›åŸºå› ï¼Œé€‰æ‹©å¥½æ•°æ®åº“åï¼Œç›´æ¥ç”¨blast/diamondå³å¯å®Œæˆæ³¨é‡Šã€‚\n1 2 3 4 5 6 7 mkdir -p temp/vfdb diamond blastp \\ --db ~/db/VFDB/VFDB_setB_pro \\ --query NR/protein.fa \\ --threads 32 -e 1e-5 --outfmt 6 \\ --max-target-seqs 1 --quiet \\ --out temp/vfdb/gene_diamond.f6 5 å…¶ä»–å„ç§æ•°æ®åº“ åŠŸèƒ½æ³¨é‡Šåˆå¹¶ å†™ä¸€ä¸ªpythonè„šæœ¬ï¼Œå°†è¡¨1ï¼ˆåŸºå› -åŠŸèƒ½çš„å¯¹åº”è¡¨ï¼‰ä¸è¡¨2ï¼ˆåŸºå› ä¸°åº¦è¡¨ï¼‰åˆå¹¶ï¼Œå³ä¸åŒåŸºå› å¯èƒ½æ³¨é‡Šåˆ°ç›¸åŒåŠŸèƒ½ï¼ŒæŠŠå®ƒä»¬çš„ä¸°åº¦åŠ åœ¨ä¸€èµ·å¾—åˆ°æ–°è¡¨3ï¼ˆåŠŸèƒ½ä¸°åº¦è¡¨ï¼‰\nbinning å®åŸºå› ç»„binningæ˜¯æŒ‡å°†ä¸åŒçš„åºåˆ—é›†åˆï¼ˆå¦‚metagenomeåºåˆ—é›†åˆï¼‰æ ¹æ®å®ƒä»¬çš„ç‰©ç§å½’ç±»åˆ°ä¸åŒçš„binsä¸­ï¼Œä»¥ä¾¿è¿›ä¸€æ­¥ç ”ç©¶å®ƒä»¬çš„ç»„æˆå’ŒåŠŸèƒ½ã€‚è¿™ä¸ªè¿‡ç¨‹å¯ä»¥å°†ç±»ä¼¼çš„åºåˆ—ç»„åˆåœ¨ä¸€èµ·ï¼Œå½¢æˆä»£è¡¨ä¸åŒç‰©ç§æˆ–åŸºå› ç»„çš„binsï¼Œä»¥ä¾¿è¿›è¡Œåç»­åˆ†æï¼Œå¦‚ç‰©ç§æ³¨é‡Šã€åŸºå› ç»„ç»„è£…ç­‰ã€‚\nä»¥ä¸‹æ˜¯å¸¸ç”¨çš„å®åŸºå› ç»„binningæ–¹æ³•ï¼š\nåŸºäºèšç±»çš„æ–¹æ³•ï¼šè¯¥æ–¹æ³•ä½¿ç”¨åºåˆ—èšç±»å°†ç›¸ä¼¼åºåˆ—åˆ†åˆ°åŒä¸€ä¸ªbinä¸­ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œèšç±»ç®—æ³•å¯åˆ†ä¸ºä¸¤ç±»ï¼šæ— ç›‘ç£èšç±»ï¼ˆå¦‚k-meansã€DBSCANç­‰ï¼‰å’Œæœ‰ç›‘ç£èšç±»ï¼ˆå¦‚CAMIã€MyCCç­‰ï¼‰ã€‚\nåŸºäºç»„è£…çš„æ–¹æ³•ï¼šè¯¥æ–¹æ³•ä½¿ç”¨de novoç»„è£…æ¥å°†ç›¸ä¼¼åºåˆ—ç»„è£…æˆè¿ç»­çš„åºåˆ—ï¼Œå†æ ¹æ®è¿™äº›åºåˆ—çš„åŸºå› ç»„ä¿¡æ¯æ¥å°†å…¶åˆ†ç±»åˆ°ä¸åŒçš„binsä¸­ã€‚è¿™ç§æ–¹æ³•çš„ä¼˜ç‚¹æ˜¯å¯ä»¥æ›´å¥½åœ°å¤„ç†é‡å¤åºåˆ—ï¼Œç¼ºç‚¹æ˜¯éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºå’Œæ—¶é—´ã€‚\nåŸºäºåˆ†ç±»å™¨çš„æ–¹æ³•ï¼šè¯¥æ–¹æ³•ä½¿ç”¨æœºå™¨å­¦ä¹ åˆ†ç±»å™¨æ¥å°†åºåˆ—åˆ†é…åˆ°ä¸åŒçš„binsä¸­ã€‚è¿™ç§æ–¹æ³•çš„ä¼˜ç‚¹æ˜¯å¯ä»¥è‡ªåŠ¨å­¦ä¹ ç‰¹å¾å¹¶åœ¨å¤„ç†å¤§è§„æ¨¡æ•°æ®æ—¶æ•ˆç‡é«˜ï¼Œç¼ºç‚¹æ˜¯éœ€è¦å…ˆå»ºç«‹ä¸€ä¸ªåˆ†ç±»å™¨å¹¶è¿›è¡Œè®­ç»ƒã€‚\nåœ¨è¿›è¡Œå®åŸºå› ç»„binningæ—¶ï¼Œé€šå¸¸éœ€è¦ä½¿ç”¨å¤šä¸ªæ–¹æ³•è¿›è¡Œæ¯”è¾ƒï¼Œä»¥é€‰æ‹©æœ€é€‚åˆæ•°æ®é›†çš„æ–¹æ³•ã€‚å¯ä»¥ä½¿ç”¨ä¸€äº›æµè¡Œçš„å·¥å…·æ¥è¿›è¡Œbinningï¼Œå¦‚MetaBATã€MaxBinã€CONCOCTå’ŒMEGANç­‰ã€‚è¿™äº›å·¥å…·é€šå¸¸åŒ…å«å„ç§binningæ–¹æ³•ï¼Œå¯ä»¥æ ¹æ®æ•°æ®é›†å’Œåˆ†æç›®çš„é€‰æ‹©é€‚åˆçš„æ–¹æ³•ã€‚\nç¯‡å¹…é™åˆ¶ï¼Œå…·ä½“çš„æ–¹æ³•æ”¾åœ¨å¦ä¸€ç¯‡é‡Œé¢è®²è§£å§ã€‚\nReference 1. Y.-X. Liu, Y. Qin, T. Chen, M. Lu, X. Qian, X. Guo, Y. Bai, A practical guide to amplicon and metagenomic analysis of microbiome data. Protein \u0026amp; Cell. 12, 315â€“330 (2021).\n","date":"2023-03-26T00:00:00Z","permalink":"/p/metagenomic-workflow/","title":"Metagenomic workflow"},{"content":"æ˜¥åˆ†åˆšè¿‡ï¼Œè®¸å¤šèŠ±å„¿éƒ½äº‰ç›¸ç»½æ”¾ã€‚å¤©æ°”è¿˜æ˜¯æœ‰ç‚¹å†·ï¼Œä½†è¿˜æ˜¯æƒ³è·Ÿç¾¤é’åŒå­¦ä¸€èµ·é€›é€›ç´«é‡‘æ¸¯ï¼ŒèµèµèŠ±ï¼Œè§‚è§‚é¸Ÿã€‚\nè¿™ä¸ªæ—¶å€™æ ¡å›­é‡Œæœ€å¤šçš„ä¾¿æ˜¯è”·è–‡ç§‘çš„èŠ±äº†ï¼Œè™½ç„¶æˆ‘å‘æ¥æ˜¯â€æ¡ƒæææ¢…æ¨±ï¼Œå‚»å‚»åˆ†ä¸æ¸…â€çš„ğŸ˜‚ï¼Œè¿™æ¬¡åœ¨ç¾¤é’åŒå­¦çš„å¸®åŠ©ä¸‹æ”¶é›†åˆ°äº†ä¹å®«æ ¼ï¼šèŠèŠ±æ¡ƒï¼Œç¢§æ¡ƒï¼Œå‚ä¸æµ·æ£ ï¼Œè¥¿åºœæµ·æ£ ï¼Œæ¹–åŒ—æµ·æ£ ï¼Œå¤§å²›æ¨±ï¼Œæ—¥æœ¬æ™šæ¨±ï¼Œæ—¥æœ¬æ¨±èŠ±ï¼Œè“¬è˜½\næ¹–å¿ƒå²›å‡ºå‘ï¼ŒäºŒæœˆå…°ï¼Œåˆšå†’èŠ½çš„æ°´æ‰ï¼Œå·å·ç»½æ”¾çš„æ°´ä»™å’Œè´è¶èŠ±ã€‚\né¸Ÿå„¿å¤§å¤šè¿˜æ˜¯è€æœ‹å‹ï¼Œä¸€åªæ­Œå£°å©‰è½¬çš„ä¹Œé¸«ï¼Œå¿«æ­¥èµ°çš„ç™½é¹¡é¸°ï¼Œæ‚ é—²çš„é»‘æ°´é¸¡å’Œæ–‘å˜´é¸­ï¼Œå¤§å–œé¹Šå’Œçº¢å˜´è“é¹Šã€‚æœ¬æ¥è¿™æ¬¡æœ€æƒ³çœ‹åˆ°çš„å°±æ˜¯ç½•è§æ—…å®¢é»‘ç¿…é•¿è„šé¹¬çš„ï¼Œä½†æ˜¯è¿™å„¿æœç„¶åªæ˜¯å®ƒä»¬æ­‡æ­‡è„šçš„åœ°æ–¹ï¼Œæ²¡èƒ½è§åˆ°ğŸ˜­ï¼Œå·æµ™å¤§å®˜å¾®çš„ç¾å›¾ï¼Œå“ˆå“ˆã€‚å—èŠ±å›­è¿˜æ˜¯å¤œé¹­ä¸ç™½é¹­ä»¬çš„é¢†åœ°ã€‚\nç”Ÿç‰©å®éªŒä¸­å¿ƒä¹‹å‰æ¯å¹´è¿™ä¸ªæ—¶å€™éƒ½æ˜¯å¤§ç‰‡æ²¹èœèŠ±ï¼Œæ‰“å¡åœ£åœ°ï¼Œä½†ä»Šå¹´çš„è¯•éªŒç”°æ¬åˆ°äº†é“¶æ³‰ï¼Œè¿™é‡Œå±…ç„¶ç§æ»¡äº†éº¦å­ã€‚ç»¿æ²¹æ²¹çš„éº¦ç”°éå¸¸æ²»æ„ˆã€‚è¿™ä¸ªæˆ‘å«åšå•åŒå­å¶çš„ç¢°æ’ã€‚æƒŠå–œå‡ºç°åœ¨éº¦ç”°çš„æ‹è§’å¤„ï¼Œå‡ åªå¯çˆ±çš„å•¾å•¾æ­£åœ¨å·éº¦å­åƒï¼ŒåŸæ¥æ˜¯ç™½è…°æ–‡é¸Ÿï¼Œä¸Šæ¬¡è§å®ƒä¹Ÿæ˜¯åœ¨å·åƒç”Ÿç§‘é™¢çš„å®éªŒæ°´ç¨»ã€‚ç«™åœ¨ç´«è†ä¸›ä¸­çš„æ–‡é¸Ÿè¶…æœ‰æ°”è´¨ã€‚\nå…¶ä»–ä¸€äº›ï¼ŒåŒ»å­¦é™¢çš„ä¸€æ’æ¨±èŠ±ï¼ŒLYåŒå­¦æœ€èµçš„ä¸€æ ªæ¨±èŠ±ï¼Œå·²ç»åƒäº†å››å¹´è¿˜è¦å†åƒå››å¹´çš„éº¦é¦™â€¦\næ„Ÿè°¢ç¾¤é’åŒå­¦çš„æ‘„å½±ï¼Œè¶Šæ¥è¶Šå¼ºäº†\n","date":"2023-03-25T00:00:00Z","permalink":"/p/%E7%B4%AB%E9%87%91%E6%98%A5%E6%97%A5/","title":"ç´«é‡‘æ˜¥æ—¥"},{"content":"Introduction ç»Ÿè®¡åˆ†æåœ¨ç”Ÿç‰©ä¿¡æ¯å­¦ä¸­å…·æœ‰éå¸¸é‡è¦çš„æ„ä¹‰ï¼Œå› ä¸ºç”Ÿç‰©ä¿¡æ¯å­¦ç ”ç©¶çš„æ•°æ®é‡åºå¤§ã€å¤æ‚æ€§é«˜ï¼Œè€Œç»Ÿè®¡åˆ†æå¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°ç†è§£å’Œè§£é‡Šè¿™äº›æ•°æ®ã€‚ä¸‹é¢æ˜¯ç»Ÿè®¡åˆ†æå¯¹ç”Ÿç‰©ä¿¡æ¯å­¦çš„å‡ ä¸ªé‡è¦æ„ä¹‰ï¼š\næ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†ï¼šç”Ÿç‰©ä¿¡æ¯å­¦ç ”ç©¶ä¸­ç»å¸¸éœ€è¦å¤„ç†å¤§è§„æ¨¡çš„æ•°æ®ï¼Œè€Œè¿™äº›æ•°æ®å¯èƒ½å­˜åœ¨å™ªå£°ã€é”™è¯¯å’Œç¼ºå¤±å€¼ç­‰é—®é¢˜ã€‚ç»Ÿè®¡åˆ†æå¯ä»¥å¸®åŠ©æˆ‘ä»¬å¯¹æ•°æ®è¿›è¡Œæ¸…æ´—å’Œé¢„å¤„ç†ï¼Œä»¥ç¡®ä¿æ•°æ®çš„è´¨é‡å’Œå¯é æ€§ã€‚ æ•°æ®å¯è§†åŒ–ï¼šç»Ÿè®¡åˆ†æå¯ä»¥å¸®åŠ©æˆ‘ä»¬å°†å¤æ‚çš„æ•°æ®è½¬åŒ–ä¸ºå¯è§†åŒ–å›¾å½¢ï¼Œä»è€Œæ›´å¥½åœ°ç†è§£æ•°æ®çš„åˆ†å¸ƒã€å…³ç³»å’Œè¶‹åŠ¿ã€‚è¿™äº›å›¾å½¢å¯ä»¥å¸®åŠ©æˆ‘ä»¬å‘ç°éšè—åœ¨æ•°æ®ä¸­çš„æ¨¡å¼å’Œè§„å¾‹ã€‚ æ•°æ®åˆ†æï¼šç”Ÿç‰©ä¿¡æ¯å­¦ç ”ç©¶ä¸­éœ€è¦å¯¹å¤§é‡çš„æ•°æ®è¿›è¡Œåˆ†æï¼Œä¾‹å¦‚æ¯”è¾ƒåŸºå› ç»„å­¦ã€è½¬å½•ç»„å­¦ã€è›‹ç™½è´¨ç»„å­¦ç­‰ã€‚ç»Ÿè®¡åˆ†æå¯ä»¥å¸®åŠ©æˆ‘ä»¬å¯¹æ•°æ®è¿›è¡Œå»ºæ¨¡å’Œé¢„æµ‹ï¼Œä»è€Œæ·±å…¥æ¢ç©¶ç”Ÿç‰©å­¦çš„å¤æ‚ç°è±¡å’Œæœºåˆ¶ã€‚ æ•°æ®æŒ–æ˜ï¼šç”Ÿç‰©ä¿¡æ¯å­¦ç ”ç©¶ä¸­éœ€è¦æŒ–æ˜å¤§é‡çš„æ•°æ®æ¥å‘ç°æ–°çš„ç”Ÿç‰©å­¦ç°è±¡å’Œæœºåˆ¶ã€‚ç»Ÿè®¡åˆ†æå¯ä»¥å¸®åŠ©æˆ‘ä»¬ä»æ•°æ®ä¸­æå–å‡ºæœ‰ç”¨çš„ä¿¡æ¯å’ŒçŸ¥è¯†ï¼Œè¿›è€Œæ¨åŠ¨ç”Ÿç‰©å­¦çš„ç ”ç©¶å’Œå‘å±•ã€‚ Rè¯­è¨€æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºæ•°æ®åˆ†æå’Œç»Ÿè®¡å»ºæ¨¡çš„ç¼–ç¨‹è¯­è¨€ï¼Œå®ƒæœ‰ä»¥ä¸‹å‡ ä¸ªä¼˜ç‚¹ï¼Œä½¿å…¶æˆä¸ºåšç»Ÿè®¡åˆ†æçš„ç†æƒ³é€‰æ‹©ï¼š\nå…è´¹å’Œå¼€æºï¼šRè¯­è¨€æ˜¯ä¸€ä¸ªå…è´¹å’Œå¼€æºçš„è½¯ä»¶ï¼Œå¯ä»¥åœ¨ä¸ä»˜å‡ºé¢å¤–æˆæœ¬çš„æƒ…å†µä¸‹ä½¿ç”¨å’Œå®šåˆ¶ã€‚è¿™ä½¿å¾—è®¸å¤šå­¦ç”Ÿã€å­¦è€…å’Œæ•°æ®åˆ†æå¸ˆé€‰æ‹©Rè¯­è¨€ä½œä¸ºä»–ä»¬çš„é¦–é€‰ç»Ÿè®¡åˆ†æå·¥å…·ã€‚\nå¼ºå¤§çš„æ•°æ®å¤„ç†èƒ½åŠ›ï¼šRè¯­è¨€å…·æœ‰å¼ºå¤§çš„æ•°æ®å¤„ç†èƒ½åŠ›ï¼Œæ”¯æŒå¤šç§æ•°æ®ç»“æ„å’Œæ•°æ®ç±»å‹ï¼Œå¯ä»¥è½»æ¾åœ°è¿›è¡Œæ•°æ®æ¸…æ´—ã€æ•´åˆã€å˜æ¢å’Œåˆ†æã€‚\nä¸°å¯Œçš„ç»Ÿè®¡åˆ†æå‡½æ•°åº“ï¼šRè¯­è¨€å…·æœ‰ä¸°å¯Œçš„ç»Ÿè®¡åˆ†æå‡½æ•°åº“ï¼ŒåŒ…æ‹¬çº¿æ€§å›å½’ã€é€»è¾‘å›å½’ã€èšç±»åˆ†æã€ä¸»æˆåˆ†åˆ†æã€æ—¶é—´åºåˆ—åˆ†æç­‰ç­‰ã€‚è¿™äº›å‡½æ•°åº“æä¾›äº†è®¸å¤šå¸¸ç”¨çš„ç»Ÿè®¡åˆ†ææ–¹æ³•ï¼Œå¯ä»¥æ»¡è¶³ä¸åŒæ•°æ®åˆ†æéœ€æ±‚ã€‚\nå›¾å½¢å¯è§†åŒ–åŠŸèƒ½ï¼šRè¯­è¨€å…·æœ‰å¼ºå¤§çš„å›¾å½¢å¯è§†åŒ–åŠŸèƒ½ï¼Œå¯ä»¥è½»æ¾åœ°åˆ›å»ºå„ç§ç±»å‹çš„å›¾è¡¨ï¼ŒåŒ…æ‹¬æ•£ç‚¹å›¾ã€æ¡å½¢å›¾ã€æŠ˜çº¿å›¾ã€çƒ­å›¾ç­‰ã€‚è¿™äº›å›¾è¡¨å¯ä»¥å¸®åŠ©æ•°æ®åˆ†æå¸ˆæ›´å¥½åœ°ç†è§£æ•°æ®ã€å‘ç°è§„å¾‹å’Œæå–ä¿¡æ¯ã€‚\nç¤¾åŒºæ”¯æŒå’Œç”Ÿæ€ç³»ç»Ÿï¼šRè¯­è¨€æ‹¥æœ‰åºå¤§çš„ç”¨æˆ·ç¤¾åŒºå’Œç”Ÿæ€ç³»ç»Ÿï¼Œç”¨æˆ·å¯ä»¥è½»æ¾åœ°æ‰¾åˆ°å¹¶ä½¿ç”¨æ•°åƒç§å¯ç”¨çš„ç»Ÿè®¡åˆ†æå·¥å…·å’ŒRåŒ…ï¼Œè¿™äº›å·¥å…·å’ŒRåŒ…å¯ä»¥å¸®åŠ©ç”¨æˆ·æ›´åŠ é«˜æ•ˆåœ°å®Œæˆç»Ÿè®¡åˆ†æä»»åŠ¡ã€‚\næˆ‘æƒ³åœ¨è¿™é‡Œç¨å¾®è®°å½•ä¸€ä¸‹æˆ‘ä½¿ç”¨Rå¸¸ç”¨çš„ä¸€äº›åˆç­‰ç»Ÿè®¡åˆ†ææ–¹æ³•ï¼Œå¦‚å›å½’ï¼Œæ–¹å·®åˆ†æï¼Œå¹¿ä¹‰çº¿æ€§æ¨¡å‹ç­‰ï¼Œä¸»è¦å‚è€ƒèµ„æ–™æ˜¯ã€ŠRè¯­è¨€æ•™ç¨‹ã€‹ VIIéƒ¨åˆ†ç»Ÿè®¡åˆ†æçš„å†…å®¹ã€‚\nStatistics åŸºç¡€ç”¨æ³• å•æ ·æœ¬å‡å€¼æ£€éªŒ 1 2 3 4 5 6 7 ?t.test() #install.packages(\u0026#34;ggstatsplot\u0026#34;,dependencies = T) library(ggstatsplot) #è¿™ä¸ªåŒ…ä¼šåœ¨ç”»å›¾çš„è¿‡ç¨‹ä¸­è®¡ç®—å¾ˆå¤šç»Ÿè®¡é‡ï¼Œå¸®æˆ‘ä»¬æ›´å¥½åœ°æŠŠæ¡æ•°æ®çš„æ€§è´¨ #æ¯”å¦‚æˆ‘ä»¬æƒ³çœ‹tooth lengthå‡å€¼æ˜¯å¦å’Œ25æœ‰æ˜¾è‘—å·®å¼‚ t.test(ToothGrowth$len,mu = 25,alternative = \u0026#34;two.sided\u0026#34;) ## ## One Sample t-test ## ## data: ToothGrowth$len ## t = -6.2648, df = 59, p-value = 0.00000004681 ## alternative hypothesis: true mean is not equal to 25 ## 95 percent confidence interval: ## 16.83731 20.78936 ## sample estimates: ## mean of x ## 18.81333 1 2 3 4 5 6 gghistostats( data = ToothGrowth, x = len, xlab = \u0026#34;Tooth length\u0026#34;, test.value = 25 ) æ£€éªŒçš„åŠŸæ•ˆï¼Œ æ˜¯æŒ‡å¯¹ç«‹å‡è®¾æˆç«‹æ—¶æ£€éªŒæ‹’ç»$H_0$çš„æ¦‚ç‡$1-\\beta$ï¼Œ å…¶ä¸­$\\beta$æ˜¯ç¬¬äºŒç±»é”™è¯¯ï¼Œ å³å½“å¯¹ç«‹å‡è®¾æˆç«‹æ—¶é”™è¯¯åœ°æ¥å—$H_0$çš„æ¦‚ç‡ã€‚ éœ€è¦è¶³å¤Ÿå¤§çš„æ ·æœ¬é‡æ‰èƒ½ä½¿å¾—æ£€éªŒèƒ½å¤Ÿå‘ç°å®é™…å­˜åœ¨çš„æ˜¾è‘—å·®å¼‚ã€‚\n1 2 3 4 5 6 7 pwr::pwr.t.test( type = \u0026#34;one.sample\u0026#34;, alternative=\u0026#34;greater\u0026#34;, d = (7.25 - 7.0)/1.052, sig.level = 0.05, power = 0.80 ) |\u0026gt; plot() å‡å€¼æ¯”è¾ƒ ç‹¬ç«‹ä¸¤æ ·æœ¬tæ£€éªŒ\n1 t.test(mpg~am,data = mtcars) ## ## Welch Two Sample t-test ## ## data: mpg by am ## t = -3.7671, df = 18.332, p-value = 0.001374 ## alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0 ## 95 percent confidence interval: ## -11.280194 -3.209684 ## sample estimates: ## mean in group 0 mean in group 1 ## 17.14737 24.39231 1 ggbetweenstats(mtcars, am, mpg) æ¯”ä¾‹æ£€éªŒ 1 2 #æŠ½æŸ¥400ä¸ªæ ·æœ¬100ä¸ªå¼‚å¸¸ï¼Œå¼‚å¸¸æ¯”ä¾‹æ˜¯å¦æ˜¾è‘—å¤§äº0.2 prop.test(100, 400, p=0.20, alternative = \u0026#34;greater\u0026#34;) ## ## 1-sample proportions test with continuity correction ## ## data: 100 out of 400, null probability 0.2 ## X-squared = 5.9414, df = 1, p-value = 0.007395 ## alternative hypothesis: true p is greater than 0.2 ## 95 percent confidence interval: ## 0.2149649 1.0000000 ## sample estimates: ## p ## 0.25 1 2 #ä¸¤æ¬¡æŠ½æŸ¥çš„æ¯”ä¾‹æ˜¯å¦ä¸€è‡´ prop.test(c(35,27), c(250,300), alternative = \u0026#34;two.sided\u0026#34;) ## ## 2-sample test for equality of proportions with continuity correction ## ## data: c(35, 27) out of c(250, 300) ## X-squared = 2.9268, df = 1, p-value = 0.08712 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.007506845 0.107506845 ## sample estimates: ## prop 1 prop 2 ## 0.14 0.09 æ–¹å·®çš„å‡è®¾æ£€éªŒ æ£€æŸ¥ä¸¤ç»„æ•°æ®çš„æ–¹å·®æœ‰è¯¯æ˜¾è‘—å·®å¼‚ï¼Ÿ\n1 2 3 4 var.test(c( 20.5, 18.8, 19.8, 20.9, 21.5, 19.5, 21.0, 21.2), c( 17.7, 20.3, 20.0, 18.8, 19.0, 20.1, 20.2, 19.1), alternative = \u0026#34;two.sided\u0026#34;) ## ## F test to compare two variances ## ## data: c(20.5, 18.8, 19.8, 20.9, 21.5, 19.5, 21, 21.2) and c(17.7, 20.3, 20, 18.8, 19, 20.1, 20.2, 19.1) ## F = 1.069, num df = 7, denom df = 7, p-value = 0.9322 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.214011 5.339386 ## sample estimates: ## ratio of variances ## 1.068966 æ‹Ÿåˆä¼˜åº¦æ£€éªŒ 1 2 #6ç±»faceçš„countæ¯”ä¾‹æ˜¯å¦ç›¸ç­‰ï¼Œå¡æ–¹æ£€éªŒ chisq.test(c(168, 159, 168, 180, 167, 158)) ## ## Chi-squared test for given probabilities ## ## data: c(168, 159, 168, 180, 167, 158) ## X-squared = 1.892, df = 5, p-value = 0.8639 1 2 3 4 5 6 7 ggpiestats( data = data.frame(face=1:6, counts=c(168, 159, 168, 180, 167, 158)), x = face, counts = counts, title = \u0026#34;Dice equality\u0026#34; ) 1 2 #å„ç±»æ¯”ä¾‹æ˜¯å¦ä¸ºæŒ‡å®šå€¼ chisq.test(c(48, 98, 54), p=c(0.3, 0.5, 0.2)) ## ## Chi-squared test for given probabilities ## ## data: c(48, 98, 54) ## X-squared = 7.34, df = 2, p-value = 0.02548 æ£€éªŒåˆ†å¸ƒç±»å‹ vcdåŒ…æä¾›äº†ä¸€ä¸ªgoodfitå‡½æ•°ï¼Œ å¯ä»¥ç”¨æ¥æ‹ŸåˆæŒ‡å®šçš„æŸç§ç†è®ºåˆ†å¸ƒ(åŒ…æ‹¬æ³Šæ¾ã€äºŒé¡¹ã€è´ŸäºŒé¡¹åˆ†å¸ƒï¼‰ï¼Œ å¹¶æ£€éªŒæœä»è¯¥ç†è®ºåˆ†å¸ƒçš„é›¶å‡è®¾ã€‚\n1 2 3 set.seed(101) datax \u0026lt;- rpois(100, 2) summary(vcd::goodfit(datax, \u0026#34;poisson\u0026#34;)) ## ## Goodness-of-fit test for poisson distribution ## ## X^2 df P(\u0026gt; X^2) ## Likelihood Ratio 4.289456 5 0.5085374 ç‹¬ç«‹æ€§å¡æ–¹æ£€éªŒ 1 2 3 4 5 6 ctab.beer \u0026lt;- rbind(c( 20, 40, 20), c(30,30,10)) colnames(ctab.beer) \u0026lt;- c(\u0026#34;Light\u0026#34;, \u0026#34;Regular\u0026#34;, \u0026#34;Dark\u0026#34;) rownames(ctab.beer) \u0026lt;- c(\u0026#34;Male\u0026#34;, \u0026#34;Female\u0026#34;) addmargins(ctab.beer) ## Light Regular Dark Sum ## Male 20 40 20 80 ## Female 30 30 10 70 ## Sum 50 70 30 150 1 2 #åˆ—è”è¡¨ç‹¬ç«‹æ€§æ£€éªŒï¼š chisq.test(ctab.beer) ## ## Pearson's Chi-squared test ## ## data: ctab.beer ## X-squared = 6.1224, df = 2, p-value = 0.04683 1 #åœ¨0.05æ°´å¹³ä¸‹è®¤ä¸ºå•¤é…’ç±»å‹åå¥½ä¸æ€§åˆ«æœ‰å…³ éå‚æ•°æ£€éªŒ å¸¸ç”¨çš„æœ‰ç‹¬ç«‹ä¸¤æ ·æœ¬æ¯”è¾ƒçš„Wilcoxonç§©å’Œæ£€éªŒï¼Œ å•æ ·æœ¬çš„ç¬¦å·ç§©æ£€éªŒå’Œç¬¦å·æ£€éªŒç­‰\n1 2 3 x \u0026lt;- c(0.80, 0.83, 1.89, 1.04, 1.45, 1.38, 1.91, 1.64, 0.73, 1.46) y \u0026lt;- c(1.15, 0.88, 0.90, 0.74, 1.21) wilcox.test(x,mu = 0.7) ## ## Wilcoxon signed rank exact test ## ## data: x ## V = 55, p-value = 0.001953 ## alternative hypothesis: true location is not equal to 0.7 1 wilcox.test(x, y, alternative = \u0026#34;g\u0026#34;) ## ## Wilcoxon rank sum exact test ## ## data: x and y ## W = 35, p-value = 0.1272 ## alternative hypothesis: true location shift is greater than 0 å›å½’åˆ†æ ç›¸å…³åˆ†æ Pearsonç›¸å…³ç³»æ•°ï¼š $$ \\rho(X,Y)=\\frac{E[(X-E(X))(Y-E(Y))]}{\\sqrt{Var(X)Var(Y)}} $$ ç›¸å…³ç³»æ•°ç»å¯¹å€¼åœ¨0.8ä»¥ä¸Šè®¤ä¸ºé«˜åº¦ç›¸å…³ã€‚ åœ¨0.5åˆ°0.8ä¹‹é—´è®¤ä¸ºä¸­åº¦ç›¸å…³ã€‚ åœ¨0.3åˆ°0.5ä¹‹é—´è®¤ä¸ºä½åº¦ç›¸å…³ã€‚ åœ¨0.3ä»¥ä¸‹è®¤ä¸ºä¸ç›¸å…³æˆ–ç›¸å…³æ€§å¾ˆå¼±ä»¥è‡³äºæ²¡æœ‰å®é™…ä»·å€¼ã€‚ å½“ç„¶ï¼Œåœ¨ç‰¹åˆ«é‡è¦çš„é—®é¢˜ä¸­ï¼Œ åªè¦ç»è¿‡æ£€éªŒæ˜¾è‘—ä¸ç­‰äºé›¶çš„ç›¸å…³éƒ½è®¤ä¸ºæ˜¯æœ‰æ„ä¹‰çš„ã€‚\nç›¸å…³ç³»æ•°æ£€éªŒï¼š\næ£€éªŒç»Ÿè®¡é‡: $$ t=\\frac{r\\sqrt{n-2}}{\\sqrt{1-r^2}} $$ på€¼ä¸ºï¼š$P(|t(n-2)|\u0026gt;|t_0|)$\n1 2 3 4 5 6 7 set.seed(1) x \u0026lt;- runif(30, 0, 10) xx \u0026lt;- seq(0, 10, length.out = 100) y \u0026lt;- 40 - (x-7)^2 + rnorm(30) yy \u0026lt;- 40 - (xx-7)^2 plot(x, y, pch=16) lines(xx, yy) 1 cor(x,y,method = \u0026#34;pearson\u0026#34;) ## [1] 0.8244374 1 cor.test(x,y,method = \u0026#34;pearson\u0026#34;) ## ## Pearson's product-moment correlation ## ## data: x and y ## t = 7.7083, df = 28, p-value = 0.00000002136 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.6602859 0.9134070 ## sample estimates: ## cor ## 0.8244374 1 2 3 4 5 ggstatsplot::ggscatterstats( data = data.frame(x,y), x = x, y = y ) ç›¸å…³æ€§çŸ©é˜µï¼Œ`n*n`æˆ–`n*m`çš„$r$ å’Œ$p-value$çŸ©é˜µ 1 2 3 ggstatsplot::ggcorrmat( data = mtcars ) 1 pcutils::cor_plot(mtcars) 1 corrplot::corrplot(cor(mtcars)) 1 ggcorrplot::ggcorrplot(cor(mtcars),method = \u0026#34;circle\u0026#34;) Spearmanç§©ç›¸å…³ç³»æ•° Spearman rhoç³»æ•°ï¼Œ æ˜¯ä¸¤ä¸ªå˜é‡çš„ç§©ç»Ÿè®¡é‡çš„ç›¸å…³ç³»æ•°\nKendall tauç³»æ•° å½“å˜é‡æ­£ç›¸å…³æ€§å¾ˆå¼ºæ—¶ï¼Œ ä»»æ„ä¸¤ä¸ªè§‚æµ‹çš„Xå€¼çš„å¤§å°é¡ºåºåº”è¯¥ä¸Yå€¼çš„å¤§å°é¡ºåºç›¸åŒï¼› å¦‚æœç‹¬ç«‹ï¼Œ ä¸€å¯¹è§‚æµ‹çš„Xå€¼æ¯”è¾ƒå’ŒYå€¼æ¯”è¾ƒé¡ºåºç›¸åŒä¸é¡ºåºç›¸åçš„æ•°ç›®åº”è¯¥åŸºæœ¬ç›¸åŒã€‚Kandall tauç³»æ•°ä¹Ÿæ˜¯å–å€¼äºåŒºé—´[-1,1]ï¼Œ ç”¨è¿™æ ·çš„æ€æƒ³è¡¨ç¤ºä¸¤ä¸ªå˜é‡çš„ç›¸å…³æ€§å’Œæ­£è´Ÿã€‚\n1 cor.test(x,y,method = \u0026#34;spearman\u0026#34;) ## ## Spearman's rank correlation rho ## ## data: x and y ## S = 922, p-value = 0.000001339 ## alternative hypothesis: true rho is not equal to 0 ## sample estimates: ## rho ## 0.7948832 1 cor.test(x,y,method = \u0026#34;kendall\u0026#34;) ## ## Kendall's rank correlation tau ## ## data: x and y ## T = 354, p-value = 0.000000159 ## alternative hypothesis: true tau is not equal to 0 ## sample estimates: ## tau ## 0.6275862 ä¸€å…ƒå›å½’ $$ Y=a+bX+\\varepsilon, \\varepsilon \\sim N(0,\\sigma^2) $$\næœ€å°äºŒä¹˜æ³• $$ \\hat{b}=\\frac{\\sum_i(x_i-\\overline{x})(y_i-\\overline{y})}{\\sum_i{(x-x_i)}^2}=r_{xy}\\frac{S_y}{S_x} $$\n$$ \\hat{a}=\\overline{y}-\\hat{b}\\overline{x} $$ å›å½’æœ‰æ•ˆæ€§å¯ä»¥ç”¨$R^2$å’Œ$p-valuie$æ¥åº¦é‡ï¼Œ $R^2=1-\\frac{SSE}{SST}$\nç»Ÿè®¡é‡$F=\\frac{SSR}{SSE/(n-2)}$,$p-value$ä¸º$P(F(1,n-2)\u0026gt;c)$,cä¸ºFçš„å€¼ã€‚\n1 2 lm1 \u0026lt;- lm(y ~ x) summary(lm1) ## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -17.856 -4.549 2.141 6.048 9.664 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 9.9855 2.6930 3.708 0.000914 *** ## x 3.5396 0.4592 7.708 0.0000000214 *** ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Residual standard error: 7.302 on 28 degrees of freedom ## Multiple R-squared: 0.6797,\tAdjusted R-squared: 0.6683 ## F-statistic: 59.42 on 1 and 28 DF, p-value: 0.00000002136 1 2 #prediction predict(lm1,newdata =data.frame(x=c(5,10,15))) ## 1 2 3 ## 27.68364 45.38182 63.08000 1 pcutils::my_lm(y,x) å¤šå…ƒå›å½’ 1 2 lm2 \u0026lt;- lm(mpg ~ cyl + disp, data=mtcars) summary(lm2) ## ## Call: ## lm(formula = mpg ~ cyl + disp, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.4213 -2.1722 -0.6362 1.1899 7.0516 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 34.66099 2.54700 13.609 4.02e-14 *** ## cyl -1.58728 0.71184 -2.230 0.0337 * ## disp -0.02058 0.01026 -2.007 0.0542 . ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Residual standard error: 3.055 on 29 degrees of freedom ## Multiple R-squared: 0.7596,\tAdjusted R-squared: 0.743 ## F-statistic: 45.81 on 2 and 29 DF, p-value: 0.000000001058 1 ggstatsplot::ggcoefstats(lm2) 1 2 #å›å½’è‡ªå˜é‡ç­›é€‰ lm3 \u0026lt;- step(lm(mpg ~ cyl + disp+hp+drat+vs, data=mtcars)) ## Start: AIC=77.08 ## mpg ~ cyl + disp + hp + drat + vs ## ## Df Sum of Sq RSS AIC ## - vs 1 0.3134 244.90 75.124 ## - cyl 1 7.6839 252.27 76.073 ## - drat 1 14.3330 258.92 76.905 ## - disp 1 14.6709 259.26 76.947 ## \u0026lt;none\u0026gt; 244.59 77.083 ## - hp 1 19.8255 264.41 77.577 ## ## Step: AIC=75.12 ## mpg ~ cyl + disp + hp + drat ## ## Df Sum of Sq RSS AIC ## - cyl 1 8.444 253.35 74.209 ## - disp 1 14.765 259.67 74.997 ## \u0026lt;none\u0026gt; 244.90 75.124 ## - drat 1 16.467 261.37 75.206 ## - hp 1 19.613 264.51 75.589 ## ## Step: AIC=74.21 ## mpg ~ disp + hp + drat ## ## Df Sum of Sq RSS AIC ## \u0026lt;none\u0026gt; 253.35 74.209 ## - drat 1 30.148 283.49 75.806 ## - disp 1 38.107 291.45 76.693 ## - hp 1 49.550 302.90 77.925 å¤šé‡å…±çº¿æ€§\nç‹­ä¹‰çš„å¤šé‡å…±çº¿æ€§ï¼ˆmulticollinearityï¼‰ï¼š è‡ªå˜é‡çš„æ•°æ®å­˜åœ¨çº¿æ€§ç»„åˆè¿‘ä¼¼åœ°ç­‰äºé›¶ï¼Œ ä½¿å¾—è§£çº¿æ€§æ–¹ç¨‹ç»„æ±‚è§£å›å½’ç³»æ•°æ—¶ç»“æœä¸ç¨³å®šï¼Œ å›å½’ç»“æœå¾ˆå·®ã€‚\nå¹¿ä¹‰çš„å¤šé‡å…±çº¿æ€§ï¼š è‡ªå˜é‡ä¹‹é—´å­˜åœ¨è¾ƒå¼ºçš„ç›¸å…³æ€§ï¼Œ è¿™æ ·è‡ªå˜é‡æ˜¯è”åŠ¨çš„ï¼Œ äº’ç›¸ä¹‹é—´æœ‰æ›¿ä»£ä½œç”¨ã€‚ ç”šè‡³äºæ–œç‡é¡¹çš„æ­£è´Ÿå·éƒ½å› ä¸ºè¿™ç§æ›¿ä»£ä½œç”¨è€Œå¯èƒ½æ˜¯é”™è¯¯çš„æ–¹å‘ã€‚\n1 2 #caråŒ…çš„vif()å‡½æ•°è®¡ç®—æ–¹å·®è†¨èƒ€å› å­ car::vif(lm3) ## disp hp drat ## 4.621988 2.868264 2.166843 éå‚æ•°å›å½’ æ‰€è°“å‚æ•°å›å½’ï¼Œ æ˜¯æŒ‡å›å½’å‡½æ•°æœ‰é¢„å…ˆç¡®å®šçš„å…¬å¼ï¼Œ ä»…éœ€è¦ä¼°è®¡çš„æœªçŸ¥å‚æ•°ï¼› éå‚æ•°å›å½’ï¼Œ å°±æ˜¯æ²¡æœ‰é¢„å…ˆç¡®å®šçš„å…¬å¼ï¼Œ çš„å½¢å¼æœ¬èº«ä¹Ÿä¾èµ–äºè¾“å…¥çš„æ ·æœ¬, ã€‚ ä¸‹é¢æè¿°çš„æ ¸å›å½’å°±æ˜¯è¿™æ ·å…¸å‹çš„éå‚æ•°å›å½’ï¼Œ æ ·æ¡å¹³æ»‘ã€æ ·æ¡å‡½æ•°å›å½’ä¸€èˆ¬ä¹Ÿçœ‹ä½œæ˜¯éå‚æ•°å›å½’ã€‚\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #æ ·æ¡å¹³æ»‘ set.seed(1) nsamp \u0026lt;- 30 x \u0026lt;- runif(nsamp, -10, 10) xx \u0026lt;- seq(-10, 10, length.out=100) x \u0026lt;- sort(x) y \u0026lt;- 10*sin(x/10*pi)^2 + rnorm(nsamp,0,0.3) plot(x, y) curve(10*sin(x/10*pi)^2, -10, 10, add=TRUE, lwd=2) library(splines) res \u0026lt;- smooth.spline(x, y) lines(spline(res$x, res$y), col=\u0026#34;red\u0026#34;) res2 \u0026lt;- loess(y ~ x, degree=2, span=0.3) lines(xx, predict(res2, newdata=data.frame(x=xx)), col=\u0026#34;blue\u0026#34;) legend(\u0026#34;top\u0026#34;, lwd=c(2,1,1), col=c(\u0026#34;black\u0026#34;, \u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;), legend=c(\u0026#34;real data\u0026#34;, \u0026#34;smooth.spline\u0026#34;, \u0026#34;local lm\u0026#34;)) 1 2 3 4 ## çº¿æ€§å¯åŠ æ¨¡å‹ ## Ræ‰©å±•åŒ…mgcvçš„gam()å‡½æ•°å¯ä»¥æ‰§è¡Œè¿™æ ·çš„å¯åŠ æ¨¡å‹çš„éå‚æ•°å›å½’æ‹Ÿåˆã€‚ lm.rock \u0026lt;- lm(log(perm) ~ area + peri + shape, data=rock) summary(lm.rock) ## ## Call: ## lm(formula = log(perm) ~ area + peri + shape, data = rock) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.8092 -0.5413 0.1734 0.6493 1.4788 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 5.33314499 0.54867792 9.720 1.59e-12 *** ## area 0.00048498 0.00008657 5.602 1.29e-06 *** ## peri -0.00152661 0.00017704 -8.623 5.24e-11 *** ## shape 1.75652601 1.75592362 1.000 0.323 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Residual standard error: 0.8521 on 44 degrees of freedom ## Multiple R-squared: 0.7483,\tAdjusted R-squared: 0.7311 ## F-statistic: 43.6 on 3 and 44 DF, p-value: 3.094e-13 1 2 gam.rock1 \u0026lt;- mgcv::gam(log(perm) ~ s(area) + s(peri) + s(shape), data=rock) summary(gam.rock1) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## log(perm) ~ s(area) + s(peri) + s(shape) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 5.1075 0.1222 41.81 \u0026lt;2e-16 *** ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(area) 1.000 1.000 29.13 0.00000307 *** ## s(peri) 1.000 1.000 71.30 \u0026lt; 2e-16 *** ## s(shape) 1.402 1.705 0.58 0.437 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## R-sq.(adj) = 0.735 Deviance explained = 75.4% ## GCV = 0.78865 Scale est. = 0.71631 n = 48 1 plot(gam.rock1) ##æ–¹å·®åˆ†æ\nå•å› ç´ æ–¹å·®åˆ†æå¯ä»¥çœ‹æˆåŸºç¡€ç»Ÿè®¡ä¸­ä¸¤æ ·æœ¬tæ£€éªŒçš„ä¸€ä¸ªæ¨å¹¿ï¼Œ è¦æ¯”è¾ƒè¯•éªŒè§‚æµ‹å€¼çš„æŸä¸ªå› å˜é‡ï¼ˆç§°ä¸ºâ€œæŒ‡æ ‡â€ï¼‰æŒ‰ç…§ä¸€ä¸ªåˆ†ç»„å˜é‡ï¼ˆç§°ä¸ºâ€œå› ç´ â€ï¼‰åˆ†ç»„åï¼Œ å„ç»„çš„å› å˜é‡å‡å€¼æœ‰æ— æ˜¾è‘—å·®å¼‚ã€‚\n1 2 3 mtcars$cyl=as.factor(mtcars$cyl) aov.manu \u0026lt;- aov(mpg ~ cyl, data=mtcars) summary(aov.manu) ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## cyl 2 824.8 412.4 39.7 0.00000000498 *** ## Residuals 29 301.3 10.4 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 1 pcutils::group_box(mtcars[\u0026#34;mpg\u0026#34;],group = \u0026#34;cyl\u0026#34;,metadata = mtcars) 1 2 #éå‚æ•°å½¢å¼ kruskal.test(mpg ~ cyl, data=mtcars) ## ## Kruskal-Wallis rank sum test ## ## data: mpg by cyl ## Kruskal-Wallis chi-squared = 25.746, df = 2, p-value = 0.000002566 è¿›è¡Œå¤šä¸ªå‡è®¾æ£€éªŒï¼ˆå¦‚å‡å€¼æ¯”è¾ƒï¼‰çš„æ“ä½œç§°ä¸º*â€œå¤šé‡æ¯”è¾ƒâ€*ï¼ˆmultiple comparisonï¼Œ æˆ–multiple testingï¼‰ï¼Œ å¤šæ¬¡æ£€éªŒä¼šä½¿å¾—æ€»ç¬¬ä¸€ç±»é”™è¯¯æ¦‚ç‡å¢å¤§ã€‚\n1 pcutils::multitest(mtcars$mpg,mtcars$cyl) ## ====================================1.ANOVA:==================================== ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## group 2 824.8 412.4 39.7 0.00000000498 *** ## Residuals 29 301.3 10.4 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ================================2.Kruskal.test:================================ ## ## Kruskal-Wallis rank sum test ## ## data: var by group ## Kruskal-Wallis chi-squared = 25.746, df = 2, p-value = 0.000002566 ## ## ==========================3.LSDtest, bonferroni p-adj:========================== ## var groups ## 4 26.66364 a ## 6 19.74286 b ## 8 15.10000 c ## ==================================4.tukeyHSD:================================== ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = var ~ group) ## ## $group ## diff lwr upr p adj ## 6-4 -6.920779 -10.769350 -3.0722086 0.0003424 ## 8-4 -11.563636 -14.770779 -8.3564942 0.0000000 ## 8-6 -4.642857 -8.327583 -0.9581313 0.0112287 ## ## =================================5.Wilcox-test:================================= ## 4 6 8 ## 4 1.00000000000 0.0006658148 0.00002774715 ## 6 0.00066581478 1.0000000000 0.00101304469 ## 8 0.00002774715 0.0010130447 1.00000000000 ##å¹¿ä¹‰çº¿æ€§æ¨¡å‹\næ³Šæ¾å›å½’ 1 2 3 4 5 6 counts \u0026lt;- c(18,17,15,20,10,20,25,13,12) outcome \u0026lt;- gl(3,1,9) treatment \u0026lt;- gl(3,3) D93=data.frame(treatment, outcome, counts) ## showing data ggplot(data = D93, mapping = aes(x = counts)) +geom_bar() 1 2 glm.D93 \u0026lt;- glm(counts ~ outcome + treatment,data = D93, family = poisson()) summary(glm.D93) ## ## Call: ## glm(formula = counts ~ outcome + treatment, family = poisson(), ## data = D93) ## ## Deviance Residuals: ## 1 2 3 4 5 6 7 8 ## -0.67125 0.96272 -0.16965 -0.21999 -0.95552 1.04939 0.84715 -0.09167 ## 9 ## -0.96656 ## ## Coefficients: ## Estimate Std. Error z value Pr(\u0026gt;|z|) ## (Intercept) 3.045e+00 1.709e-01 17.815 \u0026lt;2e-16 *** ## outcome2 -4.543e-01 2.022e-01 -2.247 0.0246 * ## outcome3 -2.930e-01 1.927e-01 -1.520 0.1285 ## treatment2 -3.242e-16 2.000e-01 0.000 1.0000 ## treatment3 -2.148e-16 2.000e-01 0.000 1.0000 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 10.5814 on 8 degrees of freedom ## Residual deviance: 5.1291 on 4 degrees of freedom ## AIC: 56.761 ## ## Number of Fisher Scoring iterations: 4 é€»è¾‘æ–¯è°›å›å½’ â€¦.\n","date":"2023-03-24T00:00:00Z","permalink":"/p/r-statistics/","title":"R-statistics"},{"content":"åœ¨Rblogdownä½¿ç”¨stack-themeé‡åˆ°äº†å‡ ä¸ªé—®é¢˜ï¼Œåº”è¯¥æ˜¯Rblogdownä¸åŸç”Ÿhugoé—´çš„ä¸å¤ªå…¼å®¹ã€‚\næˆ‘å¾ˆå¿«å‘ç°äº†é—®é¢˜æ˜¯Rmdäº§ç”Ÿçš„mdæ–‡ä»¶å¯èƒ½è·Ÿstackä¸»é¢˜ä¸å¤ªåŒ¹é…ï¼Œä¸€å¼€å§‹æƒ³çœ‹çœ‹yamlæ–‡ä»¶èƒ½ä¸èƒ½ä¿®æ”¹è§£å†³ï¼Œä½†æ‰¾äº†ä¸å°‘åœ°æ–¹éƒ½æ²¡æ‰¾åˆ°ğŸ˜­ã€‚\nå› ä¸ºé—®é¢˜è¿˜æ¯”è¾ƒç¡®å®šï¼Œå¯ä»¥è¯•è¯•è‡ªå·±å†™è„šæœ¬è½¬æ¢Rmdäº§ç”Ÿçš„mdæ–‡ä»¶ã€‚\nå…¬å¼é—®é¢˜ rblogdown æ¸²æŸ“Rmdæˆmdä¼šæŠŠæˆ‘å†™çš„å…¬å¼è¯­æ³•æ”¹å˜ï¼š\nä¾‹å¦‚ï¼š $a=sum_i^2$å˜æˆäº†\\(a=sum_i^2\\)\nä½†æ˜¯stackä¸»é¢˜è¯†åˆ«ä¸äº†åé¢é‚£ç§è¯­æ³•ï¼Œè¿™ä¸ªæ¯”è¾ƒç®€å•ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import re # å®šä¹‰ä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼ï¼ŒåŒ¹é…LaTeXæ•°å­¦å…¬å¼ä¸­çš„èµ·å§‹å’Œç»“æŸè¡Œå†…æ•°å­¦æ¨¡å¼ç¬¦å· pattern = r\u0026#39;\\\\\\((.*?)\\\\\\)\u0026#39; # å®šä¹‰ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ŒåŒ…å«è¦å¤„ç†çš„LaTeXå­—ç¬¦ä¸² latex_string = r\u0026#39;For the equation `\\(\\sum_{i=1}^n i^2\\)`\u0026#39; # ä½¿ç”¨sub()å‡½æ•°æ›¿æ¢åŒ¹é…åˆ°çš„æ–‡æœ¬ processed_string = re.sub(pattern, r\u0026#39;$\\1$\u0026#39;, latex_string) # è¾“å‡ºå¤„ç†åçš„å­—ç¬¦ä¸² print(processed_string) a=re.sub(r\u0026#39;`\\\\\\((.*?)\\\\\\)`\u0026#39;,r\u0026#39;$\\1$\u0026#39;,\u0026#34;`\\(a=sum_i^2\\)`jjjhg`\\(a=sum_i^2\\)`\u0026#34;) å›¾ç‰‡å¤§å°è°ƒæ•´ å› ä¸º![from data to viz website](images/data2viz.png){width=60%}è¿™ç§è¯­æ³•æ˜¯stackä¸»é¢˜ä¸æ”¯æŒçš„ï¼Œ ä½†æ˜¯\n1 2 3 \u0026#39;\u0026lt;p style=\u0026#34;text-align: center;\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;images/data2viz.png\u0026#34; width=\u0026#34;60%\u0026#34; title=\u0026#34;from data to viz website\u0026#34;/\u0026gt; \u0026lt;/p\u0026gt;\u0026#39; è¿™ç§è¯­æ³•æ˜¯æ”¯æŒçš„ï¼Œæ‰€ä»¥æƒ³å†™ä¸€ä¸ªå°è„šæœ¬è½¬æ¢ä¸€ä¸‹\nè‡ªå·±ä¸å¤ªç†Ÿæ‚‰æ­£åˆ™ï¼ˆä¸Šé¢é‚£ä¸ªå…¬å¼è½¬æ¢çš„ä¹Ÿæ˜¯ä»–å¸®æˆ‘å†™çš„ï¼Œå“ˆå“ˆï¼‰ï¼Œæ‰€ä»¥è¯•è¯•é—®äº†ChatGPT ï¼š\nå¯ä»¥å¸®æˆ‘å†™ä¸€ä¸ªå°†æ’å…¥å›¾ç‰‡çš„markdownè¯­æ³•è½¬æ¢ä¸ºhtmlè¯­æ³•çš„å°è„šæœ¬å—ï¼Ÿ æ¯”å¦‚ï¼š![A](B.png){width=60%}è½¬æ¢ä¸º\u0026lt;img src=\u0026quot;B.png\u0026quot; width=\u0026quot;60%\u0026quot; title=\u0026quot;A\u0026quot;/\u0026gt;\nå®ƒç«‹é©¬ç”¨pythonå¸®æˆ‘å†™äº†ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 import re def convert_markdown_to_html(markdown_text): # å°†æ’å…¥å›¾ç‰‡çš„Markdownè¯­æ³•è½¬æ¢ä¸ºHTMLè¯­æ³• pattern = r\u0026#34;!\\[(.*?)\\]\\((.*?)\\){(.*?)}\u0026#34; matches = re.findall(pattern, markdown_text) for match in matches: title = match[0] src = match[1] attributes = match[2].split(\u0026#34;,\u0026#34;) attr_dict = dict([tuple(attribute.split(\u0026#34;=\u0026#34;)) for attribute in attributes]) html_tag = f\u0026#39;\u0026lt;img src=\u0026#34;{src}\u0026#34; title=\u0026#34;{title}\u0026#34;\u0026#39; for key, value in attr_dict.items(): html_tag += f\u0026#39; {key}=\u0026#34;{value}\u0026#34;\u0026#39; html_tag += \u0026#34;/\u0026gt;\u0026#34; markdown_text = markdown_text.replace(f\u0026#34;![{title}]({src}){{{match[2]}}}\u0026#34;, html_tag) return markdown_text def convert_latex_to_md(markdown_text): html_text=re.sub(r\u0026#39;`\\\\\\((.*?)\\\\\\)`\u0026#39;,r\u0026#39;$\\1$\u0026#39;,markdown_text) return html_text def convert_markdown_file_to_html(file_path): # è¯»å–Markdownæ–‡ä»¶ with open(file_path, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: markdown_text = f.read() # å°†Markdownè¯­æ³•è½¬æ¢ä¸ºHTMLè¯­æ³• html_text = convert_markdown_to_html(markdown_text) html_text = convert_latex_to_md(html_text) # å°†HTMLæ–‡æœ¬å†™å…¥æ–‡ä»¶ with open(file_path, \u0026#34;w\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.write(html_text) if __name__ == \u0026#34;__main__\u0026#34;: file_path = \u0026#34;index.md\u0026#34; convert_markdown_file_to_html(file_path) ç‰›ç‰›ç‰›ï¼ å†é—®ä¸€ä¸‹ï¼Œå¯ä»¥ç”¨Rè¯­è¨€å†™ä¸€ä¸‹å—ï¼Ÿ\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 convert_markdown_to_html \u0026lt;- function(markdown_text) { # é€šè¿‡æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å›¾ç‰‡è¯­æ³• matches \u0026lt;- gregexpr(\u0026#34;!\\\\[(.*?)\\\\]\\\\((.*?)\\\\){(.*?)}\u0026#34;, markdown_text, perl = TRUE) # éå†åŒ¹é…ç»“æœï¼Œå°†Markdownè¯­æ³•æ›¿æ¢ä¸ºHTMLè¯­æ³• for (i in seq_along(matches[[1]])) { # åˆ¤æ–­åŒ¹é…ç»“æœæ˜¯å¦ä¸ºç©ºåˆ—è¡¨ if (length(matches[[1]][i]) == 0) { next } match \u0026lt;- regmatches(markdown_text, matches[[1]][i]) title \u0026lt;- match[[2]] src \u0026lt;- match[[3]] attributes \u0026lt;- strsplit(match[[4]], \u0026#34;,\u0026#34;)[[1]] attr_dict \u0026lt;- setNames(sapply(strsplit(attributes, \u0026#34;=\u0026#34;), \u0026#34;[\u0026#34;, 2), sapply(strsplit(attributes, \u0026#34;=\u0026#34;), \u0026#34;[\u0026#34;, 1)) # æ„é€ HTMLæ ‡ç­¾ html_tag \u0026lt;- sprintf(\u0026#39;\u0026lt;img src=\u0026#34;%s\u0026#34; title=\u0026#34;%s\u0026#34;\u0026#39;, src, title) for (key in names(attr_dict)) { value \u0026lt;- attr_dict[[key]] html_tag \u0026lt;- paste(html_tag, sprintf(\u0026#39;%s=\u0026#34;%s\u0026#34;\u0026#39;, key, value), sep = \u0026#34; \u0026#34;) } html_tag \u0026lt;- paste(html_tag, \u0026#34;/\u0026gt;\u0026#34;, sep = \u0026#34;\u0026#34;) # å°†Markdownè¯­æ³•æ›¿æ¢ä¸ºHTMLè¯­æ³• markdown_text \u0026lt;- sub(\u0026#34;!\\\\[(.*?)\\\\]\\\\((.*?)\\\\){(.*?)}\u0026#34;, html_tag, markdown_text, fixed = TRUE) } return(markdown_text) } markdown_text \u0026lt;- \u0026#34;![A](B.png){width=60%}\u0026#34; html_text \u0026lt;- convert_markdown_to_html(markdown_text) print(html_text) å”‰ï¼Œå®é™…ä¸Šè¿™ä¸ªä»£ç æ²¡æœ‰ç”¨ï¼Œæˆ‘ä¹Ÿä¸çŸ¥é“bugæ€ä¹ˆæï¼ŒRçš„æ­£åˆ™è¡¨è¾¾å¼ä¸€ç›´æ„Ÿè§‰æ²¡æœ‰pythonå¥½ç”¨ã€‚\nè¿˜æ˜¯ç”¨å†™å¥½çš„pythonè„šæœ¬å§ã€‚\nä¿®æ”¹æ–°çš„mdæ–‡ä»¶ æˆ‘ä»¬è¿˜éœ€è¦æ‰¾åˆ°æœ€æ–°renderå‡ºæ¥çš„mdæ–‡ä»¶æŒ‰ä¸Šè¿°è§„åˆ™è¿›è¡Œä¿®æ”¹ï¼ˆå¦åˆ™ä¸€å£æ°”æ”¹å…¨éƒ¨çš„è¯ï¼Œå®³æ€•ä¼šè¶Šæ¥è¶Šæ…¢ï¼Œç”šè‡³æŸåä»¥å‰çš„mdæ–‡ä»¶ï¼‰ï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import os import datetime # å®šä¹‰è¦æŸ¥æ‰¾çš„ç›®å½• directory = \u0026#39;./content/post/\u0026#39; # å­˜å‚¨æ‰€æœ‰çš„mdæ–‡ä»¶ md_files = [] # é€’å½’æŸ¥æ‰¾ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ for root, dirs, files in os.walk(directory): for file in files: if file.endswith(\u0026#39;.md\u0026#39;): file_path = os.path.join(root, file) md_files.append((file_path, os.path.getmtime(file_path))) # æ‰¾åˆ°æœ€æ–°ä¿®æ”¹çš„æ–‡ä»¶ latest_file = max(md_files, key=lambda x: x[1])[0] print(\u0026#34;æœ€æ–°ä¿å­˜çš„.mdæ–‡ä»¶æ˜¯ï¼š\u0026#34;, latest_file) å†é—®é—®ï¼Œå¯ä»¥æ‰¾åˆ°ç›®å½•ä¸‹æ‰€æœ‰æ–°ä¿å­˜çš„.mdæ–‡ä»¶å—ï¼Œå°±æ˜¯ä¿®æ”¹æ—¶é—´ä¸ä¸Šæ¬¡ä¸ä¸€è‡´çš„ï¼Ÿ\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 import os import datetime # å®šä¹‰è¦æŸ¥æ‰¾çš„ç›®å½• directory = \u0026#39;./content/\u0026#39; # å­˜å‚¨æ‰€æœ‰æ–°ä¿å­˜çš„mdæ–‡ä»¶ new_md_files = [] # è¯»å–ä¸Šä¸€æ¬¡æ£€æŸ¥çš„æ—¶é—´æˆ³ if os.path.isfile(\u0026#39;last_check_time.txt\u0026#39;): with open(\u0026#39;last_check_time.txt\u0026#39;, \u0026#39;r\u0026#39;) as f: last_check_time = datetime.datetime.strptime(f.read(), \u0026#39;%Y-%m-%d %H:%M:%S.%f\u0026#39;) else: last_check_time = datetime.datetime.now() # é€’å½’æŸ¥æ‰¾ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ for root, dirs, files in os.walk(directory): for file in files: if file.endswith(\u0026#39;.md\u0026#39;): file_path = os.path.join(root, file) mod_time = datetime.datetime.fromtimestamp(os.path.getmtime(file_path)) if mod_time \u0026gt; last_check_time: new_md_files.append(file_path) # æ›´æ–°ä¸Šä¸€æ¬¡æ£€æŸ¥çš„æ—¶é—´æˆ³ last_check_time = datetime.datetime.now() # å°†ä¸Šä¸€æ¬¡æ£€æŸ¥çš„æ—¶é—´æˆ³ä¿å­˜åˆ°æ–‡ä»¶ä¸­ with open(\u0026#39;last_check_time.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: f.write(last_check_time.strftime(\u0026#39;%Y-%m-%d %H:%M:%S.%f\u0026#39;)) # æ‰“å°æ‰€æœ‰æ–°ä¿å­˜çš„mdæ–‡ä»¶ for file_path in new_md_files: print(\u0026#34;æ–°ä¿å­˜çš„.mdæ–‡ä»¶ï¼š\u0026#34;, file_path) #æ›´æ–°æ‰€æœ‰æ–°ä¿å­˜çš„mdæ–‡ä»¶ for file_path in new_md_files: convert_markdown_file_to_html(latest_file) è¿™ä¸ªæ€è·¯çœŸä¸é”™ï¼Œå“ˆå“ˆ\nè§£å†³æ–¹æ³• è°ƒæ•™äº†ä¸€ä¸‹ChatGPTåï¼Œå°±å¾—åˆ°äº†æ•´ä¸ªæ›´æ–°é—®é¢˜çš„æ–¹æ³•äº†ï¼š é¦–å…ˆæ•´ç†ä¸€ä¸ªrefresh_md_to_fit_stack.pyæ”¾åœ¨ç½‘ç«™æ ¹ç›®å½•ä¸‹ï¼Œ ç„¶ååœ¨Ræ–‡ä»¶å¤¹çš„ï¼ˆå¦‚æœä½ æ˜¯ç”¨Rblogdownç”Ÿæˆçš„ç½‘ç«™ï¼Œé‚£å°±ä¼šæœ‰è¿™ä¸ªæ–‡ä»¶å¤¹ï¼‰çš„build2.Rä¸­åŠ å…¥ä¸€è¡Œï¼š\nsystem(\u0026quot;python refresh_md_to_fit_stack.py\u0026quot;)\nå³å¯ã€‚ å› ä¸ºRblogdownä¼šåœ¨æ¯æ¬¡å®æ—¶æ¸²æŸ“æˆ‘ä»¬çš„ç½‘ç«™åè¿è¡Œbuild2.Ræ–‡ä»¶ï¼Œç›¸å½“äºè¿è¡Œäº†refresh_md_to_fit_stack.pyæ–‡ä»¶ï¼Œè€Œrefresh_md_to_fit_stack.pyæ–‡ä»¶å°†æœç´¢æ‰€æœ‰æ›´æ–°çš„mdæ–‡ä»¶å¹¶ä¿®æ”¹ä»¥ä¸Šä¸¤ä¸ªé—®é¢˜ï¼Œè¿™æ ·hugoå»ºç«‹çš„ç½‘ç«™å°±èƒ½å¤Ÿå¥‘åˆstack-themeã€‚\nçœ‹çœ‹ç»“æœï¼š å¦‚æœè°ƒè¯•æˆåŠŸçš„è¯ï¼Œä¸‹é¢æ˜¾ç¤ºçš„å³æ˜¯æ­£å¸¸çš„latexå…¬å¼:\n$y=\\frac{1}{2} $\nå¦‚æœä¸æ˜¯ä½¿ç”¨çš„Rblogdownç”Ÿæˆçš„ç½‘ç«™ï¼Œè¿™ç§æ€è·¯çš„æ–¹æ³•ä¹Ÿå¯ä»¥å¸®åŠ©æ”¹å˜stack-themeã€‚\næ­¤å¤–ï¼Œå¦‚æœæ˜¯Rblogdownç”Ÿæˆçš„å…¶ä»–ä¸»é¢˜çš„ç½‘ç«™æœ‰ç±»ä¼¼é—®é¢˜ï¼Œä¹Ÿå¯ä»¥è¿™æ ·ä¿®æ”¹ã€‚\næœ€åï¼ŒChatGPTçœŸä¸é”™ï¼å†æ¥ä¸€ä¸ªæ”»ç•¥\n","date":"2023-03-23T00:00:00Z","image":"/p/chatgpt-stack/ChatGPT_huce8d906dd473ab038e4f784f810328ac_7886_120x120_fill_q75_box_smart1.jpg","permalink":"/p/chatgpt-stack/","title":"ChatGPTå¸®æˆ‘è°ƒæ•´stackä¸»é¢˜"},{"content":"Introduction Zhou, J. \u0026amp; Ning, D. Stochastic Community Assembly: Does It Matter in Microbial Ecology? Microbiol Mol Biol Rev 81, e00002-17 (2017). This review is very comprehensive (1)ï¼\nå‘¨é›†ä¸­è€å¸ˆå®éªŒå®¤çš„é•¿æœŸç ”ç©¶å…´è¶£é›†ä¸­åœ¨ä»åŸºå› ç»„åˆ°ç”Ÿæ€ç³»ç»Ÿçš„ä¸åŒç»„ç»‡å±‚é¢çš„ç¯å¢ƒå¾®ç”Ÿç‰©å­¦ï¼Œå…¶ä¸­ä¸€é¡¹å°±æ˜¯å®åŸºå› ç»„å­¦å’Œå¾®ç”Ÿç‰©ç”Ÿæ€å­¦ï¼šåˆ©ç”¨é«˜é€šé‡åŸºå› ç»„æµ‹åºå’Œç›¸å…³åŸºå› ç»„å­¦æŠ€æœ¯æ£€æŸ¥ä¸åŒæ –æ¯åœ°çš„å¾®ç”Ÿç‰©ç¾¤è½å¤šæ ·æ€§ã€å¾®ç”Ÿç‰©ç”Ÿç‰©åœ°ç†å­¦å’Œå½¢æˆå¾®ç”Ÿç‰©å¤šæ ·æ€§æ¨¡å¼ã€åˆ†å¸ƒå’ŒåŠ¨æ€çš„æœºåˆ¶ï¼›\nUnderstanding the mechanisms controlling community diversity, functions, succession, and biogeography is a central, but poorly understood, topic in ecology, particularly in microbial ecology. Traditional niche-based theory hypothesizes that deterministic factors such as species traits, inter-species interactions (e.g., competition, predation, mutualisms, and trade-offs), and environmental conditions (e.g., pH, temperature, salt, and moisture) govern community structure, which are often referred to as deterministic processes.\nIn contrast, neutral theory assumes that community structures are independent of species traits and governed by stochastic processes of birth, death, colonization, extinction, and speciation.\nAlthough, recently, it has been generally accepted that both deterministic and stochastic processes occur simultaneously in the assembly of local communities, a central debate is on their relative importance in controlling community structure, succession, and biogeography.\nMethods ç›®å‰åœ¨æ–‡ç« ä¸­æ™®éå‡ºç°çš„è®¡ç®—ç¾¤è½æ„å»ºçš„æ–¹æ³•ä¸»è¦æœ‰ä¸‰å¥—ï¼š\n1.Stegen ï¼ˆÎ²NTI \u0026amp; RCbray-basedï¼‰ åŸå§‹çš„æ–‡ç«  (2), (3)\nåœ¨ç¡®å®šæ€§ä¸éšæœºæ€§äºŒåˆ†æ³•çš„èƒŒæ™¯ä¸‹å¡‘é€ å¾®ç”Ÿç‰©ç¾¤è½å¤šæ ·æ€§çš„ç”Ÿæ€è¿‡ç¨‹ã€‚è¯¥æ–¹æ¡ˆæ˜¾ç¤ºäº†åœ¨æ–‡ä¸­è®¨è®ºçš„å‡è®¾ä¸‹ï¼ŒåŸºäºç³»ç»Ÿå‘è‚²å’Œåˆ†ç±»å¤šæ ·æ€§åˆ’åˆ†å„ç§ç”Ÿæ€è¿‡ç¨‹çš„ä¸åŒæ­¥éª¤ã€‚ NTIï¼ˆæœ€è¿‘åˆ†ç±»å•å…ƒæŒ‡æ•°ï¼‰åŸºäºç³»ç»Ÿå‘è‚²å¤šæ ·æ€§æŒ‡æ•° MNTDï¼ˆå¹³å‡æœ€è¿‘åˆ†ç±»å•å…ƒè·ç¦»ï¼‰çš„ç©ºæ¨¡å‹æ£€éªŒï¼ŒRCBrayï¼ˆä¿®æ­£çš„ Raup-Crick æŒ‡æ•°ï¼‰åŸºäº Bray-Curtis çš„ç©ºæ¨¡å‹æ£€éªŒåˆ†ç±»å¤šæ ·æ€§æŒ‡æ•°ã€‚è¿™ä¸¤ä¸ªæ¡†åˆ†åˆ«è¡¨ç¤ºç¡®å®šæ€§é€‰æ‹©å’Œæœªæ”¯é…éƒ¨åˆ†çš„ä¸»è¦ç»„æˆéƒ¨åˆ†ã€‚é™¤äº†å½±å“è¾ƒå°çš„é€‰æ‹©å¤–ï¼Œæœªæ”¯é…éƒ¨åˆ†çš„å¼±é€‰æ‹©ä¹Ÿå¯èƒ½æ˜¯ç”±äºæŠµæ¶ˆäº†æœ‰å½±å“çš„é€‰æ‹©å› ç´ å’Œ/æˆ–ä¸åŒåˆ†ç±»ç¾¤çš„å¯¹æ¯”é€‰æ‹©ã€‚è¯¥å›¾ä¸»è¦æ˜¯æ ¹æ® Stegen ç­‰äººå…ˆå‰æŠ¥å‘Šçš„æ•°æ®åˆ¶ä½œçš„ã€‚\nbeta-NTIï¼ˆnearest taxon indexï¼‰ï¼š ä½¿ç”¨ NTI/NRI æŒ‡ç¤ºå•ä¸ªç¾¤è½å†…å…±å­˜çš„åˆ†ç±»å•å…ƒç›¸æ¯”å¶ç„¶é¢„æœŸçš„å…³ç³»æ›´ä¸ºç´§å¯†è¿˜æ˜¯åˆ†æ•£ï¼Œä½¿ç”¨ Î²NTI/Î²NRI æŒ‡ç¤ºä¸¤ä¸¤ç¾¤è½é—´çš„å˜åŒ–å—ç¡®å®šæ€§æˆ–éšæœºæ€§å› ç´ å½±å“çš„å¤§å°ã€‚ MNTD å³mean-nearest-taxon-distance (æœ€è¿‘ç§é—´å¹³å‡è¿›åŒ–è·ç¦») ï¼Œ å…³äº NTI/NRIã€Î²NTI/Î²NRI çš„ç»“æœè§£é‡Šæ—¶å…¶æ˜¾è‘—æ€§çš„åˆ¤æ–­ä¾æ®æ˜¯å…¶ä¸´ç•Œå€¼æ˜¯å¦å¤§äº|2|ï¼Œå®é™…ä¸Šè¿™æ˜¯ä¾æ®æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„ 95%ç½®ä¿¡åŒºé—´å¾—åˆ°çš„ï¼Œä¸€èˆ¬è®¤ä¸º NRI æˆ–è€… NTI å¤§äº 1.96 æˆ–è€…å°äº-1.96 çš„ç»“æœï¼Œåœ¨ 95%çš„æ°´å¹³æ˜¯æ˜¾è‘—çš„ã€‚\nRCbray: ç›¸å¼‚æŒ‡æ•°çš„ä¸€ç§ã€‚\ncode https://blog.csdn.net/weixin_43367441/article/details/118515090\néå¸¸é‡è¦çš„ä¸€ç‚¹ï¼šè¿™ç±»æ–¹æ³•æ˜¯åŸºäºç³»ç»Ÿå‘è‚²æ ‘æ¨æ–­çš„ï¼Œæ‰€ä»¥ä¸€å®šè¦æœ‰è·Ÿtaxè¡¨å¯¹åº”çš„ç³»ç»Ÿå‘è‚²æ ‘ã€‚ ä½†äº‹å®ä¸Šï¼Œé™¤éç”¨çš„æ˜¯16S/ITSæµ‹åºï¼Œå¦åˆ™æˆ‘ä»¬å¾ˆéš¾ç»™è‡ªå·±çš„æ•°æ®å»ºä¸€ä¸ªæ ‘ã€‚ æ‰€ä»¥ï¼Œæ›¿ä»£æ–¹æ³•æ˜¯åˆ©ç”¨é˜¶å±‚åˆ†ç±»å…³ç³»ï¼ˆç•Œé—¨çº²ç›®ç§‘å±ç§ï¼‰æ¥åšä¸€ä¸ªæ‹Ÿç³»ç»Ÿå‘è‚²æ ‘ï¼ˆæé•¿éƒ½ä¸º1ï¼‰ å‚è§è‡ªå·±å†™çš„df2treeå‡½æ•°\n1 2 3 4 5 data(otutab) df2tree(taxonomy)-\u0026gt;phylo #è®¡ç®— nti_rc(otutab,phylo,metadata[,\u0026#34;Group\u0026#34;,drop=F])-\u0026gt;nti_res ## [1] \u0026quot;Result saved as nti_rc_res.rda\u0026quot; 1 2 3 4 5 #å¯è§†åŒ– nti_res$type=factor(nti_res$type,levels = c(\u0026#34;Homo_S\u0026#34;,\u0026#34;Heter_S\u0026#34;,\u0026#34;Homo_D\u0026#34;,\u0026#34;D_limit\u0026#34;,\u0026#34;Undominated\u0026#34;)) table(nti_res$type,nti_res$variable)%\u0026gt;%reshape2::melt()-\u0026gt;com_p colnames(com_p)=c(\u0026#34;type\u0026#34;,\u0026#34;variable\u0026#34;,\u0026#34;n\u0026#34;) ggplot(com_p,aes(x=variable,y=n))+geom_bar(stat = \u0026#34;identity\u0026#34;,aes(fill=type),position = \u0026#34;fill\u0026#34;) iCAMP ç°åœ¨å¤§å®¶ç»å¸¸ç”¨çš„iCAMPåŒ…å°±æ˜¯åŸºäºè¿™ä¸ªç†è®ºæ¡†æ¶è¿›è¡Œåˆ†æçš„ (4)ã€‚\n2.STï¼ŒNSTï¼ŒMST ï¼ˆstochasticity ratioï¼‰ PNASï¼šNSTæ–¹æ³•å®šé‡ç”Ÿæ€è¿‡ç¨‹ä¸­çš„éšæœºæ€§\nå‘¨è€å¸ˆçš„æ–‡ç« ï¼Œå¼€å‘å‡ºæ–°çš„æ–¹æ³•å¯¹ç”Ÿæ€è¿‡ç¨‹ä¸­çš„éšæœºæ€§è¿›è¡Œäº†å®šé‡ã€‚æå‡ºäº†ä¸€ä¸ªæ–°çš„æŒ‡æ•°ï¼Œnormalized stochasticity ratio (NST)ï¼Œä½œä¸ºç¡®å®šæ€§ä¸»å¯¼ï¼ˆdeterministic, \u0026lt;50%ï¼‰å’Œéšæœºæ€§ä¸»å¯¼ï¼ˆstochastic, \u0026gt;50%ï¼‰çš„è¾¹ç•Œç‚¹ (5)ã€‚\ncode å·²ç»æœ‰ç›¸åº”çš„åŒ…äº†,NST\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #install.packages(\u0026#34;NST\u0026#34;) library(NST) data(tda) comm=tda$comm bray=beta.g(comm,dist.method=\u0026#34;bray\u0026#34;) bray.3col=dist.3col(bray) group=tda$group tnst=tNST(comm=comm, group=group, rand=20, output.rand=TRUE, nworker=1) #æ£€éªŒå„ç»„STã€NSTçš„åˆ†å¸ƒæƒ…å†µåŠå„ç»„STã€NSTå·®å¼‚çš„æ˜¾è‘—æ€§ã€‚ nst.bt=nst.boot(nst.result=tnst, group=NULL, rand=99, trace=TRUE, two.tail=FALSE, out.detail=FALSE, between.group=FALSE, nworker=1) #STå’ŒNSTç»„é—´è¿›è¡ŒPermutational multivariate ANOVA nst.pova=nst.panova(nst.result=tnst, rand=99) #å¯è§†åŒ– pcutils::group_box(tnst$index.pair.grp,col = 8,group = tnst$index.pair.grp$group) example åœ°ä¸‹æ°´å¾®ç”Ÿç‰©ç¾¤è½æ¼”æ›¿è¿‡ç¨‹ä¸­ä¼°è®¡çš„ NST åŠ¨æ€å˜åŒ–å¯¹ä¹³åŒ–æ¤ç‰©æ²¹æ³¨å…¥çš„å“åº”ã€‚ NST æ˜¯åŸºäº (A) Jaccard å’Œ (B) Ru ziË‡ cka æŒ‡æ ‡ä½¿ç”¨ç©ºæ¨¡å‹ç®—æ³• PF è®¡ç®—çš„ã€‚åœ¨é›¶æ¨¡å‹ PF ä¸­ï¼Œç±»ç¾¤å‘ç”Ÿçš„æ¦‚ç‡ä¸è§‚å¯Ÿåˆ°çš„å‘ç”Ÿé¢‘ç‡æˆæ­£æ¯”ï¼Œå¹¶ä¸”æ¯ä¸ªæ ·æœ¬ä¸­çš„ç±»ç¾¤ä¸°å¯Œåº¦æ˜¯å›ºå®šçš„ï¼ˆ19ï¼‰ã€‚å½“ä½¿ç”¨åŸºäºä¸°åº¦çš„æŒ‡æ ‡ Ru ziË‡ cka æ—¶ï¼Œæ¯ä¸ªæ ·æœ¬ä¸­çš„ç©ºåˆ†ç±»ç¾¤ä¸°åº¦è¢«è®¡ç®—ä¸ºè§‚å¯Ÿåˆ°çš„ä¸ªä½“æ•°é‡çš„éšæœºæŠ½å–ï¼Œå…¶æ¦‚ç‡ä¸æ ·æœ¬ä¸­ç©ºåˆ†ç±»ç¾¤çš„åŒºåŸŸç›¸å¯¹ä¸°åº¦æˆæ¯”ä¾‹ï¼ˆ26ï¼‰ã€‚ W8 æ˜¯æ¤ç‰©æ²¹å¯¹å…¶æ²¡æœ‰å½±å“æˆ–å½±å“æœ€å°çš„å¯¹ç…§äº•ã€‚\n3.Solan NCM åªæœ‰å½“ç‰©ç§æ­»äº¡æˆ–ç¦»å¼€è¿™ä¸ªç³»ç»Ÿæ—¶ï¼Œç¾¤è½ç»“æ„æ‰ä¼šå‘ç”Ÿæ”¹å˜ã€‚æ­¤æ—¶ï¼Œç¦»å¼€ä¸ªä½“çš„ç”Ÿæ€ä½å°±ä¼šç©ºä½™å‡ºæ¥ï¼Œå…¶å®ƒä¸ªä½“ä¼šé€šè¿‡æ¥è‡ªç¾¤è½å¤–çš„è¿ç§»æˆ–ç¾¤è½å†…éƒ¨çš„ç¹æ®–æ¥å¡«è¡¥ç©ºå‡ºçš„ç”Ÿæ€ä½ã€‚å› æ­¤å¯ä»¥æŠŠç¾¤è½çš„åŠ¨æ€æè¿°ä¸ºæ­»äº¡â€”â€”ç¹æ®–/æ‰©æ•£â€”â€”æ­»äº¡è¿™æ ·çš„å¾ªç¯ (6)ã€‚\nè®¡ç®—å…¬å¼ï¼š\n-$Pr(\\frac{N_i+1}{N_i})=(\\frac{N_T-N_i}{N_T})[mp_i+(1+\\alpha_i)(1-m)(\\frac{N_i}{N_T-1})$ -$Pr(\\frac{N_i}{N_i})=\\frac{N_i}{N_T}[mp_i+{(1+\\alpha_i)}(1-m)(\\frac{N_i-1}{N_T-1})]+(\\frac{N_T-N_i}{N_T})[m(1-p_i)+{red}{(1-\\alpha_i)}(1-m)(\\frac{N_T-N_i-1}{N_T-1})]$ -$Pr(\\frac{N_i-1}{N_i})=\\frac{N_i}{N_T}[m(1-p_i)+(1-\\alpha_i)(1-m)(\\frac{N_T-N_i}{N_T-1})]$\nç‰©ç§ i å å±…çš„é¢‘ç‡ï¼ˆoccurrence frequency: row sums of binary OTU table/number of sitesï¼‰ä¸ºå…¶æ¦‚ç‡å¯†åº¦å‡½æ•°çš„ç§¯åˆ†ã€‚ æ­¤æ—¶è¯¥åˆ†å¸ƒæ˜¯ä¸€ä¸ªbetaåˆ†å¸ƒï¼Œæˆ‘ä»¬å°±å¯ä»¥åœ¨Rè¯­è¨€ä¸­åˆ©ç”¨betaåˆ†å¸ƒå¯¹å…¶è¿›è¡Œ[æ‹Ÿåˆ]ï¼Œè·å¾—å‚æ•°mçš„è¯„ä¼°å€¼ã€‚\ncode 1 2 3 4 library(devtools) install_github(\u0026#34;Russel88/MicEco\u0026#34;) library(MicEco) neutral.fit(t(otutab))#ä½¿ç”¨çš„æ˜¯æœ€å¤§ä¼¼ç„¶ä¼°è®¡æ‹Ÿåˆæ¨¡å‹ï¼ŒR2è®¡ç®—æ–¹æ³•ä¹Ÿä¸åŒ å¦ä¸€ä¸ªä»£ç æ¥è‡ªhttps://mp.weixin.qq.com/s/opFXl-TvkJfmPcWKFwhCFAï¼Œæ¯”è¾ƒç»å…¸ï¼Œç”¨çš„æ˜¯éçº¿æ€§æ¨¡å‹:\nNæè¿°äº†å®ç¾¤è½è§„æ¨¡ï¼ˆmetacommunity sizeï¼‰ï¼Œåœ¨æœ¬æ–‡ä¸­ä¸ºæ¯ä¸ªæ ·æœ¬ä¸­æ‰€æœ‰OTUçš„æ€»ä¸°åº¦ã€‚ mé‡åŒ–äº†ç¾¤è½å±‚é¢çš„è¿ç§»ç‡ï¼ˆmigration rateï¼‰ï¼Œè¯¥å€¼å¯¹äºæ¯ä¸ªç¾¤è½æˆå‘˜éƒ½æ˜¯ç»Ÿä¸€çš„ï¼ˆä¸ç‰©ç§æ— å…³ï¼‰ï¼Œmå€¼è¶Šå°è¯´æ˜æ•´ä¸ªç¾¤è½ä¸­ç‰©ç§æ‰©æ•£è¶Šå—é™åˆ¶ï¼Œåä¹‹må€¼è¶Šé«˜åˆ™è¡¨æ˜ç‰©ç§å—åˆ°æ‰©æ•£é™åˆ¶è¶Šä½ã€‚ Nmæ˜¯å…ƒç¾¤è½è§„æ¨¡ï¼ˆNï¼‰ä¸è¿ç§»ç‡ï¼ˆmï¼‰çš„ä¹˜ç§¯ (Nm = N*m)ï¼Œé‡åŒ–äº†å¯¹ç¾¤è½ä¹‹é—´æ‰©æ•£çš„ä¼°è®¡ï¼Œå†³å®šäº†å‘ç”Ÿé¢‘ç‡å’ŒåŒºåŸŸç›¸å¯¹ä¸°åº¦ä¹‹é—´çš„ç›¸å…³æ€§ã€‚\nè‡ªå·±çš„ç»˜å›¾ä»£ç ï¼š\n1 2 3 data(otutab) ncm(otutab)-\u0026gt;ncm_res plot(ncm_res) R2ä»£è¡¨äº†ä¸­æ€§ç¾¤è½æ¨¡å‹çš„æ•´ä½“æ‹Ÿåˆä¼˜åº¦ï¼ŒR2è¶Šé«˜è¡¨æ˜è¶Šæ¥è¿‘ä¸­æ€§æ¨¡å‹ï¼Œå³ç¾¤è½çš„æ„å»ºå—éšæœºæ€§è¿‡ç¨‹çš„å½±å“è¶Šå¤§ï¼Œå—ç¡®å®šæ€§è¿‡ç¨‹çš„å½±å“è¶Šå°ã€‚\nå€¼å¾—æ³¨æ„ï¼ŒRæ–¹ä¸æ˜¯æŸä¸ªæ•°å€¼çš„å¹³æ–¹ï¼Œå¯ä»¥æ˜¯è´Ÿå€¼ã€‚å› ä¸ºæ‹Ÿåˆç¨‹åº¦æ²¡æœ‰ä¸‹é™ï¼Œå¯ä»¥æ— é™å·®ï¼ŒRæ–¹çš„èŒƒå›´æ˜¯(âˆ’âˆ,1]ã€‚Ræ–¹çš„å–å€¼ï¼Œæœ‰ä»¥ä¸‹çš„å¯èƒ½æ€§ï¼š\nç­‰äº1ã€‚ç†æƒ³çŠ¶å†µï¼Œè¯¥æ¨¡å‹å¯¹æ‰€æœ‰çš„çœŸå€¼é¢„æµ‹å‡†ç¡®ï¼Œæ²¡æœ‰åå·®ã€‚æ³¼ä¸ªå†·æ°´ï¼Œå¦‚æœæŸç¯‡æ–‡ç« é‡Œå‡ºç°äº†Ræ–¹=1ï¼Œè¦ä¹ˆæ˜¯é—®é¢˜è¿‡äºç®€å•æ²¡æœ‰ç ”ç©¶ä»·å€¼ï¼Œè¦ä¹ˆæ˜¯æ¨¡å‹è¿‡äºå¤æ‚ï¼Œå¯¹æ•°æ®è¿›è¡Œäº†è¿‡åº¦æ‹Ÿåˆã€‚\nå°äº1å¤§äº0ã€‚è¿™æ˜¯å¸¸è§çŠ¶å†µï¼Œè¡¨æ˜è¯¥æ¨¡å‹çš„æ‹Ÿåˆæ°´å¹³æ¯”å‡å€¼æ¨¡å‹å¥½ã€‚\nç­‰äº0ã€‚è¯¥æ¨¡å‹çš„æ‹Ÿåˆæ°´å¹³æ¥è¿‘äºå‡å€¼æ¨¡å‹ã€‚è¯¥æ¨¡å‹æ²¡æœ‰ä»·å€¼ã€‚\nå°äº0ã€‚è¯¥æ¨¡å‹çš„æ‹Ÿåˆæ°´å¹³ä¸å¦‚å‡å€¼æ¨¡å‹ã€‚åŒæ ·ï¼Œè¯¥æ¨¡å‹æ²¡æœ‰ä»·å€¼ã€‚\nexample **éšæœºè¿‡ç¨‹ï¼Œä¾‹å¦‚æ•£å¸ƒã€å‡ºç”Ÿã€æ­»äº¡ã€ç­ç»å’Œç§»æ°‘ï¼Œåœ¨å‘¼æ°”ç»†èŒå’ŒçœŸèŒç¾¤è½çš„ç»„è£…ä¸­å‘æŒ¥ä½œç”¨ã€‚**çœŸèŒå¾®ç”Ÿç‰©ç¾¤çš„ SNM æ‹Ÿåˆæ€§èƒ½ï¼ˆå›¾ 2ï¼‰ä¼˜äºç»†èŒï¼ˆç»†èŒ R2 = 0.353ï¼ŒçœŸèŒ R2 = 0.683ï¼‰ã€‚è¿™ç§å·®å¼‚è¡¨æ˜éšæœºè¿‡ç¨‹å¯¹äº EBC çœŸèŒç¾¤è½çš„ç»„è£…å¯èƒ½ç›¸å¯¹æ›´é‡è¦ï¼Œè€Œå¯¹ EBC ç»†èŒç¾¤è½çš„ç»„è£…åˆ™ä¸å¤ªé‡è¦ã€‚è¿™ç§ç°è±¡å¯èƒ½ä¸ç»†èŒå’ŒçœŸèŒä¹‹é—´çš„å¤§å°å·®å¼‚æœ‰å…³ï¼Œè¾ƒå°çš„ç»†èŒå—æ‰©æ•£é™åˆ¶çš„å½±å“è¾ƒå°ï¼Œè€Œå—ç¡®å®šæ€§è¿‡ç¨‹çš„å½±å“æ›´å¤§ (7)ã€‚\nStochastic processes played a role in assembling expiratory bacterial (A) and fungal (B) communities based on Sloan neutral model fitting. The black solid line represents the best fit, and the dotted lines represent the 95% CI (confidence interval) around the model fit. The blue dots refer to taxa that occur more frequently than predicted, and the red dots refer to taxa that occur less frequently than predicted. The green dots refer to taxa that occur in a manner consistent with predicted values.\nåŸæ ¸ç”Ÿç‰©ç»†èƒç›´å¾„å¤§æ¦‚åœ¨0.5 ~ 2.0 Î¼mï¼› å¾®çœŸæ ¸ç”Ÿç‰©ä¸ªä½“å¤§å°å¤§æ¦‚åœ¨1 ~ 200 mmï¼› ä¹‹å‰çš„ç ”ç©¶å·²ç»æŠ¥é“äº†è¾ƒå°çš„ç”Ÿç‰©ä¸å¤ªå¯èƒ½å—åˆ°æ‰©æ•£é™åˆ¶çš„å½±å“ï¼Œå› ä¸ºå®ƒä»¬ä¸è¾ƒå¤§çš„ç”Ÿç‰©ç›¸æ¯”å…·æœ‰æ›´é«˜çš„æ‰©æ•£èƒ½åŠ›ã€‚å› æ­¤å‡è®¾åœ¨ç»†èŒç¾¤è½ä¸­ç”Ÿæ€ä½è¿‡ç¨‹çš„ç›¸å¯¹å½±å“å¯èƒ½æ¯”åœ¨å¾®çœŸæ ¸ç”Ÿç‰©ç¾¤è½ä¸­æ›´å¼ºã€‚å¾®çœŸæ ¸ç”Ÿç‰©ä¸ªä½“å¤§ï¼Œå¯èƒ½ä¼šå½±å“å…¶æ‰©æ•£è¿‡ç¨‹ã€‚\nOthers å‚è€ƒè‡ªå†ç¥å…¬ä¼—å·æ–‡ç« ï¼šhttps://mp.weixin.qq.com/s/nwNuPlY7x6VScJA44c0MjQ\nCompetitive lottery åŸºäºç«äº‰å½©ç¥¨æ¨¡å‹(competitive lottery model)çš„ç¾¤è½æ„å»º å‡è®¾ä¸€ä¸ªä¸¤æ­¥æ¨¡å‹:åœ¨ç¬¬ä¸€æ­¥ä¸­ï¼Œæ ·æœ¬çš„æ€»ä¸°åº¦(100%)æ ¹æ®æŸä¸ªæœªçŸ¥çš„è¿‡ç¨‹åœ¨ç»„ä¹‹é—´åˆ†é…ã€‚ ç„¶ååœ¨ç¬¬äºŒæ­¥ä¸­ï¼Œåˆ†é…ç»™æ¯ä¸ªå°ç»„çš„ä¸°åº¦ä¼šæ ¹æ®ä¸€ä¸ªç«äº‰å½©ç¥¨æ¨¡å¼åœ¨å°ç»„æˆå‘˜ä¹‹é—´è¿›è¡Œåˆ†é…ã€‚ ç«äº‰å½©ç¥¨æ¨¡å‹çš„æ¦‚å¿µè¯´æ˜:\nåœ¨ç¬¬ä¸€é˜¶æ®µï¼Œæ¯ä¸ªæ ·æœ¬çš„æ€»ä¸°åº¦(100%)åœ¨ä¸€ç»„é¢„å®šä¹‰çš„ç»„ä¹‹é—´è¿›è¡Œåˆ†å‰²ã€‚\nåœ¨ç¬¬äºŒé˜¶æ®µï¼Œæ¯ä¸€ç»„çš„ä¸°åº¦åˆ†é…æ ¹æ®ç«äº‰å½©ç¥¨æ¨¡å‹åœ¨å­ç»„ä¹‹é—´è¿›è¡Œåˆ†é…ï¼Œå…¶ä¸­ä¸€ä¸ªå­ç»„è·å¾—äº†å¤§éƒ¨åˆ†çš„ä¸°åº¦ã€‚\nDNCI åœ¨PER-SIMPERæ–¹æ³•çš„åŸºç¡€ä¸Šï¼Œæå‡ºäº†ä¸€ä¸ªæ–°çš„åº¦é‡æŒ‡æ ‡: dispersalâ€“niche continuum index (DNCI)ï¼Œè¯¥æŒ‡æ•°å¯ä¼°è®¡æ˜¯æ‰©æ•£è¿‡ç¨‹è¿˜æ˜¯ç”Ÿæ€ä½è¿‡ç¨‹ä¸»å¯¼ç¾¤è½çš„æ„å»ºï¼Œå¹¶ä¾¿äºä¸åŒæ•°æ®é›†ä¹‹é—´çš„æ¯”è¾ƒã€‚\nPER-SIMPERåˆ©ç”¨ç‰©ç§åœ¨ä¸åŒç«™ç‚¹ä¹‹é—´çš„çŸ©é˜µï¼Œåœ¨æ’åˆ—è¿‡ç¨‹ä¸­ç”Ÿæˆä¸‰ç§ä¸åŒçš„é›¶æ¨¡å‹ï¼š é€šè¿‡çº¦æŸè¡Œ(ç”Ÿæ€ä½æ„å»º)ã€çº¦æŸåˆ—(æ‰©æ•£æ„å»º)æˆ–ä¸¤è€…éƒ½çº¦æŸã€‚ PER-SIMPERåˆ©ç”¨SIMPERæ–¹æ³•å¯¹åŸå§‹ç¾¤è½çŸ©é˜µç»„æˆç›¸ä¼¼åº¦æ¨¡å¼è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶ä¸ä¸‰ä¸ªé›¶æ¨¡å‹æ¯”è¾ƒã€‚ PER-SIMPERé€šè¿‡è¯†åˆ«å“ªä¸ªé›¶æ¨¡å‹ä¸ç»éªŒåˆ†ææœ€åŒ¹é…æ¥è¿›è¡Œå®šæ€§è¯„ä¼°ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç¾¤è½éƒ½æ˜¯ç”±ç”Ÿæ€ä½å’Œæ‰©æ•£è¿‡ç¨‹å…±åŒæ„æˆçš„ï¼Œè¿™é™åˆ¶äº†æ„å»ºæœºåˆ¶å®šæ€§æ–¹æ³•çš„æ•æ„Ÿæ€§ã€‚æ­¤å¤–ç®€å•å†³ç­–è¿‡ç¨‹çš„å®šæ€§ç‰¹æ€§ä½¿ä¸åŒç¾¤è½ä¹‹é—´çš„æ„å»ºè¿‡ç¨‹éš¾ä»¥è¿›è¡Œç²¾ç¡®æ¯”è¾ƒã€‚\nPER-SIMPERåˆ†æè¿”å›ä¸‰ä¸ªE-metricåˆ†å¸ƒ,è¿™ä¸SIMPERç»éªŒå€¼ä¸ä¸‰ä¸ªPER-SIMPERé›¶æ¨¡å‹ä¹‹é—´çš„åå·®ç›¸å…³ã€‚æœ¬æ–‡æå‡ºçš„æ–°çš„DNCIæ˜¯ç”±è¿™äº›è®¡ç®—çš„Eå€¼æ¨å¯¼è€Œæ¥çš„ã€‚ å®šé‡ç»“æœæ˜¯åŸºäºæ ‡å‡†æ•ˆåº”é‡En(å³æ¥è‡ªâ€ç”Ÿæ€ä½â€æ¨¡å‹çš„E-metricåˆ†å¸ƒ)å‡å»æ ‡å‡†æ•ˆåº”é‡Ed (å³æ¥è‡ªâ€æ‰©æ•£â€æ¨¡å‹çš„E-metricåˆ†å¸ƒ)ã€‚ DNCIæä¾›äº†ä¸€ç§æ–¹æ³•æ¥é‡åŒ–å’Œæ¯”è¾ƒè·¨æ•°æ®é›†æ„å»ºè¿‡ç¨‹çš„å¼ºåº¦ã€‚DNCIå€¼æ­£æˆ–è´Ÿè¡¨æ˜ç”Ÿæ€ä½æˆ–åˆ†æ•£è¿‡ç¨‹åˆ†åˆ«æ˜¯ç¾¤ç»„æ„å»ºçš„ä¸»è¦è¿‡ç¨‹ã€‚æŒ‡æ•°çš„ç»å¯¹å€¼è¶Šé«˜ï¼Œä»£è¡¨å ä¸»å¯¼åœ°ä½çš„æ„å»ºè¿‡ç¨‹çš„æ½œåŠ›è¶Šå¤§ã€‚ $DNCI=SES_d-SES_n=\\frac{1}{n}\\sum_{i=1}^n\\left(\\frac{E_{d(i)}-\\overline {E_{dn}}}{\\sigma E_{dn}}\\right)-\\frac{1}{n}\\sum_{i=1}^n\\left(\\frac{E_{n(i)}-\\overline {E_{dn}}}{\\sigma E_{dn}}\\right)$\nå¦‚æœDNCIä¸0å·®å¼‚ä¸æ˜¾è‘—ï¼Œåˆ™å¯ä»¥è®¤ä¸ºæ‰©æ•£è¿‡ç¨‹å’Œç”Ÿæ€ä½è¿‡ç¨‹å¯¹ç¾¤è½æ„å»ºçš„å½±å“æ˜¯ç›¸ç­‰çš„ã€‚ å½“DNCIæ˜¾è‘—ä½äº0æ—¶ï¼Œæ‰©æ•£è¿‡ç¨‹æ˜¯ç¾¤è½æ„å»ºçš„ä¸»å¯¼é©±åŠ¨å› ç´ ; å¦‚æœDNCIæ˜¾è‘—é«˜äº0ï¼Œç”Ÿæ€ä½è¿‡ç¨‹æ˜¯ç¾¤è½æ„å»ºçš„ä¸»è¦å†³å®šå› ç´ ã€‚ æ³¨æ„ï¼Œè¡¨æ˜æ‰©æ•£è¿‡ç¨‹ä¼˜åŠ¿çš„è´ŸDNCIå€¼å¹¶ä¸èƒ½æä¾›å®é™…æ‰©æ•£é€Ÿç‡çš„ä¿¡æ¯ã€‚\nReferences 1. J. Zhou, D. Ning, Stochastic Community Assembly: Does It Matter in Microbial Ecology? Microbiology and Molecular Biology Reviews. 81, e00002â€“17 (2017).\n2. J. C. Stegen, X. Lin, J. K. Fredrickson, X. Chen, D. W. Kennedy, C. J. Murray, M. L. Rockhold, A. Konopka, Quantifying community assembly processes and identifying features that impose them. The ISME Journal. 7, 2069â€“2079 (2013).\n3. J. C. Stegen, X. Lin, A. E. Konopka, J. K. Fredrickson, Stochastic and deterministic assembly processes in subsurface microbial communities. The ISME Journal. 6, 1653â€“1664 (2012).\n4. D. Ning, M. Yuan, L. Wu, Y. Zhang, X. Guo, X. Zhou, Y. Yang, A. P. Arkin, M. K. Firestone, J. Zhou, A quantitative framework reveals ecological drivers of grassland microbial community assembly in response to warming. Nature Communications. 11, 4717 (2020).\n5. D. Ning, Y. Deng, J. M. Tiedje, J. Zhou, A general framework for quantitatively assessing ecological stochasticity. Proceedings of the National Academy of Sciences. 116, 16892â€“16898 (2019).\n6. W. T. Sloan, M. Lunn, S. Woodcock, I. M. Head, S. Nee, T. P. Curtis, Quantifying the roles of immigration and chance in shaping prokaryote community structure. Environmental Microbiology. 8, 732â€“740 (2006).\n7. Y. Zhang, F. Shen, Y. Yang, M. Niu, D. Chen, L. Chen, S. Wang, Y. Zheng, Y. Sun, F. Zhou, H. Qian, Y. Wu, T. Zhu, Insights into the Profile of the Human Expiratory Microbiota and Its Associations with Indoor Microbiotas. Environmental Science \u0026amp; Technology. 56, 6282â€“6293 (2022).\n","date":"2023-03-17T00:00:00Z","image":"/p/community-assembly/comm_hub260f10f12bf64e0acb74c7ee8e930d5_36974_120x120_fill_q75_box_smart1.jpg","permalink":"/p/community-assembly/","title":"å¾®ç”Ÿç‰©ç¾¤è½æ„å»ºï¼ˆcommunity assemblyï¼‰"},{"content":"ç®€ä»‹ linux, pythonå’ŒRè¯­è¨€åº”è¯¥æ˜¯ç”Ÿä¿¡å­¦ä¹ ä¸­æœ€é‡è¦çš„å‡ ä¸ªéƒ¨åˆ†ã€‚\nlinuxæ˜¯ä¸€ç§æ“ä½œç³»ç»Ÿï¼Œç”±äºè®¸å¤šç”Ÿç‰©ä¿¡æ¯å­¦è½¯ä»¶ä»…æä¾›æ”¯æŒlinuxå¹³å°çš„å‘½ä»¤è¡Œç‰ˆæœ¬ï¼Œè€Œä¸æ˜¯å›¾å½¢åŒ–ç•Œé¢ï¼Œæ‰€ä»¥æŒæ¡è¯¥æ“ä½œç³»ç»Ÿçš„åŸºç¡€æ–‡ä»¶ç®¡ç†ï¼Œå®‰è£…ä½¿ç”¨è½¯ä»¶ï¼Œè¾“å…¥è¾“å‡ºé€»è¾‘ï¼Œç®€å•shellè„šæœ¬ç¼–å†™ç­‰ååˆ†é‡è¦ã€‚\npythonä¸Réƒ½æ˜¯å…è´¹å¼€æºå¤šå¹³å°çš„ç¼–ç¨‹è¯­è¨€ï¼Œå¹¶ä¸”éƒ½æ˜¯è¾ƒä¸ºå®¹æ˜“å­¦ä¹ ä¸Šæ‰‹çš„æ¨¡ä»¿è‡ªç„¶è¯­è¨€è¯­æ³•çš„ç¼–ç¨‹è¯­è¨€ï¼Œä¸”æ”¯æŒé¢å‘å¯¹è±¡ç¼–ç¨‹ï¼Œä¸¤è€…åœ¨æ•°æ®ç§‘å­¦ä¸Šéƒ½æœ‰ç€éå¸¸é‡è¦çš„åº”ç”¨ã€‚Pythonçš„ç”Ÿæ€ç³»ç»Ÿéå¸¸ä¸°å¯Œï¼Œæ‹¥æœ‰å¤§é‡çš„æ•°æ®ç§‘å­¦åº“å’Œæ¡†æ¶ï¼Œä¾‹å¦‚ï¼šNumPyã€Pandasã€Matplotlibã€Seabornã€Scikit-learnã€PyTorchã€TensorFlowç­‰ï¼Œè¿™äº›åº“å¯ä»¥å¸®åŠ©æ•°æ®ç§‘å­¦å®¶å¿«é€Ÿå¤„ç†å’Œåˆ†ææ•°æ®ï¼Œæ„å»ºæ¨¡å‹ã€‚\nRæ˜¯ä¸€ç§ä¸“é—¨ç”¨äºç»Ÿè®¡åˆ†æå’Œæ•°æ®å¯è§†åŒ–çš„è¯­è¨€ï¼Œå…¶ç”Ÿæ€ç³»ç»Ÿä¹Ÿéå¸¸ä¸°å¯Œï¼Œæ‹¥æœ‰å¤§é‡çš„ç»Ÿè®¡åˆ†æåº“å’Œå¯è§†åŒ–å·¥å…·ï¼Œä¾‹å¦‚ï¼šggplot2ã€dplyrã€tidyrã€shinyç­‰ã€‚ Ræ‹¥æœ‰éå¸¸å¼ºå¤§çš„æ•°æ®åˆ†æå’Œå¯è§†åŒ–èƒ½åŠ›ï¼Œå®ƒæä¾›äº†å¾ˆå¤šä¸“ä¸šçš„ç»Ÿè®¡åˆ†æå‡½æ•°å’Œå›¾å½¢ï¼Œè¿™äº›å‡½æ•°å’Œå›¾å½¢å¯ä»¥ç›´æ¥ç”¨äºæ•°æ®åˆ†æå’Œå¯è§†åŒ–ï¼Œä½¿åˆ†æå’Œå¯è§†åŒ–å˜å¾—æ›´åŠ è½»æ¾å’Œé«˜æ•ˆã€‚\nåœ¨æ­¤ï¼Œæˆ‘æƒ³å…ˆè®°å½•ä¸€ä¸‹æˆ‘ä½¿ç”¨çš„æœ€å¤šçš„Rè¯­è¨€ã€‚\nå¸¸ç”¨åŠŸèƒ½ å…¨é¢æ•™ç¨‹ å°ç™½ä¸Šæ‰‹é¦–æ¨åŒ—å¤§æè€å¸ˆçš„è¯¾ç¨‹è®²ä¹‰ã€ŠRè¯­è¨€æ•™ç¨‹ã€‹ï¼Œä¸­æ–‡è®²ä¹‰ï¼Œç®€å•æ˜“è¯»ï¼Œç”šè‡³æ•´æœ¬ä¹¦å°±æ˜¯ç”¨Rbookdownç¼–å†™çš„ï¼Œç”µå­ä¹¦ä¹Ÿæ¯”è¾ƒå¥½å¤åˆ¶ä»£ç è¿›è¡Œå­¦ä¹ ã€‚\nã€ŠRè¯­è¨€å®æˆ˜ã€‹,ä¹Ÿæœ‰ä¸­æ–‡ç‰ˆï¼Œä»‹ç»åœ°æ›´åŠ å…¨é¢ä¸”æœ‰ä¸å°‘è¿›é˜¶çŸ¥è¯†ï¼Œå€¼å¾—ä¸€çœ‹ï¼\nç„¶åæ˜¯è‘—åçš„è‹±æ–‡ä¹¦å’Œå‚è€ƒæ‰‹å†Œï¼š\nã€ŠAn Introduction to Rã€‹ ã€ŠR Cookbookã€‹ æ›´å¤šå…³äºRçš„ä¹¦å¯ä»¥åœ¨Home | Bookdownè¿™é‡Œæ‰¾åˆ°ã€‚\næ•°æ®å¤„ç† æˆ‘ç›®å‰ç”¨çš„æœ€å¤šçš„æ˜¯dplyråŒ…è¿›è¡Œæ•°æ®å¤„ç†ï¼Œæœ€å¼€å§‹æ˜¯å†²ç€ç±»ä¼¼linuxä¸‹çš„|ç®¡é“ç¬¦å»çš„ï¼Œ%\u0026gt;%ç¬¦å·çœŸçš„æŒºå¥½ç”¨çš„ï¼Œå¯ä»¥è®©æˆ‘ä»¬æ— éœ€äº§ç”Ÿè®¸å¤šä¸­é—´ç»“æœ (å‡†ç¡®æ¥è¯´%\u0026gt;%æ¥è‡ªmagrittråŒ…ï¼Œå¹¶ä¸”R4.1+ä¹Ÿæ”¯æŒäº†åŸç”Ÿç®¡é“ç¬¦|\u0026gt;ï¼Œä½†ç”¨èµ·æ¥è¿˜æ˜¯%\u0026gt;%é¡ºæ‰‹ï¼Œè¿˜æœ‰%\u0026lt;\u0026gt;%ç­‰å˜ä½“)ï¼š\n1 2 library(dplyr) head(iris)%\u0026gt;%select(Species)%\u0026gt;%unique() éšåä¾¿å‘ç°äº†tidyverseå…¨å®¶æ¡¶ï¼Œå…¶ä¸­åŒ…å«ggplot2ï¼Œtibbleï¼Œdplyrï¼Œreadrï¼Œstringrç­‰å¸¸ç”¨çš„å…¨é¢çš„æ•°æ®å¤„ç†åŒ…ï¼Œèƒ½å¤Ÿå¾ˆå¥½çš„æ»¡è¶³æˆ‘ä»¬ä¸‹æœ‰æ•°æ®å¤„ç†éœ€æ±‚ï¼š\nè¯»å–æ•°æ®\næ¸…æ´—æ•°æ®\nè½¬æ¢æ•°æ®\nåˆå¹¶æ•°æ®\nç­›é€‰æ•°æ®\nå¯è§†åŒ–\nè¿™é‡Œç»™å‡ºå®˜æ–¹æ•™ç¨‹ï¼šã€ŠR for Data Scienceã€‹ï¼Œéå¸¸å»ºè®®ç†Ÿè¯»å¹¶ä½¿ç”¨ã€‚\nå¯è§†åŒ– å¯è§†åŒ–ä¸€ç›´æ˜¯Rçš„çªå‡ºä¼˜ç‚¹ï¼Œbasic graphicå’Œggplotæ˜¯æˆ‘æœ€å¸¸ç”¨çš„ç»˜å›¾ç³»ç»Ÿï¼ˆå¶å°”ä¼šç”¨plotlyç”»ä¸€äº›äº¤äº’å›¾å½¢ï¼Œä½†å¤§å¤šæ•°æ˜¯åªéœ€è¦presentationå’Œæ–‡ç« é‡Œè¦ç”¨çš„é™æ€å›¾å½¢ï¼‰ï¼Œä¸¤è€…çš„ç»˜å›¾é€»è¾‘æœ‰æ‰€å·®å¼‚ï¼Œæ¨èåœ¨å­¦ä¼šRçš„åŸºç¡€ä½¿ç”¨å’Œæ•°æ®å¤„ç†åå°±ä½“éªŒggplotã€‚\nggplotæ˜¯ç”±Hadley Wickhamåˆ›å»ºçš„ï¼Œå¹¶è¢«åŒ…å«åœ¨Rè¯­è¨€çš„ggplot2åŒ…ä¸­ã€‚ä¸»è¦æ€æƒ³æ˜¯å°†æ•°æ®å¯è§†åŒ–çœ‹ä½œæ˜¯å›¾å±‚çš„å †å ï¼Œå…¶ä¸­æ¯ä¸ªå›¾å±‚ä»£è¡¨äº†ä¸€ä¸ªæ•°æ®å±æ€§çš„å¯è§†åŒ–ã€‚ggplotæä¾›äº†ä¸€ç³»åˆ—çš„å‡½æ•°å’Œå‚æ•°ï¼Œè®©ç”¨æˆ·èƒ½å¤Ÿè½»æ¾åœ°ç»„åˆè¿™äº›å›¾å±‚ï¼Œä»¥åŠè°ƒæ•´é¢œè‰²ã€æ ‡ç­¾ã€è½´ç­‰å…¶ä»–å±æ€§ã€‚\nggplotæ”¯æŒçš„å›¾å½¢ç±»å‹åŒ…æ‹¬æ•£ç‚¹å›¾ã€æŠ˜çº¿å›¾ã€ç›´æ–¹å›¾ã€å¯†åº¦å›¾ã€ç®±çº¿å›¾ç­‰ç­‰ï¼Œå¯ä»¥æ»¡è¶³å¤§å¤šæ•°æ•°æ®å¯è§†åŒ–çš„éœ€æ±‚ã€‚ä¼˜ç‚¹åœ¨äºå…¶è¯­æ³•ç®€æ´ã€æ˜“äºç†è§£å’Œä½¿ç”¨ï¼Œå¹¶ä¸”ç”Ÿæˆçš„å›¾è¡¨è´¨é‡é«˜ã€ç¾è§‚ã€æ˜“äºç†è§£ã€‚å®ƒä¹Ÿè¢«å¹¿æ³›åœ°åº”ç”¨äºå­¦æœ¯ç ”ç©¶ã€æ•°æ®åˆ†æã€å•†ä¸šæŠ¥å‘Šç­‰é¢†åŸŸã€‚\nåŒæ ·ç»™å‡ºå®˜æ–¹æ•™ç¨‹ï¼šã€Šggplot2: Elegant Graphics for Data Analysisã€‹ï¼Œä¼˜é›…ï¼Œå¤ªä¼˜é›…äº†ã€‚è¿™æœ¬ä¹¦ä¹Ÿæ˜¯å¯ä»¥æ‰¾åˆ°å¤§ä½¬ä»¬ç¿»è¯‘çš„ä¸­æ–‡ç‰ˆçš„ï¼Œå¯ä»¥å½“ä½œä½œå›¾å·¥å…·ä¹¦ä½¿ç”¨ï¼Œè®¸å¤šæ— æ³•ç›´æ¥Googleåˆ°çš„ç»†èŠ‚é—®é¢˜å¯èƒ½èƒ½åœ¨ä¹¦ä¸­æ‰¾åˆ°ã€‚\næ­¤å¤–è¦æä¸€ä¸‹ggpubråŒ…ï¼Œå…¶åä¸ºPublication Ready Plotsï¼Œæä¾›ä¸€äº›æ–¹ä¾¿çš„åšå‡ºå‡ºç‰ˆçº§figureçš„å‡½æ•°ã€‚ggpubr: Publication Ready Plots - Articles - STHDA è¿™ä¸ªç½‘ç«™æä¾›äº†ä¸å°‘å¥½çœ‹å›¾çš„ç»˜åˆ¶æµç¨‹ã€‚\nå½“æŒæ¡äº†åŸºæœ¬çš„ggplotç»˜åˆ¶é€»è¾‘åï¼Œè¿˜å¯ä»¥å°è¯•å„ç§åŸºäºåŒæ ·é€»è¾‘çš„æ‰©å±•åŒ…ï¼Œå¦‚ggcorï¼Œggtreeç­‰ç­‰ã€‚\ngg_extensions è¿™ä¸ªç½‘ç«™æ”¶é›†äº†å¾ˆå¤šæ­¤ç±»æ‹“å±•åŒ…å¹¶æ”¯æŒåˆ¶ä½œä¸Šä¼ è‡ªåˆ›çš„ggæ‹“å±•ï¼ˆå½“ç„¶æš‚æ—¶æœ‰ç‚¹éš¾ğŸ˜®â€ğŸ’¨ï¼‰\næœ€åï¼Œå¼ºçƒˆæ¨èä¸€ä¸ªä¸ºå¯è§†åŒ–è€Œå»ºçš„ç½‘ç«™From data to Viz | Find the graphic you need (data-to-viz.com)ï¼Œå°±åƒç½‘ç«™åä¸€æ ·ï¼Œä¸°å¯Œå¤šå½©çš„å¯è§†åŒ–å½¢å¼å¸®æˆ‘ä»¬æ‰¾åˆ°é€‚åˆè‡ªå·±æ•°æ®çš„æ ·å¼ï¼Œå¹¶æä¾›ç”»æŸä¸€ç±»å›¾çš„pythonï¼ŒRç”šè‡³D3.jsä»£ç ï¼ŒçœŸçš„éå¸¸æ–¹ä¾¿åœ°copyä»£ç ï¼Œæ›¿æ¢æˆ‘ä»¬çš„æ•°æ®ï¼Œå°‘é‡çš„ä¿®æ”¹å°±èƒ½æœ‰å¾ˆä¸é”™çš„æ•ˆæœğŸ˜„ã€‚\nRç¼–ç¨‹ Ræ˜¯ä¸€ä¸ªå®åº“ï¼Œå‡ ä¹æ€»èƒ½åœ¨ä¸Šé¢æ‰¾åˆ°åˆé€‚çš„åŒ…å®ç°æˆ‘ä»¬æƒ³è¦çš„åŠŸèƒ½ï¼Œä½†ä»–ä¹Ÿæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€ï¼Œç†Ÿæ‚‰å…¶ç¼–ç¨‹è¯­æ³•å¯¹è¿›é˜¶ä½¿ç”¨ååˆ†é‡è¦ã€‚\nåŸºæœ¬çš„æ•°æ®è¯»å–ä¸è¾“å‡ºï¼Œif elseã€switchã€forå¾ªç¯ä¸ç®€å•å‡½æ•°ç¼–å†™éœ€è¦æŒæ¡ã€‚\nåŒæ—¶å› ä¸ºRæ˜¯ä¸€ä¸ªæ¯”è¾ƒ\u0026quot;æ…¢\u0026quot;çš„è¯­è¨€ï¼Œå°½é‡ä½¿ç”¨å‘é‡å¼ç¼–ç¨‹ã€applyæ›¿ä»£forå¾ªç¯ã€RCppç¼–å†™å‡½æ•°ç­‰æ–¹æ³•æé«˜å…¶æ•ˆç‡ï¼ˆåé¢å¯èƒ½ä¼šä¸“é—¨è®²è®²ï¼‰ã€‚\nè¿™é‡Œæ¨èå¤§ä½¬çš„ã€ŠAdvanced Rã€‹ï¼Œå¯¹Ré«˜çº§ç¼–ç¨‹æŠ€æœ¯è¿›è¡Œè®²è§£ã€‚\nRmarkdown R Markdownæ˜¯ä¸€ç§æ–‡æœ¬æ ¼å¼å’Œå·¥å…·ï¼Œç”¨äºåˆ›å»ºå…·æœ‰ä»£ç ã€æ–‡æœ¬ã€å›¾å½¢å’Œè¾“å‡ºç»“æœçš„å¯é‡å¤æ€§æŠ¥å‘Šã€‚å®ƒæ˜¯åœ¨Rè¯­è¨€ç¯å¢ƒä¸­å¼€å‘çš„ï¼Œä½†ä¹Ÿå¯ä»¥ä¸å…¶ä»–ç¼–ç¨‹è¯­è¨€ï¼ˆå¦‚Pythonï¼‰ç»“åˆä½¿ç”¨ã€‚\nä½¿ç”¨R Markdownï¼Œæ‚¨å¯ä»¥å°†ä»£ç ã€æ–‡æœ¬å’Œå›¾å½¢ç»„åˆåˆ°ä¸€ä¸ªæ–‡ä»¶ä¸­ï¼Œå¹¶ä½¿ç”¨R Markdownè¯­æ³•å°†å®ƒä»¬ç»„ç»‡æˆç»“æ„åŒ–çš„æ–‡æ¡£ã€‚ç„¶åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨R Markdownç¼–è¯‘å™¨å°†æ–‡æ¡£è½¬æ¢ä¸ºHTMLã€PDFã€Wordæˆ–å…¶ä»–æ ¼å¼çš„æŠ¥å‘Šã€‚\nR Markdownå…·æœ‰ä»¥ä¸‹ä¼˜ç‚¹ï¼š\nå¯é‡å¤æ€§ï¼šæŠ¥å‘Šä¸­çš„æ‰€æœ‰ä»£ç å’Œç»“æœéƒ½æ˜¯å¯é‡å¤çš„ï¼Œè¿™æœ‰åŠ©äºç¡®ä¿ç ”ç©¶ç»“æœçš„å¯é æ€§å’Œé€æ˜åº¦ã€‚\næ•ˆç‡ï¼šä½¿ç”¨R Markdownï¼Œæ‚¨å¯ä»¥åœ¨å•ä¸ªæ–‡ä»¶ä¸­ç»„ç»‡å’Œè®°å½•æ‰€æœ‰å†…å®¹ï¼Œä»è€ŒèŠ‚çœæ—¶é—´å’Œç²¾åŠ›ã€‚\nçµæ´»æ€§ï¼šR Markdownæ”¯æŒå¤šç§æ ¼å¼å’Œè¾“å‡ºé€‰é¡¹ï¼Œå› æ­¤æ‚¨å¯ä»¥æ ¹æ®éœ€è¦è‡ªå®šä¹‰æŠ¥å‘Šçš„æ ·å¼å’Œå¸ƒå±€ã€‚\nYihui Xieå¤§ä½¬çš„å®˜æ–¹æ–‡æ¡£ä»‹ç»ï¼šR Markdown: The Definitive Guide (bookdown.org)\nä»¥åŠå‚è€ƒä¹¦ï¼šR Markdown Cookbook (bookdown.org)\nRbookdown Rçš„bookdownæ‰©å±•åŒ…(https://github.com/rstudio/bookdown) æ˜¯ç»§knitrå’Œrmarkdownæ‰©å±•åŒ…ä¹‹åï¼Œ å¦ä¸€ä¸ªå¢å¼ºmarkdownæ ¼å¼çš„æ‰©å±•ï¼Œ ä½¿å¾—Rmdæ ¼å¼å¯ä»¥æ”¯æŒå…¬å¼ã€å®šç†ã€å›¾è¡¨è‡ªåŠ¨ç¼–å·å’Œå¼•ç”¨ã€é“¾æ¥ï¼Œ æ–‡çŒ®å¼•ç”¨å’Œé“¾æ¥ç­‰é€‚ç”¨äºç¼–å†™ä¹¦ç±çš„åŠŸèƒ½ã€‚ç›¸å½“æ–¹ä¾¿ï¼Œæˆ‘ä¹Ÿç¨å¾®å°è¯•å†™äº†ä¸€ä¸‹ï¼šMetaNet Tutorial (asa12138.github.io)ã€‚\nå‚è€ƒä¹¦ï¼šbookdown: Authoring Books and Technical Documents with R Markdown\nRblogdown Ræ‰©å±•åŒ…blogdownå¯ä»¥ä¸Hugoè½¯ä»¶é…åˆåˆ¶ä½œç®€å•çš„é™æ€ç½‘ç«™ã€‚ ç½‘ç«™çš„æ‰€æœ‰æ–‡ä»¶éƒ½å­˜åœ¨äºä¸€ä¸ªç›®å½•ä¸­ï¼Œ åªè¦ä¸Šä¼ åˆ°ä»»æ„çš„ç½‘ç«™æœåŠ¡å™¨å°±å¯ä»¥å‘å¸ƒï¼Œ æ²¡æœ‰ä»»ä½•é™åˆ¶ã€‚è¿™ç¯‡åšå®¢å°±æ˜¯åŸºäºRblogdownå†™çš„ï¼Œè¿˜æ˜¯éå¸¸å‹å¥½æ˜“ä¸Šæ‰‹çš„ã€‚\nå‚è€ƒä¹¦ï¼šblogdown: Creating Websites with R Markdown (bookdown.org)\n3.21æ›´æ–°ï¼š\nå¤§å¤šæ•°ç½‘ç«™çš„ä¿®æ”¹è¦åœ¨themesä¸­å®ç°ï¼Œæ¯”å¦‚æˆ‘ç°åœ¨ä½¿ç”¨çš„ä¸»é¢˜ä¸æ”¯æŒlatexæ¸²æŸ“ï¼Œæƒ³è¦åŠ ä¸Šè¿™ä¸ªåŠŸèƒ½ï¼Œæˆ‘å…ˆæ‰¾åˆ°äº†yihuiå¤§ä½¬çš„ä¸»é¢˜å®ç°è¿™ä¸ªåŠŸèƒ½çš„Javascriptä»£ç ï¼Œå³hugo-lithium/layouts/partials/footer_mathjax.htmlï¼Œç„¶åæŠŠå®ƒå¤åˆ¶åˆ°ç›®å‰ç”¨çš„ä¸»é¢˜çš„footerç›®å½•ä¸‹ï¼ˆå¯èƒ½æ²¡æœ‰è¿™ä¸ªç›®å½•ï¼Œè€Œæ˜¯footer.htmlåŒç›®å½•ä¸‹ï¼‰ï¼Œè®°å¾—åœ¨include.htmlæˆ–è€…å…¶ä»–layoutæ–‡ä»¶ä¸­åŠ å…¥{{ partial \u0026quot;footer/footer_mathjax.html\u0026quot; . }}ï¼Œè¿™æ ·å°±èƒ½é¡ºåˆ©è°ƒç”¨mathjaxäº†ã€‚\nR Presentation R Markdownæ–‡ä»¶(.Rmd)æ”¯æŒç”Ÿæˆç½‘é¡µæ ¼å¼çš„å¹»ç¯ç‰‡(slidy_presentation)ï¼Œ ä»¥åŠLaTeX beameræ ¼å¼çš„PDFå¹»ç¯ç‰‡(beamer_presentation)ï¼Œ å’ŒMicrosoft Officeçš„PowerPointå¹»ç¯ç‰‡(powerpoint_presentation)æ ¼å¼ã€‚\nç›®å‰ç¨å¾®å°è¯•äº†ä¸€äº›Yihuiå¤§ä½¬çš„\u0026quot;å†™è½®çœ¼\u0026quot;åŒ…ï¼Œä½†æ²¡æœ‰è¯•ç€åšè‡ªå·±çš„slidesï¼Œä»¥åæœ‰æœºä¼šä¸€å®šè¯•è¯•ã€‚\nå†™RåŒ… ç§¯æå°è¯•\nå‚è€ƒä¹¦ï¼šR Packages (2e) (r-pkgs.org)\nåˆ¶ä½œshinyåº”ç”¨ ç§¯æå°è¯•\nå®˜æ–¹æ•™ç¨‹ï¼šShiny Learning Resources\nå‚è€ƒä¹¦ï¼šMastering Shiny\n","date":"2023-03-16T00:00:00Z","image":"/p/r/images/data2viz_hu2949f787b14e5432e8dbe93255a87ee8_671473_120x120_fill_box_smart1_3.png","permalink":"/p/r/","title":"Rè¯­è¨€å­¦ä¹ "},{"content":"æœ€è¿‘å€’è…¾äº†ä¸å°‘æ–°ç©æ„ï¼Œæ¯”å¦‚è¿™ä¸ªåšå®¢ç³»ç»Ÿï¼Œåœ¨æ­¤å†™ä¸‹ç¬¬ä¸€ç¯‡åšå®¢ã€‚\nä»åˆšå¼€å§‹æ¥è§¦ç”Ÿä¿¡åˆ°ç°åœ¨å·²ç»3å¹´äº†ï¼Œæˆ‘ä¹Ÿä»æœ¬ç§‘ç”Ÿå˜æˆäº†åšå£«ç”Ÿï¼Œä¸“ä¸šä»ç”Ÿç‰©ç§‘å­¦å˜æˆäº†ç”Ÿç‰©ä¿¡æ¯å­¦ã€‚èµ°ä¸Šç§‘ç ”é“è·¯ï¼Œå¯èƒ½æ˜¯ç§ç§å·§åˆä¸é€‰æ‹©çš„ç»“æœï¼Œä½†ç°åœ¨è„‘å­é‡Œæƒ³çš„å°±æ˜¯å°†äºŒåæ¥å¹´çš„å„ç§çŸ¥è¯†è¿ç”¨åœ¨ç ”ç©¶ä¸Šï¼Œåšä¸€äº›æœ‰æ„æ€çš„ä¸œè¥¿ã€‚\nå¸Œæœ›è‡ªå·±æœ‰ç©ºå¯ä»¥å¤šæ›´æ–°ï¼Œå¸®åŠ©è‡ªå·±æ•´ç†æ€è·¯ï¼Œè®°å½•ä¸€äº›å®éªŒå’Œæ•°æ®åˆ†æçš„æ–¹æ³•æŠ€å·§ï¼Œè°ƒèŠ‚ä¸€ä¸‹å¿ƒæƒ…ğŸ˜‚ã€‚\n","date":"2023-03-14T00:00:00Z","image":"/p/%E6%98%A5%E4%B9%8B%E4%BC%8A%E5%A7%8B/spring_hu0533df8c600b6ebf5e775c57536fef00_394558_120x120_fill_q75_box_smart1.jpeg","permalink":"/p/%E6%98%A5%E4%B9%8B%E4%BC%8A%E5%A7%8B/","title":"æ˜¥ä¹‹ä¼Šå§‹"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nFormula $a=sum_i^2$ $a=sum_i$\nHeadings The following HTML \u0026lt;h1\u0026gt;â€”\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\nâ€” Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements â€” abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-03-11T00:00:00Z","image":"/p/markdown-syntax-guide/pawel-czerwinski-8uZPynIu-rQ-unsplash_hud7e36f7e20e71be184458283bdae4646_55974_120x120_fill_q75_box_smart1.jpg","permalink":"/p/markdown-syntax-guide/","title":"Markdown Syntax Guide"}]