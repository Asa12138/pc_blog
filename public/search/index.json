[{"content":"Introduction 在 R 语言中，有多个软件包可以用来绘制地图，其中最流行的是 ggplot2、sp、maptools 和 leaflet。\nsimple examples 以下是一些简单的示例：\n使用 ggplot2 包绘制世界地图： 1 2 3 4 5 6 7 library(ggplot2) library(maps) world_map \u0026lt;- map_data(\u0026#34;world\u0026#34;) ggplot(world_map, aes(x = long, y = lat, group = group)) + geom_polygon(fill = \u0026#34;lightblue\u0026#34;, color = \u0026#34;white\u0026#34;) 使用 sp 包和 maptools 包绘制美国州界地图： 1 2 3 4 5 6 7 8 library(sp) library(maptools) #sids.shp是一个内置的数据，后面会讲到 us_states \u0026lt;- readShapePoly(system.file(\u0026#34;shapes/sids.shp\u0026#34;, package=\u0026#34;maptools\u0026#34;)[1], proj4string=CRS(\u0026#34;+proj=longlat +datum=WGS84\u0026#34;)) plot(us_states) 使用 leaflet 包绘制交互式地图： 1 2 3 4 5 library(leaflet) leaflet() %\u0026gt;% addTiles() %\u0026gt;% addMarkers(lng=-74.5, lat=40, popup=\u0026#34;New York City\u0026#34;) 如果需要更高级的地图可视化，就需要一些地图相关知。例如在地图上添加标注或进行交互式可视化，也是我们接下来要讨论的地方。\nFormat 首先，在地图绘制中，常用的数据格式包括：\n.shp 文件：地理信息系统 (GIS) 中的一种数据格式，通常用于存储地理矢量数据，例如点、线、面、多边形等地理特征的坐标和属性信息。\n.kml 文件：Google 地图使用的一种数据格式，通常用于存储地理矢量数据和标记，例如点、线、面、图标等地理特征的坐标、属性信息和样式信息。\n.kmz 文件：Google 地图使用的一种数据格式，通常是 .kml 文件的压缩版本，可以方便地共享和传输。\n.gpx 文件：一种常见的 GPS 数据格式，通常用于存储路径、轨迹等 GPS 数据。\n.json 文件：一种常见的数据交换格式，可以存储各种结构化数据，包括地理矢量数据、属性信息等。\n.csv 文件：一种常见的数据格式，可以存储表格数据，例如经纬度、名称、描述等地理信息。\n除了以上列举的格式之外，还有其他一些格式，例如 .gml、.svg、.dxf 等，这些格式通常在不同的 GIS 软件和地图绘制工具之间进行数据交换和共享。需要根据具体需求和使用工具选择合适的数据格式。\nR 可以处理上述列举的地图相关的文件格式。\n对于 .shp 文件，R中的 rgdal、sp、sf 等软件包可以读取和操作该文件格式，可以进行地图绘制、分析和处理等任务。\n对于 .kml 和 .kmz 文件，R中的 plotKML 软件包可以读取和操作该文件格式，可以进行地图绘制和分析等任务。\n对于 .gpx 文件，R中的 maptools、ggmap 等软件包可以读取和操作该文件格式，可以进行路径和轨迹可视化等任务。\n对于 .json 和 .csv 文件，R内置的函数和外部软件包都可以读取和操作该文件格式，可以进行地图数据的转换、处理和可视化等任务。\n总的来说，R 中有许多内置函数和软件包可以读取、操作和可视化地图相关的数据格式，可以帮助我们进行地图制作、数据分析和可视化等任务。\nCRS 坐标参考系统（Coordinate Reference System，CRS）是一个基于地球表面形状和大小的坐标系统。它是通过经度和纬度来描述地球表面上的点和区域的。\n在地理坐标系中，经度是指地球表面上某点所在的经线和地球本初子午线（即0度经线）之间的夹角，以东经为正，以西经为负。纬度是指地球表面上某点所在的纬线和赤道之间的夹角，以北纬为正，以南纬为负。\nWGS84坐标系统是全球定位系统（GPS）使用的一种地理坐标系统。WGS84是\u0026quot;World Geodetic System 1984\u0026quot;的缩写，是由美国国防部和美国国家地球空间情报局共同研制的。WGS84坐标系统使用经度和纬度来描述地球表面上的点和区域。它使用的是大地基准面，与传统的椭球体模型有所不同。WGS84坐标系统的零点定义为通过英国格林尼治天文台的经线（0度经线），也称为本初子午线。R的sf识别\u0026quot;EPSG:4326\u0026quot; or \u0026ldquo;WGS84\u0026rdquo; 都是该坐标系。\n在R里面我们可以定义自己绘图需要的坐标系，如\u0026quot;+proj=laea +lat_0=40 +lon_0=104\u0026quot; ，它表示一个局部等面积投影（LAEA）坐标系，中心纬度为40度，中心经度为104度（后面会用到）。\n如果想将一个地理坐标系（比如经度-纬度坐标系）中的点转换为这个投影坐标系中的点，可以使用R中的proj4库来进行转换。下面是一个简单的R代码示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 library(proj4) # 定义源坐标系（经度-纬度坐标系） src_crs \u0026lt;- \u0026#34;+proj=longlat +datum=WGS84\u0026#34; # 定义目标坐标系（局部等面积投影坐标系） dst_crs \u0026lt;- \u0026#34;+proj=laea +lat_0=40 +lon_0=104\u0026#34; # 定义待转换的点（经度、纬度） lon \u0026lt;- 116.4074 lat \u0026lt;- 39.9042 # 转换坐标系 p \u0026lt;- project(cbind(lon, lat), dst_crs) # 输出转换后的坐标（x、y） print(p) # 或者使用sf转换 source_df=st_as_sf(data.frame(lon, lat),coords = c(\u0026#34;lon\u0026#34;, \u0026#34;lat\u0026#34;), crs = 4326) sf::st_transform(source_df,crs=\u0026#34;+proj=laea +lat_0=40 +lon_0=104\u0026#34;) China map basic map 基础的ggplot2绘图代码如下，但是最近maps包好像没有存储中国的数据了，所以我们应该自己去找自己要画的区域的地图文件。\n1 2 3 4 5 6 7 8 9 10 11 12 # 注意，无法正常运行 library(maps) library(ggplot2) # 读取中国地图数据 china_map \u0026lt;- map_data(\u0026#34;china\u0026#34;) # 绘制中国地图 ggplot() + geom_polygon(data = china_map, aes(x = long, y = lat, group = group), fill = \u0026#34;white\u0026#34;, color = \u0026#34;black\u0026#34;) + theme_void() + coord_fixed() 我常用的是geojson文件，网上能够下载到中国地图的地方很多，比如 GeoJSON.cn，yezongyang/china-geojson等等，而世界上其他区域，不同精度（洲，国家，城市，县\u0026hellip;）的地图数据就需要自己按照需求寻找一下，如GeoJSON Maps of the globe (ash.ms)，georgique/world-geojson，datasets/geo-countries等等。\n中国地图绘制主要参考这篇博客：R-ggplot2 标准中国地图制作。\n使用sf包读取地图数据：这里用的是民政局提供的一个API，如果是自己下载的数据就换成文件地址即可，st_read或者read_sf可以以处理geojson文件。\n1 2 3 4 5 6 7 8 9 10 11 library(sf) library(ggplot2) #1.下载数据 dir=getwd() china_shp=paste0(dir,\u0026#34;/china.json\u0026#34;) if(!file.exists(china_shp))download.file(\u0026#34;https://gitcode.net/mirrors/lyhmyd1211/geomapdata_cn/-/raw/master/china.json?inline=false\u0026#34;,china_shp) china \u0026lt;- sf::read_sf(china_shp) #2.民政部API link: https://mp.weixin.qq.com/s/qj1SRc6D8sgYJYaZzDux6Q API_pre = \u0026#34;http://xzqh.mca.gov.cn/data/\u0026#34; china = sf::st_read(dsn = paste0(API_pre, \u0026#34;quanguo.json\u0026#34;), stringsAsFactors=FALSE) 读取数据后变成一个sf对象，sf类型的数据本质还是一个data.frame，但是其中有些元素是MULTIPOLYGON S3对象，这是一种表示多边形几何对象的数据类型，可以用于描述多个不相交的多边形区域，每个多边形可以由一个或多个线性环组成。在R中，MULTIPOLYGON 通常作为空间数据类型的一种表示，用于表示地理区域的空间形状和位置关系。\nst_crs函数可以用来改变地理坐标系：\n1 head(china) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ## Simple feature collection with 6 features and 10 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: 97.1729 ymin: 34.58341 xmax: 126.0685 ymax: 53.33701 ## Geodetic CRS: WGS 84 ## # A tibble: 6 × 11 ## adcode name child…¹ level parent subFe…² adchar center centr…³ acrou…⁴ ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; ## 1 110000 北京市 16 prov… \u0026#34;{ \\\u0026#34;… 0 \u0026lt;NA\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 2 120000 天津市 16 prov… \u0026#34;{ \\\u0026#34;… 1 \u0026lt;NA\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 3 130000 河北省 11 prov… \u0026#34;{ \\\u0026#34;… 2 \u0026lt;NA\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 4 140000 山西省 11 prov… \u0026#34;{ \\\u0026#34;… 3 \u0026lt;NA\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 5 150000 内蒙古自治区 12 prov… \u0026#34;{ \\\u0026#34;… 4 \u0026lt;NA\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## 6 210000 辽宁省 14 prov… \u0026#34;{ \\\u0026#34;… 5 \u0026lt;NA\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; ## # … with 1 more variable: geometry \u0026lt;MULTIPOLYGON [°]\u0026gt;, and abbreviated variable ## # names ¹​childrenNum, ²​subFeatureIndex, ³​centroid, ⁴​acroutes 1 2 3 4 5 6 7 library(sf) library(ggplot2) library(ggspatial) # plot ggplot(china)+ geom_sf()+ labs(title=\u0026#34;Ministry of Civil of PRC\u0026#34;,x=\u0026#34;Lon\u0026#34;,y=\u0026#34;Lat\u0026#34;) 1 2 3 4 5 6 #改变crs # plot ggplot(china)+ geom_sf()+ coord_sf(crs = \u0026#34;+proj=laea +lat_0=40 +lon_0=104\u0026#34;)+ labs(title=\u0026#34;Ministry of Civil of PRC\u0026#34;,x=\u0026#34;Lon\u0026#34;,y=\u0026#34;Lat\u0026#34;) 使用ggspatial包添加比例尺和指北针：\n1 2 3 4 5 6 7 8 9 main_map=ggplot()+ geom_sf(data = china,fill=NA,size=1,color=\u0026#34;black\u0026#34;)+ coord_sf(crs = \u0026#34;+proj=laea +lat_0=40 +lon_0=104\u0026#34;)+ labs(title=\u0026#34;Ministry of Civil of PRC\u0026#34;,x=\u0026#34;Lon\u0026#34;,y=\u0026#34;Lat\u0026#34;) + annotation_scale(location = \u0026#34;bl\u0026#34;) + # spatial-aware automagic north arrow annotation_north_arrow(location = \u0026#34;tl\u0026#34;, which_north = \u0026#34;false\u0026#34;, style = north_arrow_fancy_orienteering)+theme_minimal() main_map annotation 使用ggplot常规的注释手段geom_point()或geom_text() 在使用geom_sf 绘制的地图上一般不会成功，而是应该先用st_as_sf转换我们的注释数据，然后用geom_sf() ，geom_sf_text() 或geom_sf_label()。\n不要把注释信息放在coord_sf 的后面，因为ggplot是按照图层添加元素的，coord_sf 转换坐标后加入的注释就会有位置偏差。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #生成测试数据 anno=data.frame(lon=runif(20,90,120), lat=runif(20,30,40), type=sample(letters[1:3], 20, replace = TRUE), value=runif(20,1,10)) #转换对象 anno_sf \u0026lt;- st_as_sf(anno,coords = c(\u0026#34;lon\u0026#34;, \u0026#34;lat\u0026#34;),crs = 4326) p2=ggplot()+ geom_sf(data = china,fill=NA,size=1,color=\u0026#34;black\u0026#34;)+ #添加散点注释 geom_sf(data = anno_sf,aes(fill=type,size=value),shape=21,colour=\u0026#39;black\u0026#39;,stroke=.25)+ scale_size(range = c(1,5))+ #添加text geom_sf_text(data = anno_sf,aes(label=round(value,1)),size=2,legend=\u0026#34;none\u0026#34;)+ coord_sf(crs = \u0026#34;+proj=laea +lat_0=40 +lon_0=104\u0026#34;)+ labs(title=\u0026#34;Ministry of Civil of PRC\u0026#34;,x=\u0026#34;Lon\u0026#34;,y=\u0026#34;Lat\u0026#34;) + annotation_scale(location = \u0026#34;bl\u0026#34;) + # spatial-aware automagic north arrow annotation_north_arrow(location = \u0026#34;tl\u0026#34;, which_north = \u0026#34;false\u0026#34;, style = north_arrow_fancy_orienteering)+theme_minimal() p2 如果想要添加具体坐标的注释或者使用xlim或，geom_sf_text里调整文本位置的nudge_x等功能，那也需要注意投影坐标系的变化，使用st_transform处理。\n1 2 3 4 5 6 7 8 9 #例如，这个方法是无法取出90E到120E的部分的，而是很窄的一段 p2+xlim(90,120) data.frame(lon=c(90,120),lat=c(30,30))%\u0026gt;% st_as_sf(coords = c(\u0026#34;lon\u0026#34;, \u0026#34;lat\u0026#34;), crs = 4326) %\u0026gt;% sf::st_transform(df2_sf,crs=\u0026#34;+proj=laea +lat_0=40 +lon_0=104\u0026#34;) #发现结果对应的是(-1348988,1539346),这样截取的才是90E到120E的部分。 p2+xlim(-1348988,1539346) Leaflet usage Leaflet是一个开源的JavaScript库，用于创建交互式地图。R中的Leaflet包提供了一个轻量级的接口，允许在R中创建交互式地图。Leaflet包提供了许多基本的地图操作功能，例如缩放、平移和旋转，同时还允许添加标记、文本注释、多边形、线条和点。\n在使用Leaflet包之前，需要先安装并加载它。可以通过以下代码安装和加载Leaflet包：\n1 2 install.packages(\u0026#34;leaflet\u0026#34;) library(leaflet) 在使用Leaflet包创建地图时，需要提供一个起始的中心点和缩放级别。例如，可以使用以下代码创建一个以纽约市为中心的地图，此外，可以使用addTiles()函数添加地图图层，还可以使用addMarkers()函数添加标记，使用addPolygons()函数添加多边形，使用addLines()函数添加线条，使用addPopups()函数添加弹出窗口等等。通过使用这些函数，可以在地图上添加各种各样的元素，从而创建一个自定义的交互式地图，以下是完成上述中国地图的一个完整的例子。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # Prepare the text for the tooltip (HTML style): gre_text \u0026lt;- paste( \u0026#34;Type: \u0026#34;, anno$type, \u0026#34;\u0026lt;br/\u0026gt;\u0026#34;, \u0026#34;Value: \u0026#34;, round(anno$value,2), \u0026#34;\u0026lt;br/\u0026gt;\u0026#34; )%\u0026gt;% lapply(htmltools::HTML) type_col=colorFactor(palette = c(\u0026#34;red3\u0026#34;,\u0026#34;green3\u0026#34;,\u0026#34;blue3\u0026#34;),domain =anno$type) inter_p=leaflet(anno) %\u0026gt;% #添加图层 addTiles() %\u0026gt;% #确定中心点 setView(lng = 104, lat = 40, zoom = 4)%\u0026gt;% #添加散点注释 addCircleMarkers(~lon, ~lat, fillColor = ~type_col(type), fillOpacity = 0.7, color=\u0026#34;white\u0026#34;, radius=8, stroke=FALSE, label = gre_text, labelOptions = labelOptions( style = list(\u0026#34;font-weight\u0026#34; = \u0026#34;normal\u0026#34;, padding = \u0026#34;3px 8px\u0026#34;), textsize = \u0026#34;13px\u0026#34;, direction = \u0026#34;auto\u0026#34;)) %\u0026gt;% #添加图例 addLegend( pal=type_col, values=~type, opacity=0.7, title = \u0026#34;Type\u0026#34;, position = \u0026#34;bottomright\u0026#34; ) class(inter_p) inter_p add in PPT leaflet最后生成的是一个htmlwidget衍生对象，所以可以用htmlwidgets包保存为html文件并直接用浏览器打开。\n1 2 #保存结果 htmlwidgets::saveWidget(inter_p,file = \u0026#34;leaflet.html\u0026#34;) 有时候这种交互地图在presentation展示时非常好用，要是能插入到ppt就是件美事了。\n可惜的是，没有找到很好的方式完成这个功能😭（除非一开始的ppt都是用Rmarkdown做的）\nWindows上的Powerpoint可以考虑使用插件：\nwebView：PPT：如何在ppt中显示网页，并且实时操作？（但好像也挂掉了）\nLiveWeb：如何将实时网页添加到PowerPoint演示文稿 （新版office不行）\nMac上的Powerpoint更加不太行了。\n看来只能加个超链接到该文件，然后点击后跳转到浏览器了（希望未来有解决方法）。\nGeoTiff manipulate 我本人不是地科相关专业的，不太会用ArcGIS等更为专业的软件，但有时候也需要去收集一些跟地理环境相关的数据，比如气温，土壤元素等等，发现在很多数据库中这些数据以geotiff格式储存。\nGeoTIFF是一种基于TIFF格式的地理信息图像文件格式，它包含了地理空间信息和图像信息。GeoTIFF文件可以包含单一图像或多个图像，并且可以存储地球表面的各种数据，如高程数据、卫星图像、气象数据等等。GeoTIFF文件与普通的TIFF文件相比，增加了一些地理参考信息和投影信息，可以用于地图制作和GIS分析等领域。GeoTIFF文件中的地理参考信息包括地理坐标系和投影坐标系，以及每个像素所表示的地理位置和像素大小等信息。\nRasterLayer 在R语言中，可以使用raster包和gdal包读取和处理GeoTIFF文件。使用raster包中的函数可以读取GeoTIFF文件并将其转换为RasterLayer对象，以进行各种空间分析操作。\nRasterLayer是raster包中的一种对象类型，它代表了一个栅格数据集。栅格数据集是由多个栅格单元组成的二维矩阵，每个栅格单元都有一个特定的值，代表了该位置上的数据信息。在R语言中，使用raster包可以方便地读取和处理栅格数据集，例如遥感影像、地形图等。通过将栅格数据集转换为RasterLayer对象，可以进行各种空间分析操作，例如裁剪、合并、重采样、计算、绘图等。\n下面是一些基于RasterLayer对象（或者sf对象，很多函数都是通用的）的常见操作和分析的R语言代码示例：\n计算栅格数据的基本统计信息 1 2 3 4 5 6 7 8 9 10 library(raster) # 读入一个栅格数据文件 r \u0026lt;- raster(\u0026#34;path/to/raster.tif\u0026#34;) # 计算最小值、最大值、均值、方差 min_val \u0026lt;- minValue(r) max_val \u0026lt;- maxValue(r) mean_val \u0026lt;- mean(r) var_val \u0026lt;- var(r) 对栅格数据进行裁剪、合并、重采样等操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 library(raster) # 读入两个栅格数据文件 r1 \u0026lt;- raster(\u0026#34;path/to/raster1.tif\u0026#34;) r2 \u0026lt;- raster(\u0026#34;path/to/raster2.tif\u0026#34;) # 裁剪两个栅格数据文件 r1_crop \u0026lt;- crop(r1, extent(r2)) r2_crop \u0026lt;- crop(r2, extent(r1)) # 合并两个栅格数据文件 r_merge \u0026lt;- merge(r1_crop, r2_crop) # 将一个栅格数据文件的分辨率重采样为另一个栅格数据文件的分辨率 r_resample \u0026lt;- resample(r1_crop, r2_crop) 进行栅格数据的代数、逻辑运算 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 library(raster) # 读入两个栅格数据文件 r1 \u0026lt;- raster(\u0026#34;path/to/raster1.tif\u0026#34;) r2 \u0026lt;- raster(\u0026#34;path/to/raster2.tif\u0026#34;) # 对两个栅格数据文件进行加、减、乘、除运算 r_add \u0026lt;- r1 + r2 r_sub \u0026lt;- r1 - r2 r_mul \u0026lt;- r1 * r2 r_div \u0026lt;- r1 / r2 # 对一个栅格数据文件进行逻辑与、或、非运算 r_and \u0026lt;- r1 \u0026amp; r2 r_or \u0026lt;- r1 | r2 r_not \u0026lt;- !r1 进行栅格数据的可视化 1 2 3 4 5 6 7 8 9 10 11 12 13 library(raster) # 读入一个栅格数据文件 r \u0026lt;- raster(\u0026#34;path/to/raster.tif\u0026#34;) # 绘制等高线图 contour(r, add=FALSE) # 绘制等值线图 image(r, col=terrain.colors(255)) # 绘制渐变色图 plot(r, col=rainbow(255)) Example 继续我们上面的中国地图绘制，我们想要获得某个时间的中国气温图：\n首先在WorldClim网站上可以下载到全球历史天气信息：\n我们下载一个average temperature信息，精度为10minute(即10个经纬度的单位，比较粗略，35M～)，通过把全球的数据map到我们之前已经得到的sf对象china上就可以取出这部分的数据了。\n1 2 3 4 5 library(raster) avgtemp \u0026lt;- raster(\u0026#34;~/Downloads/wc2.1_10m_tavg/wc2.1_10m_tavg_01.tif\u0026#34;) #全球平均气温数据 plot(avgtemp) 1 2 3 #切片 china_tmp=crop(avgtemp,china) plot(china_tmp) 1 2 3 #掩膜 china_tmp=mask(china_tmp,china) plot(china_tmp) 最后再把经过切片掩膜处理的RasterLayer转换为sf对象，就可以根据我们之前绘制annotation的方法把气温数据全部绘制上去了。\n大功告成！这里是最后的结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 将RasterLayer转换为sf对象 sf_data \u0026lt;- st_as_sf(rasterToPolygons(china_tmp), crs = st_crs(china_tmp)) colnames(sf_data)[1]=\u0026#34;Average_temperature\u0026#34; ggplot()+ geom_sf(data = china,fill=NA,size=1,color=\u0026#34;black\u0026#34;)+ #添加栅格数据 geom_sf(data = sf_data,aes(fill=Average_temperature),shape=22,size=0.5,stroke=0,color=NA)+ scale_fill_gradient2(low = \u0026#34;blue\u0026#34;,mid = \u0026#34;white\u0026#34;,high = \u0026#34;red\u0026#34;)+ #使用ggnewscale产生一个新的fill映射，否则会覆盖报错。 ggnewscale::new_scale_fill()+ #添加散点注释 geom_sf(data = anno_sf,aes(fill=type,size=value),shape=21,colour=\u0026#39;black\u0026#39;,stroke=.25)+ scale_size(range = c(1,5))+ #添加text geom_sf_text(data = anno_sf,aes(label=round(value,1)),size=2,legend=\u0026#34;none\u0026#34;)+ coord_sf(crs = \u0026#34;+proj=laea +lat_0=40 +lon_0=104\u0026#34;)+ labs(title=\u0026#34;Ministry of Civil of PRC\u0026#34;,x=\u0026#34;Lon\u0026#34;,y=\u0026#34;Lat\u0026#34;) + annotation_scale(location = \u0026#34;bl\u0026#34;) + # spatial-aware automagic north arrow annotation_north_arrow(location = \u0026#34;tl\u0026#34;, which_north = \u0026#34;false\u0026#34;, style = north_arrow_fancy_orienteering)+theme_minimal() ","date":"2023-04-06T00:00:00Z","image":"/p/r-map/index_files/figure-html/unnamed-chunk-22-1_hu25d347af0f26b4f0f63f78f0a939c84a_495129_120x120_fill_box_smart1_3.png","permalink":"/p/r-map/","title":"R绘制优美的地图"},{"content":"","date":"2023-04-03T00:00:00Z","permalink":"/p/antibiotics-resistance/","title":"antibiotics resistance"},{"content":"Motivation cd-hit在数据量很大的情况下会非常慢，我问chatGPT有没有更快的：\nhttps://www.nature.com/articles/s41467-018-04964-5 是的，有一些其他的基因序列聚类软件也比较流行，其中一些也是非常快速的，例如：\nUCLUST：这是一种基于贪心算法的聚类工具，可用于聚类DNA和蛋白质序列。它是CD-HIT的一种变体，也是速度非常快的软件之一。\nVSEARCH：这是一种类似于UCLUST的工具，也是基于贪心算法，可以用于聚类DNA和蛋白质序列。它的速度比CD-HIT更快，而且还支持多线程和一些其他高级功能。\nMMSEQS2：这是一种使用图像剖析技术的聚类工具，可以用于聚类非常大的序列数据集。它比CD-HIT和UCLUST都要快，而且还支持多线程和GPU加速。\nSwarm：这是一种基于聚类半径的工具，可以用于聚类16S rRNA序列等微生物群落数据。它比CD-HIT等工具要快，而且可以处理高度冗余的序列。\n尝试使用一下mmseqs2 要使用MMseqs2聚类大量核酸序列，可以按照以下步骤操作：\n准备数据：收集所有要聚类的核酸序列，并将它们存储在一个文件中，例如FASTA格式。\n安装MMseqs2：访问MMseqs2的官方网站（https://github.com/soedinglab/MMseqs2）并下载和安装软件包。\n创建数据库：使用MMseqs2将所有核酸序列导入一个数据库中。例如，可以使用以下命令将FASTA格式的序列导入到MMseqs2数据库中： mmseqs createdb input.fasta db_name\n其中，\u0026ldquo;input.fasta\u0026quot;是你的输入文件名，\u0026ldquo;db_name\u0026quot;是你想要为数据库取的名称。\n运行聚类：使用MMseqs2运行聚类分析。例如，可以使用以下命令运行聚类分析： mmseqs easy-cluster db_name cluster_name tmp --threads 4\n其中，\u0026ldquo;db_name\u0026quot;是你的数据库名称，\u0026ldquo;cluster_name\u0026quot;是你想要为聚类结果取的名称，\u0026ldquo;tmp\u0026quot;是你想要为临时文件夹取的名称，\u0026rdquo;\u0026ndash;threads 4\u0026quot;表示你想要使用4个线程运行分析。\n解析结果：等待聚类分析完成后，可以使用MMseqs2的其他工具（如\u0026quot;mmseqs createtsv\u0026rdquo;）来解析聚类结果，并将结果导出到所需的格式中（如TSV格式）。 需要注意的是，MMseqs2支持多种聚类算法和参数设置，因此在运行分析之前，应该根据具体的应用需求进行设置和优化。例如，你可以选择使用其他的聚类算法，或调整聚类的相似性阈值等参数，以获得最佳的聚类结果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 #测试比较一下 cd ~/work/st/temp/cluster_test $ ll ../prodigal/C1.gene.fa -rw-r--r-- 1 pengchen jianglab 338M Apr 7 2022 ../prodigal/C1.gene.fa 800000条序列 #cd-hit============ ## aS覆盖度，c:identity相似度，G0局部比对？，g最优解，T多线程，M内存0不限制 cd-hit-est -i ../prodigal/C1.gene.fa \\ -o cd_hit.fa \\ -aS 0.9 -c 0.9 -g 0 -T 0 -M 0 #两小时过去了，还在处理第20000条 #mmseqs2========= ##min-seq-id:identity（相似度？），c覆盖度，rescore-mode3: global alignment #建库 input_fa=../prodigal/C1.gene.fa DB=C1.geneDB DB_clu=mmseq_out mmseqs createdb $input_fa $DB #聚类 mmseqs cluster $DB $DB_clu tmp \\ --min-seq-id 0.9 -c 0.9 --cov-mode 1 --threads 8 #输出转换 #第一列是代表序列id，第二列是成员序列id #mmseqs createtsv $DB $DB mmseq_out mmseq_out.tsv #mmseqs createseqfiledb $DB $DB_clu ${DB_clu}_seq #mmseqs result2flat $DB $DB ${DB_clu}_seq ${DB_clu}_seq.fasta #获取represent sequence mmseqs createsubdb $DB_clu $DB ${DB_clu}_rep mmseqs convert2fasta ${DB_clu}_rep ${DB_clu}_rep.fasta #上述步骤可以直接用easycluster替代。 input_fa=../prodigal/C1.gene.fa mmseqs easy-cluster $input_fa cluster_res tmp \\ --min-seq-id 0.9 -c 0.9 --cov-mode 1 --threads 8 #再测试一下easylinclust input_fa=../prodigal/C1.gene.fa mmseqs easy-linclust $input_fa lin_res tmp \\ --min-seq-id 0.9 -c 0.9 --cov-mode 1 --threads 8 #结果mmseq_out_rep.fasta：315M #这是单样本assembly结果的聚类结果，合理。 #250s,快得一批,使用10GB左右的内存。 #cluster模块可能需要大量内存。包含 N 个序列和每个序列平均 r 个比对结果的数据库的内存消耗可以估计为 #M = (6 * N * r) 字节 Cores per node: 8 CPU Utilized: 00:12:22 CPU Efficiency: 41.97% of 00:29:28 core-walltime Job Wall-clock time: 00:03:41 Memory Utilized: 9.40 GB Memory Efficiency: 60.14% of 15.62 GB 多个待聚类文件的使用方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 #cd-hit两个文件 cd-hit-est -i ../prodigal/C1.gene.fa \\ -o A.fa \\ -aS 0.9 -c 0.9 -g 0 -T 0 -M 0 # A和B基因集待聚类 # 计算B中特有的基因 cd-hit-est-2d -i A.fa -i2 B.fa -o B.uni.fa \\ -aS 0.9 -c 0.9 -g 0 \\ -T 96 -M 0 -d 0 # 合并为非冗余基因集 cat A.fa B.uni.fa \u0026gt; NR.fa #有更多文件时 #可以准备一个namelist first=`head -n1 namelist` echo handing $first cd-hit-est -i $first \\ -o NR.fa \\ -aS 0.9 -c 0.9 -g 0 -T 0 -M 0 for i in `tail -n+2 namelist` do echo handing $i cd-hit-est-2d -i NR.fa -i2 $i -o ${i}.uni.fa \\ -aS 0.9 -c 0.9 -g 0 \\ -T 96 -M 0 -d 0 cat ${i}.uni.fa \u0026gt;\u0026gt; NR.fa done #mmseqs2 #看看直接上两个文件的聚类结果 #合并文件：使用cat命令将所有核酸序列文件合并成一个大的FASTA格式文件 sed -i \u0026#34;/\u0026gt;/s/\u0026gt;/\u0026gt;C2_/\u0026#34; ../prodigal/C2.gene.fa cat ../prodigal/C1.gene.fa ../prodigal/C2.gene.fa \u0026gt; all.fasta #建库 mmseqs createdb all.fasta all DB=all DB_clu=all_clu #聚类 mmseqs cluster $DB $DB_clu tmp \\ --min-seq-id 0.9 -c 0.9 --cov-mode 1 --threads 8 --rescore-mode 3 #输出转换 #获取represent sequence mmseqs createsubdb $DB_clu $DB ${DB_clu}_rep mmseqs convert2fasta ${DB_clu}_rep ${DB_clu}_rep.fasta #mmseqs2 oldDB=C1.geneDB cluDB_old=mmseq_out newDB=all mmseqs clusterupdate $oldDB $newDB $cluDB_old ${newDB}_updated ${cluDB}_updated tmp \\ --min-seq-id 0.9 -c 0.9 --cov-mode 1 --threads 8 --rescore-mode 3 ","date":"2023-04-03T00:00:00Z","permalink":"/p/mmseqs2/","title":"Mmseqs2的基础使用"},{"content":"Theories and Methods of Species Diversity Research\n这是我在一门研究生课程上的课程任务，查阅了一些文献总结整理了物种多样性研究理论与方法，比较基础，没有对一些理论和模型深入讲解，仅做分享。\nIntroduction Biological diversity largely describes the change of life from genes to ecosystems, comprising their existences, genetic variations, their environment, populations and the ecosystem in which they are existing and other evolutionary developments that keep the system functioning, changing and adapting.\n生物多样性是度量生命的变异和变异能力的指标，又分成遗传多样性，物种多样性，生态系统多样性三个层次，我这里主要介绍物种多样性。 他又有三个尺度和三个维度，分别是α，β，γ分类多样性，谱系多样性，功能多样性，这里的每个交集都是可以研究的。\nData collection methods 我们应该如何进行物种多样性研究呢？\n首先当然是制定研究方案，进行取样， 对于自己的研究对象，可以进行随机取样，系统取样，或者其他的一些方法， 也可能是一块有代表性的永久样地，可以研究它的动态变化。\n然后是开始调查获取数据，传统的方法里，植物群落一般会进行实地调查或者使用遥感图像收集数据，动物会用到自动音视频记录，昆虫的话还会有灯光诱捕法等。\n还有对微生物进行调查的，用直接培养方法或者测序手段。\n当然这些方法不是一定专用的，一些新的方法也可以交叉使用，比如eDNA方法： eDNA是指在环境样品中所有被发现的不同生物的基因组DNA的混合，环境可以包括土壤、沉积物、排泄物、空气、水体，甚至生物个体本身。 动物在某个环境中生活，身上的各种痕迹会携带着自身DNA掉落到四周，所以用这个方法有调查各种物种的潜力，有篇文章就用空气的eDNA调查了附近的动物。\n此外还有整合的方法，比如这篇文章就提出，将遥感，田间调查和测序结合在一起，来获得完整的物种风度表。\n有了这些方法后，我们还要明确自己要获取的有哪些数据：\n我认为主要有三个方面：\n第一个就是群落的特征，包括各个物种的丰度，密度，频度，群落的生物量；如果是植物的话，还要收集盖度、树冠直径、树高、位置等等。 第二个重要的方面是我们每个样方的环境因子数据： 包括气候数据，如降水，相对湿度，温度等等，地形数据，如海拔，坡度等等，土壤数据，如土壤的粒径保水量和各种化学元素等等，有条件的话可以做微生物和人类因素的数据收集。 第三个方面是物种的特征：比如植物的生活型，生长型，功能类型等，这个对后面功能多样性的研究很关键 还有就是各个物种的系统发育位置，可以去找各种植物志，动物志或者NCBI的数据库来获得，这个对谱系多样性研究很重要。 Measure methods 获取了以上这些数据后，接下来就是使用一些指标对多样性进行度量。\nTaxa α diversity 首先是分类的a多样性指数，主要有以下几个类别：\n使用物种数指示 物种数和物种总个体数 物种数和物种总个体数和每个物种的个体数（还有一些专门用在测序数据表征多样性的，因为测序手段我们能获得的丰度表是不传统的。这种树我看到了几棵，那个动物有几只等等，而是用测序测到了多少条DNA来表征的，所以会有很多测不到的，或者只能测到几条序列的，就有Chao1和ACE指数来考虑这些非常低的物种） 用信息公示表示（常用的shannon-wiener指数就在这里） 均一性表示 Taxa β diversity beta多样性的三个常用的简单指标： 基于相异系数进行计算： 这里收集了目前会用到的各种距离的算法，比如我们常用的欧式距离，还有这个bray距离等，这样算出来就是一个距离矩阵，我们可以知道哪些样方之间差异大或者差异小 Taxa γ diversity gamma多样性，沿着长江取样来举个例子，图中每个取样点本身的微生物多样性是α-多样性（单个群落水平）；将1～9这九个样点归为一组，则这一组内各样点之间的差异，可以理解为β-多样性（局部或者区域水平）；当我们把所有取样点放在一起，站在一个更高、更广阔的尺度上时，这时候的多样性就是所谓的γ-多样性。这个指标就是α-多样性在尺度上的一个推广。\n一个例子总结三个尺度上的物种多样性：\n三个生态区九座山峰的生物多样性指数。每个符号代表不同的物种；有些物种只在一个峰上有种群，而另一些则在两个或更多峰上。每个峰上物种丰富度的变化导致每个生态区的不同 alpha、gamma 和 beta 多样性值。\n这种变化对我们如何分配有限的资源以最大限度地保护资源有影响。如果只能保护一个生态区，生态区 3可能是一个不错的选择，因为它具有高伽马（总）多样性。但是，如果只能保护一个山峰，是否应该保护生态区 1（有许多分布广泛的物种）或生态区3（有几个独特的、范围受限的物种）中的山峰？\nPhylogenetic α diversity 群落系统发育多样性PD：谱系树的总枝长度 净相关指数NRI： 计算所有物种对的平均谱系距离MPD，保持物种数量和个体数不变 最近邻体指数NTI： 计算所有物种对的平均谱系距离MNPD，保持物种数量和个体数不变 可以看上图右边的例子，3个样方发现的四种物种丰度表，我们确定了他们的系统发育关系就可以进行计算。\nPhylogenetic β diversity Beta的计算会稍微复杂一点，公式没有一个个列出，但是有相关的R包进行计算（vegan）。\nFunctional diversity 最后就是功能多样性指数，他是影响种群生存、群落和生态系统稳定的重要因素， 能更好地反映生态系统生产、养分平衡等功能。\n这个怎么计算呢，要收集好物种的功能类型，比如对于植物来说，有光和途径等等，也同样整理为功能表，功能表和物种丰度表mapping合并一下可以得到功能丰度表，然后就可以计算各种指数了。\nAnalytical methods 我们应该怎么做数据分析呢？（具体的流程和代码下次分享，这里先简单描述一下）\n首先拿到丰度表，可以对整个表进行重采样，每次采样计算一次a多样性指数，就可以做出这个稀释曲线，他可以说明我们在这个样方里的调查或者说测序手段是否是充足的。\n然后是计算每个样方的a多样性指数， 通过结合环境因子数据，我们可以做组间多重比较，比如说 对于一些数值数据，我们可以计算相关性，或者做回归分析。 这个回归又分为很多方式，比如线性回归，广义线性回归等等，这个可以帮我们发现那些因素会以怎样的方式影响a多样性，比如这里，可能海拔越高多样性越低。\n对于beta多样性，我们首先计算相异矩阵，这里就是样本与样本间的距离 我们可以做热图展示各样本间的距离， 或者做一个相似系数-地理距离的回归分析，一般来说，地理距离越远，可能beta多样性越高。\n或者具体看看组间差异，这里可以看到KO_OE组beta多样性最大， 还能做聚类分析，看看到底哪些样本更加类似。\nBeta多样性的另一种展示方法是排序方法，也叫降维分析，我们常用的方法有PCA，PcoA等等， 另外可以加上环境因子数据，做约束排序，比如RDA，CCA等方法，不仅能看到样本间的差异，还可以看到这种差异主要是由那种环境因子影响的，比如这里，在轴一上的差异主要是由env1这个变量引起的。\nTheories 物种多样性的中性理论做出了一个具有挑战性的假设，即所有个体在生态上都是相同的，并且不需要生态位差异来解释生物多样性模式。 根据中性理论，等同物种的高度多样化群落的出现是因为偶然的灭绝被物种形成所平衡。具体来说，适应性等价假设与随机或随机过程相结合，包括死亡、来自区域物种库的移民和物种形成，可以导致物种丰富的种群。（有关生态位和中性作用对多样性影响，专门有研究这种群落构建的）\nReferences ","date":"2023-04-01T00:00:00Z","image":"/p/biodiversity/images/diversity_hu497d07d6085df17c480b385e6cae73d8_591092_120x120_fill_box_smart1_3.png","permalink":"/p/biodiversity/","title":"物种多样性研究的理论和方法"},{"content":"Introduction Shiny 是一个 R 包，可轻松地直接从 R 构建交互式 Web 应用程序。还可以在网页上托管独立应用程序或将它们嵌入 R Markdown 文档或构建仪表板，还可以使用 CSS 主题、html 小部件和 JavaScript 操作扩展您的 Shiny 应用程序。\n1 2 3 4 5 6 7 8 #first app library(shiny) ui \u0026lt;- fluidPage( \u0026#34;Hello, world!\u0026#34; ) server \u0026lt;- function(input, output, session) { } shinyApp(ui, server) 整个app可分为两个部分，ui与sever，可以认为是前端与后端的关系，Rshiny提供了很多内置的小组件帮我们将前后端联系起来，非常方便好用。只需要有一点点的HTML/CSS/Javascript的知识就可以设计出更好看的界面和更多有趣的交互。\n这里是shiny的记忆手册,浓缩了大部分的操作。 Methods UI设计 Layout 最基础的布局就是sidebarLayout,可以分成sidebarPanel,mainPanel两个部分。\n1 2 3 4 5 6 7 8 ui \u0026lt;- fluidPage( titlePanel(\u0026#34;title panel\u0026#34;), sidebarLayout( sidebarPanel(\u0026#34;sidebar panel\u0026#34;), mainPanel(\u0026#34;main panel\u0026#34;) ) ) 可以通过将内容放在 *Panel 函数中来向Shiny 应用程序添加内容，shiny提供了R代码方便插入HTML (Table 1)，更多标签可以查看tag-glossary。\nTable 1: shiny function\tHTML5 equivalent\tcreates shiny function HTML5 equivalent creates p \u0026lt;p\u0026gt; A paragraph of text h1 \u0026lt;h1\u0026gt; A first level header h2 \u0026lt;h2\u0026gt; A second level header h3 \u0026lt;h3\u0026gt; A third level header h4 \u0026lt;h4\u0026gt; A fourth level header h5 \u0026lt;h5\u0026gt; A fifth level header h6 \u0026lt;h6\u0026gt; A sixth level header a \u0026lt;a\u0026gt; A hyper link br \u0026lt;br\u0026gt; A line break (e.g. a blank line) div \u0026lt;div\u0026gt; A division of text with a uniform style span \u0026lt;span\u0026gt; An in-line division of text with a uniform style pre \u0026lt;pre\u0026gt; Text ‘as is’ in a fixed width font code \u0026lt;code\u0026gt; A formatted block of code img \u0026lt;img\u0026gt; An image strong \u0026lt;strong\u0026gt; Bold text em \u0026lt;em\u0026gt; Italicized text HTML NA Directly passes a character string as HTML code Control widgets 这些是常用shiny内置的小控件，提供一种向 Shiny serve发送消息的方式。 Table 2: standard Shiny widgets function widget actionButton Action Button checkboxGroupInput A group of check boxes checkboxInput A single check box dateInput A calendar to aid date selection dateRangeInput A pair of calendars for selecting a date range fileInput A file upload control wizard helpText Help text that can be added to an input form numericInput A field to enter numbers radioButtons A set of radio buttons selectInput A box with choices to select from sliderInput A slider bar submitButton A submit button textInput A field to enter text 可以想想怎么获取更多控件，比如一个color panel等等。\n更多：\n使用 textInput() 收集少量文本，使用 passwordInput()3 收集密码，使用 textAreaInput() 收集文本段落。\n要收集数值，请使用 numericInput() 创建一个受约束的文本框或使用 sliderInput() 创建一个滑块。如果您为 sliderInput() 的默认值提供一个长度为 2 的数值向量，您将得到一个具有两端的“范围”滑块。\n使用 dateInput() 收集一天或使用 dateRangeInput() 收集两天的范围。这些提供了一个方便的日历选择器，并且诸如 datesdisabled 和 daysofweekdisabled 之类的附加参数允许您限制有效输入的集合。\n有两种不同的方法允许用户从一组预先指定的选项中进行选择：selectInput()(还可以设置 multiple = TRUE 以允许用户选择多个元素)和 radioButtons(); 可以使用checkboxGroupInput()形成多选。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ui \u0026lt;- fluidPage( textInput(\u0026#34;name\u0026#34;, \u0026#34;What\u0026#39;s your name?\u0026#34;), passwordInput(\u0026#34;password\u0026#34;, \u0026#34;What\u0026#39;s your password?\u0026#34;), textAreaInput(\u0026#34;story\u0026#34;, \u0026#34;Tell me about yourself\u0026#34;, rows = 3) ) ui \u0026lt;- fluidPage( numericInput(\u0026#34;num\u0026#34;, \u0026#34;Number one\u0026#34;, value = 0, min = 0, max = 100), sliderInput(\u0026#34;num2\u0026#34;, \u0026#34;Number two\u0026#34;, value = 50, min = 0, max = 100), sliderInput(\u0026#34;rng\u0026#34;, \u0026#34;Range\u0026#34;, value = c(10, 20), min = 0, max = 100) ) ui \u0026lt;- fluidPage( dateInput(\u0026#34;dob\u0026#34;, \u0026#34;When were you born?\u0026#34;), dateRangeInput(\u0026#34;holiday\u0026#34;, \u0026#34;When do you want to go on vacation next?\u0026#34;) ) animals \u0026lt;- c(\u0026#34;dog\u0026#34;, \u0026#34;cat\u0026#34;, \u0026#34;mouse\u0026#34;, \u0026#34;bird\u0026#34;, \u0026#34;other\u0026#34;, \u0026#34;I hate animals\u0026#34;) ui \u0026lt;- fluidPage( selectInput(\u0026#34;state\u0026#34;, \u0026#34;What\u0026#39;s your favourite state?\u0026#34;, state.name), radioButtons(\u0026#34;animal\u0026#34;, \u0026#34;What\u0026#39;s your favourite animal?\u0026#34;, animals), checkboxGroupInput(\u0026#34;animal\u0026#34;, \u0026#34;What animals do you like?\u0026#34;, animals) ) 让用户使用 actionButton() 或 actionLink() 执行操作，可以使用“btn-primary”、“btn-success”、“btn-info”、“btn-warning”或“btn-danger”之一使用类参数自定义外观，使用“btn-lg”、“btn-sm”、“btn-xs”更改大小，可以使用“btn-block”使按钮跨越它们嵌入的元素的整个宽度。\n1 2 3 4 5 6 7 8 9 ui \u0026lt;- fluidPage( fluidRow( actionButton(\u0026#34;click\u0026#34;, \u0026#34;Click me!\u0026#34;, class = \u0026#34;btn-danger\u0026#34;), actionButton(\u0026#34;drink\u0026#34;, \u0026#34;Drink me!\u0026#34;, class = \u0026#34;btn-lg btn-success\u0026#34;) ), fluidRow( actionButton(\u0026#34;eat\u0026#34;, \u0026#34;Eat me!\u0026#34;, class = \u0026#34;btn-block\u0026#34;) ) ) 连接sever general 添加输出对象在ui中 Shiny 提供了一系列函数，可以将 R 对象转换为用户界面的输出。每个函数创建特定类型的输出。\nTable 3: output R objects family Output function Creates dataTableOutput DataTable htmlOutput raw HTML imageOutput image plotOutput plot tableOutput table textOutput text uiOutput raw HTML verbatimTextOutput text 编写构建R对象的代码在serve中 Table 4: render R objects family render function creates renderDataTable DataTable renderImage images (saved as a link to a source file) renderPlot plots renderPrint any printed output renderTable data frame, matrix, other table like structures renderText character strings renderUI a Shiny tag object or HTML 使用input，output连接 以下代码就可以将selectInput选择的值var通过input$var的形式传递到renderText()，再render成output$selected_var的形式，最后通过textOutput()输出到ui界面。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 library(shiny) ui \u0026lt;- fluidPage( titlePanel(\u0026#34;censusVis\u0026#34;), sidebarLayout( sidebarPanel( selectInput(\u0026#34;var\u0026#34;, label = \u0026#34;Choose a variable to display\u0026#34;, choices = c(\u0026#34;Percent White\u0026#34;, \u0026#34;Percent Black\u0026#34;, \u0026#34;Percent Hispanic\u0026#34;, \u0026#34;Percent Asian\u0026#34;), selected = \u0026#34;Percent White\u0026#34;) ), mainPanel( textOutput(\u0026#34;selected_var\u0026#34;) ) ) ) server \u0026lt;- function(input, output) { output$selected_var \u0026lt;- renderText({ paste(\u0026#34;You have selected\u0026#34;, input$var) }) } shinyApp(ui, server) 更多：\n使用 textOutput() 输出常规文本，使用 verbatimTextOutput() 输出固定代码和控制台输出。 renderText() 将结果组合成一个字符串，通常与 textOutput() 配对 renderPrint() 打印结果，就像您在 R 控制台中一样，并且通常与 verbatimTextOutput() 配对。\ntableOutput() 和 renderTable() 呈现静态数据表，同时显示所有数据。 dataTableOutput() 和 renderDataTable() 呈现一个动态表，显示固定数量的行以及用于更改哪些行可见的控件。 tableOutput() 对于小型、固定的摘要（例如模型系数）最有用；如果您想向用户公开完整的数据框，则 dataTableOutput() 是最合适的。\n默认情况下，plotOutput() 将占据其容器的整个宽度（稍后会详细介绍），并且高度为 400 像素。您可以使用高度和宽度参数覆盖这些默认值。我们建议始终设置 res = 96，因为这将使您的 Shiny 图与您在 RStudio 中看到的尽可能接近。\nreactive expressions This difference between commands and recipes is one of the key differences between two important styles of programming:\nIn imperative programming, you issue a specific command and it’s carried out immediately. This is the style of programming you’re used to in your analysis scripts: you command R to load your data, transform it, visualise it, and save the results to disk.\nIn declarative programming, you express higher-level goals or describe important constraints, and rely on someone else to decide how and/or when to translate that into action. This is the style of programming you use in Shiny.\nShiny 中声明式编程的优势之一是它允许应用程序非常懒惰。 Shiny 应用程序只会执行更新您当前可以看到的输出控件所需的最少工作量，优点是快速，缺点是如果你不运行所有代码，可能不会发现错误。\n反应式表达式比常规 R 函数更聪明。它们缓存值并知道它们的值何时会变。第一次运行反应式表达式时，表达式会将其结果保存在计算机的内存中。下次调用反应式表达式时，它可以返回保存的结果而不进行任何计算（这将使您的应用程序更快）。\n如果反应式表达式知道结果是最新的，它只会返回保存的结果。如果反应式表达式得知结果已过时（因为小部件已更改），则表达式将重新计算结果。然后它返回新结果并保存一个新副本。反应式表达式将使用这个新副本，直到它也变得过时为止。 让我们总结一下这种行为：\n反应式表达式会在您第一次运行时保存其结果。\n下次调用反应式表达式时，它会检查保存的值是否已过时（即，它所依赖的小部件是否已更改）。\n如果该值已过期，反应对象将重新计算它（然后保存新结果）。\n如果该值是最新的，反应式表达式将返回保存的值而不进行任何计算。\n建议把文件导入等不需要每次更新的代码放在reactive里。\n在 Shiny 中，应该考虑一个规则：每当复制和粘贴一次东西时，就应该考虑将重复的代码提取到一个反应表达式中，因为反应式表达式不仅让人类更容易理解代码，它们还提高了 Shiny 高效重新运行代码的能力。\n考虑以下代码，reactive()确保只有在改变n或lambda时才会重新计算：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 library(ggplot2) freqpoly \u0026lt;- function(x1, x2, binwidth = 0.1, xlim = c(-3, 3)) { df \u0026lt;- data.frame( x = c(x1, x2), g = c(rep(\u0026#34;x1\u0026#34;, length(x1)), rep(\u0026#34;x2\u0026#34;, length(x2))) ) ggplot(df, aes(x, colour = g)) + geom_freqpoly(binwidth = binwidth, size = 1) + coord_cartesian(xlim = xlim) } ui \u0026lt;- fluidPage( fluidRow( column(3, numericInput(\u0026#34;lambda1\u0026#34;, label = \u0026#34;lambda1\u0026#34;, value = 3), numericInput(\u0026#34;lambda2\u0026#34;, label = \u0026#34;lambda2\u0026#34;, value = 5), numericInput(\u0026#34;n\u0026#34;, label = \u0026#34;n\u0026#34;, value = 1e4, min = 0) ), column(9, plotOutput(\u0026#34;hist\u0026#34;)) ) ) server \u0026lt;- function(input, output, session) { x1 \u0026lt;- reactive(rpois(input$n, input$lambda1)) x2 \u0026lt;- reactive(rpois(input$n, input$lambda2)) output$hist \u0026lt;- renderPlot({ freqpoly(x1(), x2(), binwidth = 1, xlim = c(0, 40)) }, res = 96) } shinyApp(ui,server) 控制reactive行为：\n计时器 reactiveTimer() 是一个响应式表达式，它依赖于隐藏的输入：当前时间。 将server里的reactive修改成下列形式可以让图形每500ms刷新一次。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 server \u0026lt;- function(input, output, session) { timer \u0026lt;- reactiveTimer(500) x1 \u0026lt;- reactive({ timer() rpois(input$n, input$lambda1) }) x2 \u0026lt;- reactive({ timer() rpois(input$n, input$lambda2) }) output$hist \u0026lt;- renderPlot({ freqpoly(x1(), x2(), binwidth = 1, xlim = c(0, 40)) }, res = 96) } 点击刷新 当你的serve运行一次需要庞大计算和时间时，可能希望要求用户通过单击按钮来选择执行昂贵的计算。这是 actionButton() 的一个很好的用例： 并且我们需要 eventReactive()，它有两个参数：第一个参数指定依赖什么，第二个参数指定计算什么。\n修改ui和serve，添加了按键，用户点击按键即可出现新的模拟结果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ui \u0026lt;- fluidPage( fluidRow( column(3, numericInput(\u0026#34;lambda1\u0026#34;, label = \u0026#34;lambda1\u0026#34;, value = 3), numericInput(\u0026#34;lambda2\u0026#34;, label = \u0026#34;lambda2\u0026#34;, value = 5), numericInput(\u0026#34;n\u0026#34;, label = \u0026#34;n\u0026#34;, value = 1e4, min = 0), actionButton(\u0026#34;simulate\u0026#34;, \u0026#34;Simulate!\u0026#34;) ), column(9, plotOutput(\u0026#34;hist\u0026#34;)) ) ) server \u0026lt;- function(input, output, session) { x1 \u0026lt;- eventReactive(input$simulate, { rpois(input$n, input$lambda1) }) x2 \u0026lt;- eventReactive(input$simulate, { rpois(input$n, input$lambda2) }) output$hist \u0026lt;- renderPlot({ freqpoly(x1(), x2(), binwidth = 1, xlim = c(0, 40)) }, res = 96) } observeEvent() 与 eventReactive() 非常相似。它有两个重要的参数：eventExpr 和 handlerExpr。第一个参数是要依赖的输入或表达式；第二个参数是将要运行的代码。例如，对 server() 的以下修改意味着每次更新该名称时，都会向控制台发送一条消息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 ui \u0026lt;- fluidPage( textInput(\u0026#34;name\u0026#34;, \u0026#34;What\u0026#39;s your name?\u0026#34;), textOutput(\u0026#34;greeting\u0026#34;) ) server \u0026lt;- function(input, output, session) { string \u0026lt;- reactive(paste0(\u0026#34;Hello \u0026#34;, input$name, \u0026#34;!\u0026#34;)) output$greeting \u0026lt;- renderText(string()) observeEvent(input$name, { message(\u0026#34;Greeting performed\u0026#34;) }) } file up/download 使用fileInput在ui中上传文件后，得到的input是一个列表，其中的datapath是文件上传后的路径，需要使用read.csv等函数读取file$datapath。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ui \u0026lt;- fluidPage( sidebarLayout( sidebarPanel( fileInput(\u0026#34;file1\u0026#34;, \u0026#34;Choose CSV File\u0026#34;, accept = \u0026#34;.csv\u0026#34;), checkboxInput(\u0026#34;header\u0026#34;, \u0026#34;Header\u0026#34;, TRUE) ), mainPanel( tableOutput(\u0026#34;contents\u0026#34;) ) ) ) server \u0026lt;- function(input, output) { output$contents \u0026lt;- renderTable({ file \u0026lt;- input$file1 ext \u0026lt;- tools::file_ext(file$datapath) req(file) validate(need(ext == \u0026#34;csv\u0026#34;, \u0026#34;Please upload a csv file\u0026#34;)) read.csv(file$datapath, header = input$header) }) } shinyApp(ui, server) 您可以让用户使用 downloadButton() 或 downloadLink() 下载文件。这些都需要服务器功能中的新技术，因此我们将在第 9 章中回过头来讨论。\nShare 文件形式 任何拥有 R 的人都可以运行Shiny 应用程序，分享你的app.R 文件副本，以及您的应用程序中使用的任何补充材料（例如，www 文件夹或 helpers.R 文件）即可，最好写上代码运行的依赖包安装代码。\nrunUrl() will download and launch a Shiny app straight from a weblink. runGitHub( \u0026quot;\u0026lt;your repository name\u0026gt;\u0026quot;, \u0026quot;\u0026lt;your user name\u0026gt;\u0026quot;) 网页形式 上述方法要求用户在他们的计算机上安装 R 和 Shiny。但如果我们自己搭建好了服务器，也可以直接用浏览器使用我们的APP。\nShinyapps.io 将 Shiny 应用程序转换为网页的最简单方法是使用 shinyapps.io，这是 RStudio 为 Shiny 应用程序提供的托管服务。 2. Shiny Server\nRStudio Connect Reference 官方教程：Shiny Learning Resources\n参考书：Mastering Shiny\n","date":"2023-03-27T00:00:00Z","image":"/p/rshiny/Rshiny_hu0864f99837a84b3a0d6c26cdeddf969b_6899_120x120_fill_q75_box_smart1.jpg","permalink":"/p/rshiny/","title":"开发我的Rshiny应用"},{"content":"Introduction 宏基因组（Metagenome）是指对一个生态系统中的所有微生物进行DNA分析的过程，可以帮助研究人员了解微生物的多样性、功能和互作关系。\n宏基因组的应用非常广泛，包括：\n生物多样性研究：通过对宏基因组进行分析，可以了解不同生态系统中微生物的多样性和分布情况。\n生态学研究：宏基因组可以帮助研究人员了解微生物在生态系统中的功能、互作关系和生态位等。\n生物技术：宏基因组可以用于筛选具有特定功能的微生物，例如，寻找能够降解有害物质的微生物。\n宏基因组的分析一般包括以下步骤：\nDNA提取与建库。\n高通量测序：使用高通量测序技术对扩增后的DNA进行测序，得到原始序列数据。\n数据清洗和组装：对原始数据进行质量控制、去除低质量序列和冗余序列，将序列拼接成较长的连续序列（contigs）。\n基因注释：将contigs中的基因进行注释，得到基因功能信息。\n数据分析：了解微生物多样性、群落结构、功能特征等信息（更多是指获取了物种丰度表或功能丰度表之后的进一步分析）。\nMAGs binning， 进化动态等进一步分析\n这是我常用的一套基本流程(Figure 1)，当然在面对不同项目时应该有不同的侧重点和适用的分析方法，可以在此基础上添加或修改。\n最早这方面的分析我都是参考刘永鑫老师的EasyMetagenome,现在这套流程也发文章了 (1)，值得参考，对上手16S测序数据或宏基因组数据都很有帮助。\nFigure 1: Basic workflow preprocess 绝大多数这里介绍的软件都是仅支持linux平台的，我们做测序文件的上游分析也肯定是在服务器上做，个人PC一般很难满足需求，所以在做这些分析前必须先学习linux基础知识如文件系统，shell脚本编写，软件安装等。\n安装软件建议使用conda或mamba（新建环境和管理），有很多参考方法。\n我们服务器使用的是slurm作业管理系统，尽量先学习一下slurm的使用再尝试提交作业。\n一般把所有样本的测序双端文件放在一个文件夹下\n质控：fastp 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #!/bin/bash #SBATCH --job-name=fastp #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/fastp/log/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/fastp/log/%x_%a.err #SBATCH --array=1-33 #SBATCH --partition=short #SBATCH --cpus-per-task=8 echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` echo \u0026#34;SLURM_ARRAY_TASK_ID: \u0026#34; $SLURM_ARRAY_TASK_ID sample=$(head -n $SLURM_ARRAY_TASK_ID ~/work/asthma/data/namelist | tail -1) #sample=$(head -n 1 namelist | tail -1) echo handling: $sample #################### fastp -w 8 -i ~/work/asthma/data/$sample/$sample\u0026#39;_f1.fastq\u0026#39; -o ${i}_1 \\ -I ~/work/asthma/data/$sample/$sample\u0026#39;_r2.fastq\u0026#39; -O ${i}_2 -j ~/work/asthma/fastp/${i}.json #delete outputfile rm -rf ${i}_1 ${i}_2 #################### echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s 后面接一个python脚本就可以统计常用指标了。\n把所有的.json文件移到一个文件夹里，report/下，就可以统计了。\n去宿主：bowtie2 其实就是将序列比对到人类基因组上，没有比对到的序列整合成新文件就是去宿主后的了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #!/bin/bash #SBATCH --job-name=rm_human #SBATCH --output=/share/home/jianglab/pengchen/work/meta/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/meta/%x_%a.err #SBATCH --cpus-per-task=32 #SBATCH --partition=short echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` ############# for i in C1 C2 do bowtie2 -p 32 -x ~/db/humangenome/hg38 -1 seq/${i}_1.fq.gz \\ -2 seq/${i}_2.fq.gz -S ${i}.sam --un-conc ${i}.fq --very-sensitive done ############## echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s 基本信息统计 可以用FastqCount：\n1 2 3 4 ~/biosoft/FastqCount-master/FastqCount_v0.5 xx.fastq.gz Total Reads Total Bases N Bases Q20 Q30 GC 11568822 (11.57 M) 1702829127 (1.70 G) 0.00% 98.00% 94.00% 54.00% reads-based 物种注释：kraken2 Kraken 2是一个用于对高通量测序数据进行分类和标识物种的软件。它使用参考数据库中的基因组序列来进行分类，并使用k-mer方法来实现快速和准确的分类。\n使用Kraken 2进行基本分类的简单步骤：\n准备参考数据库：Kraken 2需要一个参考数据库，以便对测序数据进行分类。可以从NCBI、Ensembl或其他数据库下载相应的基因组序列，并使用Kraken 2内置的工具来构建数据库。\n安装Kraken 2：可以从Kraken 2官方网站下载并安装Kraken 2软件。\n运行Kraken 2：使用Kraken 2对测序数据进行分类需要使用以下命令：\nkraken2 \\--db \\\u0026lt;path_to_database\\\u0026gt; \\\u0026lt;input_file\\\u0026gt; \\--output \\\u0026lt;output_file\\\u0026gt;\n这里，**\u0026lt;path_to_database\u0026gt;是参考数据库的路径，\u0026lt;input_file\u0026gt;是需要进行分类的输入文件，\u0026lt;output_file\u0026gt;**是输出文件的名称。Kraken 2将输出一个分类报告文件和一个序列文件。\nkraken2-build --standard --threads 24 --db ./\n\u0026ndash;standard标准模式下只下载5种数据库：古菌archaea、细菌bacteria、人类human、载体UniVec_Core、病毒viral。也可选直接下载作者构建的索引，还包括bracken的索引。\n这个kraken数据库是可以自己构建的，所以适用于各种项目的物种注释，我做的比较多的是环境样本的宏基因组，就可能需要更全面的物种数据库（甚至除了各种微生物，还要动植物数据等），实验室的WX师姐收集构建了一个超大的物种库。\n需要注意的是kraken运行至少要提供数据库大小的内存大小（运行内存），因为它会把整个数据库载入内存后进行序列的注释，所以如果发现无法载入数据库的报错，可以尝试调大内存资源。\nkraken软件运行时载入数据库是一个十分耗时的步骤，而每条序列的鉴定时间差不多，所以我们可以将很多样本的fastq文件合并成一个大文件后输入kraken注释，之后再按照序列的数量拆分结果文件，这样多个样本也只需要载入一次数据库，节省时间。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #!/bin/bash #SBATCH --job-name=kraken2M #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/kraken/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/kraken/%x_%a.err #SBATCH --time=14-00:00:00 #SBATCH --partition=mem #SBATCH --cpus-per-task=32 #SBATCH --mem-per-cpu=100G fqp=~/work/asthma/data/CRR205159/ python /share/home/jianglab/shared/krakenDB/K2ols/kraken2M.py -t 32 \\ -i ${fqp} \\ -c 0.05 \\ -s _f1.fastq,_r2.fastq \\ -o ~/work/asthma/kraken/ \\ -d /share/home/jianglab/shared/krakenDB/mydb2 \\ -k ~/miniconda3/envs/waste/bin/kraken2 \\ -kt /share/home/jianglab/shared/krakenDB/K2ols/KrakenTools 输出文件格式 Kraken标准输出格式\n五列表 output\nC/U代表分类classified或非分类unclassifed\n序列ID\n物种注释\n比序列注释的区域，如98|94代表左端98bp，右端94bp比对至数据库\nLCA比对结果，如”562:13 561:4”代表13 k-mer比对至物种#562，4 k-mer比对至#561物种\n报告输出格式 report\n包括6列，方便整理下游分析。\n百分比\ncount\ncount最优\n(U)nclassified, (R)oot, (D)omain, (K)ingdom, (P)hylum, (C)lass, (O)rder, (F)amily, (G)enus, or (S)pecies. “G2”代表位于属一种间\nNCBI物种ID\n科学物种名\n常用的物种丰度表格式除了kraken report，还有mpa，spf，krona等格式，关于kraken结果的整理以及格式转换方式，有一些现成的脚本或者自己写。\nKrakenTools (jhu.edu) 就是一套很好用的kraken工具包，其中常用的有：\nextract_kraken_reads.py 此程序提取读取在任何用户指定的分类id处分类的内容。用户必须指定Kraken输出文件、序列文件和至少一个分类法ID。下面指定了其他选项。截至2021年4月19日，此脚本与KrakenUniq/Kraken2Uniq报告兼容。\ncombine_kreports.py This script combines multiple Kraken reports into a combined report file.\npython combine_kreports.py\n-r 1.KREPORT 2.KREPORT\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;Kraken-style reports to combine\n-o COMBINED.KREPORT\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;Output file\nkreport2krona.py This program takes a Kraken report file and prints out a krona-compatible TEXT file\n换成krona文件好画图。嘿嘿\nkrona装了一个excel的插件可以很容易画图\npython kreport2krona.py\n-r/\u0026ndash;report MYFILE.KREPORT\u0026hellip;.….Kraken report file\n-o/\u0026ndash;output MYFILE.KRONA\u0026hellip;\u0026hellip;.…Output Krona text file\nthen, ktImportText MYSAMPLE.krona -o MYSAMPLE.krona.html\n好看的网页就出来了。\nkreport2mpa.py This program takes a Kraken report file and prints out a mpa (MetaPhlAn) -style TEXT file\npython kreport2mpa.py\n-r/\u0026ndash;report MYFILE.KREPORT\u0026hellip;.….Kraken report file\n-o/\u0026ndash;output MYFILE.MPA.TXT\u0026hellip;.….Output MPA-STYLE text file\ncombine_mpa.py python combine_mpa.py\n-i/\u0026ndash;input MYFILE1.MPA MYFILE2.MPA\u0026hellip;.…Multiple MPA-STYLE text files (separated by spaces)\n-o/\u0026ndash;output MYFILE.COMBINED.MPA\u0026hellip;\u0026hellip;.…Output MPA-STYLE text file\nThis program combines multiple outputs from kreport2mpa.py. Files to be combined must have been generated using the same kreport2mpa.py options.\npython combine_mpa.py -i -o --intermediate-ranks\nHUMAnN HUMAnN2（The HMP Unified Metabolic Analysis Network 2）是一款用于分析人类微生物组的功能和代谢能力的工具。它通过将宏基因组序列与参考基因组数据库比对，利用MetaCyc代谢通路数据库和UniRef蛋白质序列数据库，分析微生物组在功能和代谢通路水平上的组成和活性。HUMAnN2还提供了多样性分析、关联分析和可视化工具，可用于深入研究人类微生物组对宿主健康的影响和治疗策略的制定等方面。\nHUMAnN2是由美国国家人类微生物组计划（HMP）开发的，目前最新版本为HUMAnN3，于2020年发布。与HUMAnN2相比，HUMAnN3改进了基因家族注释的方法，提高了注释精度和速度，并提供了新的功能和工具，如功能韧度分析、代谢指纹识别和多样性分析等。\n但是HUMAnN2的数据库基本都是与人相关的微生物，比较适合做各种人体微生物组（肠道，肺部，口腔，皮肤等等），对于环境样本可能unclassified比较多。\nHUMAnN2要求双端序列合并的文件作为输入，for循环根据实验设计样本名批量双端序列合并。\n物种组成调用MetaPhlAn2, bowtie2比对至核酸序列，解决有哪些微生物存在的问题；\n功能组成为humann2调用diamond比对至蛋白库11Gb，解决这些微生物参与哪些功能通路的问题；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 cd alldata for i in `cat ~/work/asthma/data/namelist` do echo $i cat ${i}_f1.fastq ${i}_r2.fastq \u0026gt;${i}_paired.fastq done #!/bin/bash #SBATCH --job-name=humann2 #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/humann/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/humann/%x_%a.err #SBATCH --array=1-32 #SBATCH --cpus-per-task=24 #SBATCH --partition=cpu echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` ############## myarray=(`cat ~/work/asthma/data/namelist`) echo $SLURM_ARRAY_TASK_ID #this is your single file name sample=${myarray[${SLURM_ARRAY_TASK_ID}]} echo handling: $sample humann2 --input data/alldata/${sample}_paired.fastq \\ --output temp/humann2/ --threads 24 ## 链接重要文件至humann2目录 ln temp/humann2/${sample}_paired_humann2_temp/${sample}_paired_metaphlan_bugs_list.tsv temp/humann2/ ## 删除临时文件 rm -rf temp/humann2/${sample}_paired_humann2_temp ############## echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s ## 合并、修正样本名、预览 merge_metaphlan_tables2.py \\ temp/humann2/*_metaphlan_bugs_list.tsv | \\ sed \u0026#39;s/_metaphlan_bugs_list//g\u0026#39; \\ \u0026gt; metaphlan2/taxonomy.tsv contigs-based 组装：megahit MegaHit是一个用于对高通量测序数据进行de novo组装的软件。它使用了一种基于短读比对和图形构建的算法来组装基因组，可以高效地处理大规模的数据集。以下是MegaHit的一些优点和适用情况：\n速度快：MegaHit的算法非常高效，可以处理大规模的数据集，通常比其他de novo组装工具更快。\n高质量的组装：MegaHit在组装结果的连通性和准确性方面表现优异，尤其在处理高GC含量基因组时效果显著。\n适用于不同类型的测序数据：MegaHit支持多种不同类型的测序数据，包括 Illumina HiSeq/MiSeq、IonTorrent和PacBio等平台。\n易于使用：MegaHit具有简单的命令行语法，方便用户进行组装操作，且具有中断点，避免失败后全部重跑。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #!/bin/bash #SBATCH --job-name=asthma_megahit #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/megahit/log/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/megahit/log/%x_%a.err #SBATCH --array=1-33 #SBATCH --partition=cpu #SBATCH --cpus-per-task=32 echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` echo \u0026#34;SLURM_ARRAY_TASK_ID: \u0026#34; $SLURM_ARRAY_TASK_ID sample=$(head -n $SLURM_ARRAY_TASK_ID ~/work/asthma/data/namelist | tail -1) #sample=$(head -n 1 namelist | tail -1) echo handling: $sample\t#################### megahit -t 32 -1 ~/work/asthma/data/$sample/$sample\u0026#39;_f1.fastq\u0026#39; \\ -2 ~/work/asthma/data/$sample/$sample\u0026#39;_r2.fastq\u0026#39; -o ~/work/asthma/megahit/$sample --out-prefix $sample #################### echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s 组装评估：QUAST QUAST代表质量评估工具。 QUAST可以使用参考基因组以及不使用参考基因组来评估装配。 QUAST生成详细的报告，表格和图解，以显示装配的不同方面。\n基因预测：Prodigal 输入文件：拼装好的序列文件 megahit/final.contigs.fa\n输出文件：prodigal预测的基因序列 prodigal/gene.fa\nprodigal不支持多线程运行，所以我们可以自行分割序列文件调用多个prodigal程序分别跑实现伪多线程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #!/bin/bash #SBATCH --job-name=prodigal #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/prodigal/log/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/prodigal/log/%x_%a.err #SBATCH --array=1-33 #SBATCH --partition=cpu #SBATCH --cpus-per-task=1 echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` echo \u0026#34;SLURM_ARRAY_TASK_ID: \u0026#34; $SLURM_ARRAY_TASK_ID sample=$(head -n $SLURM_ARRAY_TASK_ID ~/work/asthma/data/namelist | tail -1) #sample=$(head -n 1 namelist | tail -1) echo handling: $sample #################### prodigal -i ~/work/asthma/megahit/contigs/$sample.fa \\ -d ~/work/asthma/prodigal/$sample.gene.fa \\ -o ~/work/asthma/prodigal/$sample.gene.gff \\ -p meta -f gff grep \u0026#39;partial=00\u0026#39; ~/work/asthma/prodigal/$sample.gene.fa | cut -f1 -d \u0026#39; \u0026#39;| sed \u0026#39;s/\u0026gt;//\u0026#39; \u0026gt; ~/work/asthma/prodigal/$sample.fullid seqkit grep -f ~/work/asthma/prodigal/$sample.fullid ~/work/asthma/prodigal/$sample.gene.fa \u0026gt; ~/work/asthma/prodigal/fullgene/$sample.gene.fa #################### echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s ============================================================================ ## 统计基因数量 grep -c \u0026#39;\u0026gt;\u0026#39; temp/prodigal/gene.fa ## 统计完整基因数量，数据量大可只用完整基因部分 grep -c \u0026#39;partial=00\u0026#39; temp/prodigal/gene.fa ## 提取完整基因(完整片段获得的基因全为完整，如成环的细菌基因组) grep \u0026#39;partial=00\u0026#39; temp/prodigal/gene.fa | cut -f1 -d \u0026#39; \u0026#39;| sed \u0026#39;s/\u0026gt;//\u0026#39; \u0026gt; temp/prodigal/full_length.id seqkit grep -f temp/prodigal/full_length.id temp/prodigal/gene.fa \u0026gt; temp/prodigal/full_length.fa seqkit stat temp/prodigal/full_length.fa 去冗余： Cd-hit 上面产生了n个样本的基因预测结果文件，gene.fa文件要想办法整合为一个文件再去去冗余。\n1 2 3 4 5 6 7 8 9 10 #!/bin/bash #修改每条序列的名称，加上样本名 for i in `cat ~/work/asthma/data/namelist` do echo $i sed -i \u0026#34;/\u0026gt;/s/\u0026gt;/\u0026gt;${i}_/\u0026#34; $i.gene.fa done echo \u0026#39;start merge\u0026#39; cat *.gene.fa\u0026gt;all.fullgene.fa echo \u0026#39;done\u0026#39; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #!/bin/bash #SBATCH --job-name=cdhit #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/%x_%a.err #SBATCH --cpus-per-task=32 #SBATCH --partition=short echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` ############## ## 输入文件：prodigal预测的基因序列 all.fullgene.fa ## 输出文件：去冗余后的基因和蛋白序列：NR/nucleotide.fa;NR/protein.fa mkdir NR ## aS覆盖度，c相似度，G局部比对，g最优解，T多线程，M内存0不限制 ## 2万基因2m，2千万需要2000h，多线程可加速\tcd-hit-est -i prodigal/fullgene/all.fullgene.fa \\ -o NR/nucleotide.fa \\ -aS 0.9 -c 0.9 -G 0 -g 0 -T 0 -M 0 ## 统计非冗余基因数量，单次拼接结果数量下降不大，多批拼接冗余度高 echo \u0026#39;after remove, the number of genes: \u0026#39; grep -c \u0026#39;\u0026gt;\u0026#39; NR/nucleotide.fa ## 翻译核酸为对应蛋白序列，emboss ## emboss transeq工具，93.9 MB conda install emboss -y transeq -sequence NR/nucleotide.fa \\ -outseq NR/protein.fa -trim Y ## 序列名自动添加了_1，为与核酸对应要去除 sed -i \u0026#39;s/_1 / /\u0026#39; NR/protein.fa ############## echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s 基因定量：salmon 建立索引 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #!/bin/bash #SBATCH --job-name=salmon-index #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/%x_%a.err #SBATCH --cpus-per-task=32 #SBATCH --partition=short echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` ############## mkdir -p temp/salmon ## 建索引, -t序列, -i 索引，10s salmon index \\ -t NR/nucleotide.fa \\ -p 32 \\ -i temp/salmon/index ############## echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s 对每个样本定量 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #!/bin/bash #SBATCH --job-name=salmon #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/salmon/log/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/salmon/log/%x_%a.err #SBATCH --array=1-33 #SBATCH --partition=cpu #SBATCH --cpus-per-task=32 echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` echo \u0026#34;SLURM_ARRAY_TASK_ID: \u0026#34; $SLURM_ARRAY_TASK_ID sample=$(head -n $SLURM_ARRAY_TASK_ID ~/work/asthma/data/namelist | tail -1) #sample=$(head -n 1 namelist | tail -1) echo handling: $sample #################### ## 输入文件：去冗余后的基因和蛋白序列：NR/nucleotide.fa ## 输出文件：Salmon定量后的结果：salmon/gene.count;salmon/gene.TPM ## 定量，l文库类型自动选择，p线程，--meta宏基因组模式 salmon quant \\ -i temp/salmon/index -l A -p 32 --meta \\ -1 data/alldata/${sample}_f1.fastq \\ -2 data/alldata/${sample}_r2.fastq \\ -o temp/salmon/${sample}.quant #################### echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s 合并各样本结果 1 2 3 4 5 6 7 8 9 10 11 12 ## 合并 mkdir -p salmon salmon quantmerge \\ --quants temp/salmon/*.quant \\ -o salmon/gene.TPM salmon quantmerge \\ --quants temp/salmon/*.quant \\ --column NumReads -o salmon/gene.count sed -i \u0026#39;1 s/.quant//g\u0026#39; salmon/gene.* ## 预览结果表格 head -n3 salmon/gene.* 功能基因注释 上一步已经有了所有的基因和每个样本所有基因的read count定量结果，我们只需要对上一步的基因序列（或蛋白质序列）进行不同数据库的注释（很多软件都是用diamond比对，如果没有专用软件的数据库我们也可以自己用diamond比对），合并注释结果得到的就是功能丰度表。\ndiamond选择\u0026ndash;outfmt 6的输出结果和blastp一样：\n1. qseqid query sequence id 2. sseqid subject (e.g., reference genome) sequence id 3. pident percentage of identical matches 4. length alignment length 5. mismatch number of mismatches 6. gapopen number of gap openings 7. qstart start of alignment in query 8. qend end of alignment in query 9. sstart start of alignment in subject 10. send end of alignment in subject 11. evalue expect value 12. bitscore bit score 1 eggNOG(COG/KEGG/CAZy) EggNOG数据库收集了COG（Clusters of Orthologous Groups of proteins，直系同源蛋白簇）,构成每个COG的蛋白都是被假定为来自于一个祖先蛋白，因此是orthologs或者是paralogs。通过把所有完整基因组的编码蛋白一个一个的互相比较确定的。在考虑来自一个给定基因组的蛋白时，这种比较将给出每个其他基因组的一个最相似的蛋白（因此需要用完整的基因组来定义COG），这些基因的每一个都轮番地被考虑。如果在这些蛋白（或子集）之间一个相互的最佳匹配关系被发现，那么那些相互的最佳匹配将形成一个COG。这样，一个COG中的成员将与这个COG中的其他成员比起被比较的基因组中的其他蛋白更相像。\nEggNOG里面包含了GO，KEGG，CAZy等。\n1 2 3 4 5 6 7 8 9 ## 下载常用数据库，注意设置下载位置 mkdir -p ${db}/eggnog5 \u0026amp;\u0026amp; cd ${db}/eggnog5 ## -y默认同意，-f强制下载，eggnog.db.gz 7.9G+4.9G download_eggnog_data.py -y -f --data_dir ./ ## 下载方式2(可选)：链接直接下载 wget -c http://eggnog5.embl.de/download/emapperdb-5.0.0/eggnog.db.gz ## 7.9G wget -c http://eggnog5.embl.de/download/emapperdb-5.0.0/eggnog_proteins.dmnd.gz ## 4.9G gunzip *.gz 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #!/bin/bash #SBATCH --job-name=eggo #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/%x_%j.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/%x_%j.err #SBATCH --cpus-per-task=32 #SBATCH --partition=cpu echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` ############## #切换环境 ## diamond比对基因至eggNOG 5.0数据库, 1~9h，默认diamond 1e-3 mkdir -p temp/eggnog emapper.py --no_annot --no_file_comments --override \\ --data_dir ~/db/eggnog5 \\ -i NR/protein.fa \\ --cpu 32 -m diamond \\ -o temp/eggnog/protein ## 比对结果功能注释, 1h emapper.py \\ --annotate_hits_table temp/eggnog/protein.emapper.seed_orthologs \\ --data_dir ~/db/eggnog5 \\ --cpu 32 --no_file_comments --override \\ -o temp/eggnog/output ## 添表头, 1列为ID，9列KO，16列CAZy，21列COG，22列描述 sed \u0026#39;1 i Name\\tortholog\\tevalue\\tscore\\ttaxonomic\\tprotein\\tGO\\tEC\\tKO\\tPathway\\tModule\\tReaction\\trclass\\tBRITE\\tTC\\tCAZy\\tBiGG\\ttax_scope\\tOG\\tbestOG\\tCOG\\tdescription\u0026#39; \\ temp/eggnog/output.emapper.annotations \\ \u0026gt; temp/eggnog/output ############## echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s 2 碳水化合物dbCAN2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## dbCAN2 http://bcb.unl.edu/dbCAN2 ## 创建数据库存放目录并进入 mkdir -p ${db}/dbCAN2 \u0026amp;\u0026amp; cd ${db}/dbCAN2 ## 下载序列和描述 wget -c http://bcb.unl.edu/dbCAN2/download/CAZyDB.07312020.fa wget -c http://bcb.unl.edu/dbCAN2/download/Databases/CAZyDB.07302020.fam-activities.txt ## 备用数据库下载地址并解压 #wget -c http://210.75.224.110/db/dbcan2/CAZyDB.07312020.fa.gz #gunzip CAZyDB.07312020.fa.gz ## diamond建索引，800M，1m diamond --version ## 0.8.22/2.0.5 time diamond makedb \\ --in CAZyDB.07312020.fa \\ --db CAZyDB.07312020 1 2 3 4 5 6 7 8 ## 比对CAZy数据库, 用时2~18m; 加--sensitive更全但慢至1h mkdir -p temp/dbcan2 diamond blastp \\ --db ~/db/dbcan2/CAZyDB.07312020 \\ --query NR/protein.fa \\ --threads 64 -e 1e-5 --outfmt 6 \\ --max-target-seqs 1 --quiet \\ --out temp/dbcan2/gene_diamond.f6 3 ARGs（CARD） ## Github: https://github.com/arpcard/rgi\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #!/bin/bash #SBATCH --job-name=rgi #SBATCH --output=/share/home/jianglab/pengchen/work/asthma/%x_%a.out #SBATCH --error=/share/home/jianglab/pengchen/work/asthma/%x_%a.err #SBATCH --cpus-per-task=32 #SBATCH --partition=cpu echo start: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` start=`date +%s` ############## mkdir -p card rgi main --input_sequence ~/work/asthma/temp/protein.fa \\ --output_file card/protein \\ --input_type protein --num_threads 32 \\ --clean --alignment_tool DIAMOND ############## echo end: `date +\u0026#39;%Y-%m-%d %T\u0026#39;` end=`date +%s` echo TIME:`expr $end - $start`s 4 毒力因子VFDB 官网地址：http://www.mgc.ac.cn/VFs/ 在官网下载数据库时，带有setA 的库为VFDB数据库核心库(set A)，而setB为全库(setB), 其中setA仅包含经实验验证过的毒力基因，而setB则在setA的基础上增加了预测的毒力基因，选择好数据库后，直接用blast/diamond即可完成注释。\n1 2 3 4 5 6 7 mkdir -p temp/vfdb diamond blastp \\ --db ~/db/VFDB/VFDB_setB_pro \\ --query NR/protein.fa \\ --threads 32 -e 1e-5 --outfmt 6 \\ --max-target-seqs 1 --quiet \\ --out temp/vfdb/gene_diamond.f6 5 其他各种数据库 功能注释合并 写一个python脚本，将表1（基因-功能的对应表）与表2（基因丰度表）合并，即不同基因可能注释到相同功能，把它们的丰度加在一起得到新表3（功能丰度表）\nbinning 宏基因组binning是指将不同的序列集合（如metagenome序列集合）根据它们的物种归类到不同的bins中，以便进一步研究它们的组成和功能。这个过程可以将类似的序列组合在一起，形成代表不同物种或基因组的bins，以便进行后续分析，如物种注释、基因组组装等。\n以下是常用的宏基因组binning方法：\n基于聚类的方法：该方法使用序列聚类将相似序列分到同一个bin中。一般来说，聚类算法可分为两类：无监督聚类（如k-means、DBSCAN等）和有监督聚类（如CAMI、MyCC等）。\n基于组装的方法：该方法使用de novo组装来将相似序列组装成连续的序列，再根据这些序列的基因组信息来将其分类到不同的bins中。这种方法的优点是可以更好地处理重复序列，缺点是需要大量的计算资源和时间。\n基于分类器的方法：该方法使用机器学习分类器来将序列分配到不同的bins中。这种方法的优点是可以自动学习特征并在处理大规模数据时效率高，缺点是需要先建立一个分类器并进行训练。\n在进行宏基因组binning时，通常需要使用多个方法进行比较，以选择最适合数据集的方法。可以使用一些流行的工具来进行binning，如MetaBAT、MaxBin、CONCOCT和MEGAN等。这些工具通常包含各种binning方法，可以根据数据集和分析目的选择适合的方法。\n篇幅限制，具体的方法放在另一篇里面讲解吧。\nReference 1. Y.-X. Liu, Y. Qin, T. Chen, M. Lu, X. Qian, X. Guo, Y. Bai, A practical guide to amplicon and metagenomic analysis of microbiome data. Protein \u0026amp; Cell. 12, 315–330 (2021).\n","date":"2023-03-26T00:00:00Z","permalink":"/p/metagenomic-workflow/","title":"Metagenomic workflow"},{"content":"春分刚过，校园许多花儿都争相绽放。天气还是有点冷，但还是想跟群青同学一起逛逛紫金港，赏赏花，观观鸟。\n这个时候校园里最多的便是蔷薇科的花了，虽然我向来是”桃李杏梅樱，傻傻分不清”的😂，这次在群青同学的帮助下收集到了九宫格：菊花桃，碧桃，垂丝海棠，西府海棠，湖北海棠，大岛樱，日本晚樱，日本樱花，蓬蘽(疑似)\n日本樱花 大岛樱 日本晚樱 西府海棠 湖北海棠 垂丝海棠 菊花桃 碧桃 蓬蘽(疑似) 湖心岛出发，大片的二月兰，刚冒芽的水杉，偷偷绽放的水仙和蝴蝶花。\n二月兰 水仙 蝴蝶花 水杉 早樱 鸟儿大多还是老朋友，快步走的白鹡鸰，悠闲的黑水鸡和斑嘴鸭，大喜鹊和红嘴蓝鹊，一只歌声婉转的乌鸫。本来这次最想看到的就是罕见旅客黑翅长脚鹬的，但是这儿果然只是它们歇歇脚的地方，没能见到😭，偷浙大官微的美图，哈哈。南花园还是夜鹭与白鹭们的领地。\n白鹡鸰 黑水鸡 斑嘴鸭 喜鹊 夜鹭 乌鸫 黑翅长脚鹬 （浙江大学B站号） 红嘴蓝鹊 生物实验中心之前每年这个时候都是大片油菜花，打卡圣地，但今年的试验田搬到了银泉，这里居然种满了麦子，绿油油的麦田非常治愈。去年的油菜花应该还留下了一些种子，这个我叫做单双子叶的碰撞。\n单双子叶的碰撞 惊喜出现在麦田的拐角处，几只可爱的啾啾正在偷麦子吃，原来是白腰文鸟，上次见它也是在偷吃生科院的实验水稻。站在紫荆丛中的文鸟超有气质。\n其他一些瞬间，医学院的一排樱花，LY同学最赞的一株樱花，已经吃了四年还要再吃四年的麦香，晶莹的水珠…\n医学院 药学院 医图 麦香 感谢群青同学的摄影，越来越强了👍。下一个季节再来看看。\n","date":"2023-03-25T00:00:00Z","image":"/p/%E7%B4%AB%E9%87%91%E6%98%A5%E6%97%A5/images/%E8%A5%BF%E5%BA%9C_hu9cec70a3d2a230bf39151bcb5362fd23_124766_120x120_fill_q75_box_smart1.jpg","permalink":"/p/%E7%B4%AB%E9%87%91%E6%98%A5%E6%97%A5/","title":"紫金春日"},{"content":"Introduction 统计分析在生物信息学中具有非常重要的意义，因为生物信息学研究的数据量庞大、复杂性高，而统计分析可以帮助我们更好地理解和解释这些数据。下面是统计分析对生物信息学的几个重要意义：\n数据清洗和预处理：生物信息学研究中经常需要处理大规模的数据，而这些数据可能存在噪声、错误和缺失值等问题。统计分析可以帮助我们对数据进行清洗和预处理，以确保数据的质量和可靠性。 数据可视化：统计分析可以帮助我们将复杂的数据转化为可视化图形，从而更好地理解数据的分布、关系和趋势。这些图形可以帮助我们发现隐藏在数据中的模式和规律。 数据分析：生物信息学研究中需要对大量的数据进行分析，例如比较基因组学、转录组学、蛋白质组学等。统计分析可以帮助我们对数据进行建模和预测，从而深入探究生物学的复杂现象和机制。 数据挖掘：生物信息学研究中需要挖掘大量的数据来发现新的生物学现象和机制。统计分析可以帮助我们从数据中提取出有用的信息和知识，进而推动生物学的研究和发展。 R语言是一个专门用于数据分析和统计建模的编程语言，它有以下几个优点，使其成为做统计分析的理想选择：\n免费和开源：R语言是一个免费和开源的软件，可以在不付出额外成本的情况下使用和定制。这使得许多学生、学者和数据分析师选择R语言作为他们的首选统计分析工具。\n强大的数据处理能力：R语言具有强大的数据处理能力，支持多种数据结构和数据类型，可以轻松地进行数据清洗、整合、变换和分析。\n丰富的统计分析函数库：R语言具有丰富的统计分析函数库，包括线性回归、逻辑回归、聚类分析、主成分分析、时间序列分析等等。这些函数库提供了许多常用的统计分析方法，可以满足不同数据分析需求。\n图形可视化功能：R语言具有强大的图形可视化功能，可以轻松地创建各种类型的图表，包括散点图、条形图、折线图、热图等。这些图表可以帮助数据分析师更好地理解数据、发现规律和提取信息。\n社区支持和生态系统：R语言拥有庞大的用户社区和生态系统，用户可以轻松地找到并使用数千种可用的统计分析工具和R包，这些工具和R包可以帮助用户更加高效地完成统计分析任务。\n我想在这里稍微记录一下我使用R常用的一些初等统计分析方法，如回归，方差分析，广义线性模型等，主要参考资料是《R语言教程》 VII部分统计分析的内容。\nStatistics 基础用法 单样本均值检验 1 2 3 4 5 6 7 ?t.test() #install.packages(\u0026#34;ggstatsplot\u0026#34;,dependencies = T) library(ggstatsplot) #这个包会在画图的过程中计算很多统计量，帮我们更好地把握数据的性质 #比如我们想看tooth length均值是否和25有显著差异 t.test(ToothGrowth$len,mu = 25,alternative = \u0026#34;two.sided\u0026#34;) ## ## One Sample t-test ## ## data: ToothGrowth$len ## t = -6.2648, df = 59, p-value = 0.00000004681 ## alternative hypothesis: true mean is not equal to 25 ## 95 percent confidence interval: ## 16.83731 20.78936 ## sample estimates: ## mean of x ## 18.81333 1 2 3 4 5 6 gghistostats( data = ToothGrowth, x = len, xlab = \u0026#34;Tooth length\u0026#34;, test.value = 25 ) 检验的功效， 是指对立假设成立时检验拒绝$H_0$的概率$1-\\beta$， 其中$\\beta$是第二类错误， 即当对立假设成立时错误地接受$H_0$的概率。 需要足够大的样本量才能使得检验能够发现实际存在的显著差异。\n1 2 3 4 5 6 7 pwr::pwr.t.test( type = \u0026#34;one.sample\u0026#34;, alternative=\u0026#34;greater\u0026#34;, d = (7.25 - 7.0)/1.052, sig.level = 0.05, power = 0.80 ) |\u0026gt; plot() 均值比较 独立两样本t检验\n1 t.test(mpg~am,data = mtcars) ## ## Welch Two Sample t-test ## ## data: mpg by am ## t = -3.7671, df = 18.332, p-value = 0.001374 ## alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0 ## 95 percent confidence interval: ## -11.280194 -3.209684 ## sample estimates: ## mean in group 0 mean in group 1 ## 17.14737 24.39231 1 ggbetweenstats(mtcars, am, mpg) 比例检验 1 2 #抽查400个样本100个异常，异常比例是否显著大于0.2 prop.test(100, 400, p=0.20, alternative = \u0026#34;greater\u0026#34;) ## ## 1-sample proportions test with continuity correction ## ## data: 100 out of 400, null probability 0.2 ## X-squared = 5.9414, df = 1, p-value = 0.007395 ## alternative hypothesis: true p is greater than 0.2 ## 95 percent confidence interval: ## 0.2149649 1.0000000 ## sample estimates: ## p ## 0.25 1 2 #两次抽查的比例是否一致 prop.test(c(35,27), c(250,300), alternative = \u0026#34;two.sided\u0026#34;) ## ## 2-sample test for equality of proportions with continuity correction ## ## data: c(35, 27) out of c(250, 300) ## X-squared = 2.9268, df = 1, p-value = 0.08712 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.007506845 0.107506845 ## sample estimates: ## prop 1 prop 2 ## 0.14 0.09 方差的假设检验 检查两组数据的方差有误显著差异？\n1 2 3 4 var.test(c( 20.5, 18.8, 19.8, 20.9, 21.5, 19.5, 21.0, 21.2), c( 17.7, 20.3, 20.0, 18.8, 19.0, 20.1, 20.2, 19.1), alternative = \u0026#34;two.sided\u0026#34;) ## ## F test to compare two variances ## ## data: c(20.5, 18.8, 19.8, 20.9, 21.5, 19.5, 21, 21.2) and c(17.7, 20.3, 20, 18.8, 19, 20.1, 20.2, 19.1) ## F = 1.069, num df = 7, denom df = 7, p-value = 0.9322 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.214011 5.339386 ## sample estimates: ## ratio of variances ## 1.068966 拟合优度检验 1 2 #6类face的count比例是否相等，卡方检验 chisq.test(c(168, 159, 168, 180, 167, 158)) ## ## Chi-squared test for given probabilities ## ## data: c(168, 159, 168, 180, 167, 158) ## X-squared = 1.892, df = 5, p-value = 0.8639 1 2 3 4 5 6 7 ggpiestats( data = data.frame(face=1:6, counts=c(168, 159, 168, 180, 167, 158)), x = face, counts = counts, title = \u0026#34;Dice equality\u0026#34; ) 1 2 #各类比例是否为指定值 chisq.test(c(48, 98, 54), p=c(0.3, 0.5, 0.2)) ## ## Chi-squared test for given probabilities ## ## data: c(48, 98, 54) ## X-squared = 7.34, df = 2, p-value = 0.02548 检验分布类型 vcd包提供了一个goodfit函数， 可以用来拟合指定的某种理论分布(包括泊松、二项、负二项分布）， 并检验服从该理论分布的零假设。\n1 2 3 set.seed(101) datax \u0026lt;- rpois(100, 2) summary(vcd::goodfit(datax, \u0026#34;poisson\u0026#34;)) ## ## Goodness-of-fit test for poisson distribution ## ## X^2 df P(\u0026gt; X^2) ## Likelihood Ratio 4.289456 5 0.5085374 独立性卡方检验 1 2 3 4 5 6 ctab.beer \u0026lt;- rbind(c( 20, 40, 20), c(30,30,10)) colnames(ctab.beer) \u0026lt;- c(\u0026#34;Light\u0026#34;, \u0026#34;Regular\u0026#34;, \u0026#34;Dark\u0026#34;) rownames(ctab.beer) \u0026lt;- c(\u0026#34;Male\u0026#34;, \u0026#34;Female\u0026#34;) addmargins(ctab.beer) ## Light Regular Dark Sum ## Male 20 40 20 80 ## Female 30 30 10 70 ## Sum 50 70 30 150 1 2 #列联表独立性检验： chisq.test(ctab.beer) ## ## Pearson's Chi-squared test ## ## data: ctab.beer ## X-squared = 6.1224, df = 2, p-value = 0.04683 1 #在0.05水平下认为啤酒类型偏好与性别有关 非参数检验 常用的有独立两样本比较的Wilcoxon秩和检验， 单样本的符号秩检验和符号检验等\n1 2 3 x \u0026lt;- c(0.80, 0.83, 1.89, 1.04, 1.45, 1.38, 1.91, 1.64, 0.73, 1.46) y \u0026lt;- c(1.15, 0.88, 0.90, 0.74, 1.21) wilcox.test(x,mu = 0.7) ## ## Wilcoxon signed rank exact test ## ## data: x ## V = 55, p-value = 0.001953 ## alternative hypothesis: true location is not equal to 0.7 1 wilcox.test(x, y, alternative = \u0026#34;g\u0026#34;) ## ## Wilcoxon rank sum exact test ## ## data: x and y ## W = 35, p-value = 0.1272 ## alternative hypothesis: true location shift is greater than 0 回归分析 相关分析 Pearson相关系数： $$ \\rho(X,Y)=\\frac{E[(X-E(X))(Y-E(Y))]}{\\sqrt{Var(X)Var(Y)}} $$ 相关系数绝对值在0.8以上认为高度相关。 在0.5到0.8之间认为中度相关。 在0.3到0.5之间认为低度相关。 在0.3以下认为不相关或相关性很弱以至于没有实际价值。 当然，在特别重要的问题中， 只要经过检验显著不等于零的相关都认为是有意义的。\n相关系数检验：\n检验统计量: $$ t=\\frac{r\\sqrt{n-2}}{\\sqrt{1-r^2}} $$ p值为：$P(|t(n-2)|\u0026gt;|t_0|)$\n1 2 3 4 5 6 7 set.seed(1) x \u0026lt;- runif(30, 0, 10) xx \u0026lt;- seq(0, 10, length.out = 100) y \u0026lt;- 40 - (x-7)^2 + rnorm(30) yy \u0026lt;- 40 - (xx-7)^2 plot(x, y, pch=16) lines(xx, yy) 1 cor(x,y,method = \u0026#34;pearson\u0026#34;) ## [1] 0.8244374 1 cor.test(x,y,method = \u0026#34;pearson\u0026#34;) ## ## Pearson's product-moment correlation ## ## data: x and y ## t = 7.7083, df = 28, p-value = 0.00000002136 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.6602859 0.9134070 ## sample estimates: ## cor ## 0.8244374 1 2 3 4 5 ggstatsplot::ggscatterstats( data = data.frame(x,y), x = x, y = y ) 相关性矩阵，`n*n`或`n*m`的$r$ 和$p-value$矩阵 1 2 3 ggstatsplot::ggcorrmat( data = mtcars ) 1 pcutils::cor_plot(mtcars) 1 corrplot::corrplot(cor(mtcars)) 1 ggcorrplot::ggcorrplot(cor(mtcars),method = \u0026#34;circle\u0026#34;) Spearman秩相关系数 Spearman rho系数， 是两个变量的秩统计量的相关系数\nKendall tau系数 当变量正相关性很强时， 任意两个观测的X值的大小顺序应该与Y值的大小顺序相同； 如果独立， 一对观测的X值比较和Y值比较顺序相同与顺序相反的数目应该基本相同。Kandall tau系数也是取值于区间[-1,1]， 用这样的思想表示两个变量的相关性和正负。\n1 cor.test(x,y,method = \u0026#34;spearman\u0026#34;) ## ## Spearman's rank correlation rho ## ## data: x and y ## S = 922, p-value = 0.000001339 ## alternative hypothesis: true rho is not equal to 0 ## sample estimates: ## rho ## 0.7948832 1 cor.test(x,y,method = \u0026#34;kendall\u0026#34;) ## ## Kendall's rank correlation tau ## ## data: x and y ## T = 354, p-value = 0.000000159 ## alternative hypothesis: true tau is not equal to 0 ## sample estimates: ## tau ## 0.6275862 一元回归 $$ Y=a+bX+\\varepsilon, \\varepsilon \\sim N(0,\\sigma^2) $$\n最小二乘法 $$ \\hat{b}=\\frac{\\sum_i(x_i-\\overline{x})(y_i-\\overline{y})}{\\sum_i{(x-x_i)}^2}=r_{xy}\\frac{S_y}{S_x} $$\n$$ \\hat{a}=\\overline{y}-\\hat{b}\\overline{x} $$ 回归有效性可以用$R^2$和$p-value$来度量， $R^2=1-\\frac{SSE}{SST}$\n统计量$F=\\frac{SSR}{SSE/(n-2)}$,$p-value$为$P(F(1,n-2)\u0026gt;c)$,c为F的值。\n1 2 lm1 \u0026lt;- lm(y ~ x) summary(lm1) ## ## Call: ## lm(formula = y ~ x) ## ## Residuals: ## Min 1Q Median 3Q Max ## -17.856 -4.549 2.141 6.048 9.664 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 9.9855 2.6930 3.708 0.000914 *** ## x 3.5396 0.4592 7.708 0.0000000214 *** ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Residual standard error: 7.302 on 28 degrees of freedom ## Multiple R-squared: 0.6797,\tAdjusted R-squared: 0.6683 ## F-statistic: 59.42 on 1 and 28 DF, p-value: 0.00000002136 1 2 #prediction predict(lm1,newdata =data.frame(x=c(5,10,15))) ## 1 2 3 ## 27.68364 45.38182 63.08000 1 pcutils::my_lm(y,x) 多元回归 1 2 lm2 \u0026lt;- lm(mpg ~ cyl + disp, data=mtcars) summary(lm2) ## ## Call: ## lm(formula = mpg ~ cyl + disp, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.4213 -2.1722 -0.6362 1.1899 7.0516 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 34.66099 2.54700 13.609 4.02e-14 *** ## cyl -1.58728 0.71184 -2.230 0.0337 * ## disp -0.02058 0.01026 -2.007 0.0542 . ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Residual standard error: 3.055 on 29 degrees of freedom ## Multiple R-squared: 0.7596,\tAdjusted R-squared: 0.743 ## F-statistic: 45.81 on 2 and 29 DF, p-value: 0.000000001058 1 ggstatsplot::ggcoefstats(lm2) 1 2 #回归自变量筛选 lm3 \u0026lt;- step(lm(mpg ~ cyl + disp+hp+drat+vs, data=mtcars)) ## Start: AIC=77.08 ## mpg ~ cyl + disp + hp + drat + vs ## ## Df Sum of Sq RSS AIC ## - vs 1 0.3134 244.90 75.124 ## - cyl 1 7.6839 252.27 76.073 ## - drat 1 14.3330 258.92 76.905 ## - disp 1 14.6709 259.26 76.947 ## \u0026lt;none\u0026gt; 244.59 77.083 ## - hp 1 19.8255 264.41 77.577 ## ## Step: AIC=75.12 ## mpg ~ cyl + disp + hp + drat ## ## Df Sum of Sq RSS AIC ## - cyl 1 8.444 253.35 74.209 ## - disp 1 14.765 259.67 74.997 ## \u0026lt;none\u0026gt; 244.90 75.124 ## - drat 1 16.467 261.37 75.206 ## - hp 1 19.613 264.51 75.589 ## ## Step: AIC=74.21 ## mpg ~ disp + hp + drat ## ## Df Sum of Sq RSS AIC ## \u0026lt;none\u0026gt; 253.35 74.209 ## - drat 1 30.148 283.49 75.806 ## - disp 1 38.107 291.45 76.693 ## - hp 1 49.550 302.90 77.925 多重共线性\n狭义的多重共线性（multicollinearity）： 自变量的数据存在线性组合近似地等于零， 使得解线性方程组求解回归系数时结果不稳定， 回归结果很差。\n广义的多重共线性： 自变量之间存在较强的相关性， 这样自变量是联动的， 互相之间有替代作用。 甚至于斜率项的正负号都因为这种替代作用而可能是错误的方向。\n1 2 #car包的vif()函数计算方差膨胀因子 car::vif(lm3) ## disp hp drat ## 4.621988 2.868264 2.166843 非参数回归 所谓参数回归， 是指回归函数有预先确定的公式， 仅需要估计的未知参数； 非参数回归， 就是没有预先确定的公式， 的形式本身也依赖于输入的样本, 。 下面描述的核回归就是这样典型的非参数回归， 样条平滑、样条函数回归一般也看作是非参数回归。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #样条平滑 set.seed(1) nsamp \u0026lt;- 30 x \u0026lt;- runif(nsamp, -10, 10) xx \u0026lt;- seq(-10, 10, length.out=100) x \u0026lt;- sort(x) y \u0026lt;- 10*sin(x/10*pi)^2 + rnorm(nsamp,0,0.3) plot(x, y) curve(10*sin(x/10*pi)^2, -10, 10, add=TRUE, lwd=2) library(splines) res \u0026lt;- smooth.spline(x, y) lines(spline(res$x, res$y), col=\u0026#34;red\u0026#34;) res2 \u0026lt;- loess(y ~ x, degree=2, span=0.3) lines(xx, predict(res2, newdata=data.frame(x=xx)), col=\u0026#34;blue\u0026#34;) legend(\u0026#34;top\u0026#34;, lwd=c(2,1,1), col=c(\u0026#34;black\u0026#34;, \u0026#34;red\u0026#34;, \u0026#34;blue\u0026#34;), legend=c(\u0026#34;real data\u0026#34;, \u0026#34;smooth.spline\u0026#34;, \u0026#34;local lm\u0026#34;)) 1 2 3 4 ## 线性可加模型 ## R扩展包mgcv的gam()函数可以执行这样的可加模型的非参数回归拟合。 lm.rock \u0026lt;- lm(log(perm) ~ area + peri + shape, data=rock) summary(lm.rock) ## ## Call: ## lm(formula = log(perm) ~ area + peri + shape, data = rock) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.8092 -0.5413 0.1734 0.6493 1.4788 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 5.33314499 0.54867792 9.720 1.59e-12 *** ## area 0.00048498 0.00008657 5.602 1.29e-06 *** ## peri -0.00152661 0.00017704 -8.623 5.24e-11 *** ## shape 1.75652601 1.75592362 1.000 0.323 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Residual standard error: 0.8521 on 44 degrees of freedom ## Multiple R-squared: 0.7483,\tAdjusted R-squared: 0.7311 ## F-statistic: 43.6 on 3 and 44 DF, p-value: 3.094e-13 1 2 gam.rock1 \u0026lt;- mgcv::gam(log(perm) ~ s(area) + s(peri) + s(shape), data=rock) summary(gam.rock1) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## log(perm) ~ s(area) + s(peri) + s(shape) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 5.1075 0.1222 41.81 \u0026lt;2e-16 *** ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(area) 1.000 1.000 29.13 0.00000307 *** ## s(peri) 1.000 1.000 71.30 \u0026lt; 2e-16 *** ## s(shape) 1.402 1.705 0.58 0.437 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## R-sq.(adj) = 0.735 Deviance explained = 75.4% ## GCV = 0.78865 Scale est. = 0.71631 n = 48 1 plot(gam.rock1) ##方差分析\n单因素方差分析可以看成基础统计中两样本t检验的一个推广， 要比较试验观测值的某个因变量（称为“指标”）按照一个分组变量（称为“因素”）分组后， 各组的因变量均值有无显著差异。\n1 2 3 mtcars$cyl=as.factor(mtcars$cyl) aov.manu \u0026lt;- aov(mpg ~ cyl, data=mtcars) summary(aov.manu) ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## cyl 2 824.8 412.4 39.7 0.00000000498 *** ## Residuals 29 301.3 10.4 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 1 pcutils::group_box(mtcars[\u0026#34;mpg\u0026#34;],group = \u0026#34;cyl\u0026#34;,metadata = mtcars) 1 2 #非参数形式 kruskal.test(mpg ~ cyl, data=mtcars) ## ## Kruskal-Wallis rank sum test ## ## data: mpg by cyl ## Kruskal-Wallis chi-squared = 25.746, df = 2, p-value = 0.000002566 进行多个假设检验（如均值比较）的操作称为*“多重比较”*（multiple comparison， 或multiple testing）， 多次检验会使得总第一类错误概率增大。\n1 pcutils::multitest(mtcars$mpg,mtcars$cyl) ## ====================================1.ANOVA:==================================== ## Df Sum Sq Mean Sq F value Pr(\u0026gt;F) ## group 2 824.8 412.4 39.7 0.00000000498 *** ## Residuals 29 301.3 10.4 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ================================2.Kruskal.test:================================ ## ## Kruskal-Wallis rank sum test ## ## data: var by group ## Kruskal-Wallis chi-squared = 25.746, df = 2, p-value = 0.000002566 ## ## ==========================3.LSDtest, bonferroni p-adj:========================== ## var groups ## 4 26.66364 a ## 6 19.74286 b ## 8 15.10000 c ## ==================================4.tukeyHSD:================================== ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = var ~ group) ## ## $group ## diff lwr upr p adj ## 6-4 -6.920779 -10.769350 -3.0722086 0.0003424 ## 8-4 -11.563636 -14.770779 -8.3564942 0.0000000 ## 8-6 -4.642857 -8.327583 -0.9581313 0.0112287 ## ## =================================5.Wilcox-test:================================= ## 4 6 8 ## 4 1.00000000000 0.0006658148 0.00002774715 ## 6 0.00066581478 1.0000000000 0.00101304469 ## 8 0.00002774715 0.0010130447 1.00000000000 ##广义线性模型\n泊松回归 1 2 3 4 5 6 counts \u0026lt;- c(18,17,15,20,10,20,25,13,12) outcome \u0026lt;- gl(3,1,9) treatment \u0026lt;- gl(3,3) D93=data.frame(treatment, outcome, counts) ## showing data ggplot(data = D93, mapping = aes(x = counts)) +geom_bar() 1 2 glm.D93 \u0026lt;- glm(counts ~ outcome + treatment,data = D93, family = poisson()) summary(glm.D93) ## ## Call: ## glm(formula = counts ~ outcome + treatment, family = poisson(), ## data = D93) ## ## Deviance Residuals: ## 1 2 3 4 5 6 7 8 ## -0.67125 0.96272 -0.16965 -0.21999 -0.95552 1.04939 0.84715 -0.09167 ## 9 ## -0.96656 ## ## Coefficients: ## Estimate Std. Error z value Pr(\u0026gt;|z|) ## (Intercept) 3.045e+00 1.709e-01 17.815 \u0026lt;2e-16 *** ## outcome2 -4.543e-01 2.022e-01 -2.247 0.0246 * ## outcome3 -2.930e-01 1.927e-01 -1.520 0.1285 ## treatment2 -3.242e-16 2.000e-01 0.000 1.0000 ## treatment3 -2.148e-16 2.000e-01 0.000 1.0000 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 10.5814 on 8 degrees of freedom ## Residual deviance: 5.1291 on 4 degrees of freedom ## AIC: 56.761 ## ## Number of Fisher Scoring iterations: 4 逻辑斯谛回归 ….\n","date":"2023-03-24T00:00:00Z","image":"/p/r-statistics/index.en_files/figure-html/unnamed-chunk-4-1_hu6a7295393dc4d80def3bf7388e19d776_109022_120x120_fill_box_smart1_3.png","permalink":"/p/r-statistics/","title":"R-statistics"},{"content":"在Rblogdown使用stack-theme遇到了几个问题，应该是Rblogdown与原生hugo间的不太兼容。\n我很快发现了问题是Rmd产生的md文件可能跟stack主题不太匹配，一开始想看看yaml文件能不能修改解决，但找了不少地方都没找到😭。\n因为问题还比较确定，可以试试自己写脚本转换Rmd产生的md文件。\n公式问题 rblogdown 渲染Rmd成md会把我写的公式语法改变：\n例如： $a=sum_i^2$变成$a=sum_i^2$\n但是stack主题识别不了后面那种语法，这个比较简单：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import re # 定义一个正则表达式，匹配LaTeX数学公式中的起始和结束行内数学模式符号 pattern = r\u0026#39;\\\\\\((.*?)\\\\\\)\u0026#39; # 定义一个字符串，包含要处理的LaTeX字符串 latex_string = r\u0026#39;For the equation$\\sum_{i=1}^n i^2$\u0026#39; # 使用sub()函数替换匹配到的文本 processed_string = re.sub(pattern, r\u0026#39;$\\1$\u0026#39;, latex_string) # 输出处理后的字符串 print(processed_string) a=re.sub(r\u0026#39;`\\\\\\((.*?)\\\\\\)`\u0026#39;,r\u0026#39;$\\1$\u0026#39;,$a=sum_i^2$jjjh$a=sum_i^2$\u0026#34;) 图片大小调整 因为![from data to viz website](images/data2viz.png){width=60%}这种语法是stack主题不支持的， 但是\n1 2 3 \u0026#39;\u0026lt;p style=\u0026#34;text-align: center;\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;images/data2viz.png\u0026#34; width=\u0026#34;60%\u0026#34; title=\u0026#34;from data to viz website\u0026#34;/\u0026gt; \u0026lt;/p\u0026gt;\u0026#39; 这种语法是支持的，所以想写一个小脚本转换一下\n自己不太熟悉正则（上面那个公式转换的也是他帮我写的，哈哈），所以试试问了ChatGPT ：\n可以帮我写一个将插入图片的markdown语法转换为html语法的小脚本吗？ 比如：![A](B.png){width=60%}转换为\u0026lt;img src=\u0026quot;B.png\u0026quot; width=\u0026quot;60%\u0026quot; title=\u0026quot;A\u0026quot;/\u0026gt;\n它立马用python帮我写了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 import re def convert_markdown_to_html(markdown_text): # 将插入图片的Markdown语法转换为HTML语法 pattern = r\u0026#34;!\\[(.*?)\\]\\((.*?)\\){(.*?)}\u0026#34; matches = re.findall(pattern, markdown_text) for match in matches: title = match[0] src = match[1] attributes = match[2].split(\u0026#34;,\u0026#34;) attr_dict = dict([tuple(attribute.split(\u0026#34;=\u0026#34;)) for attribute in attributes]) html_tag = f\u0026#39;\u0026lt;img src=\u0026#34;{src}\u0026#34; title=\u0026#34;{title}\u0026#34;\u0026#39; for key, value in attr_dict.items(): html_tag += f\u0026#39; {key}=\u0026#34;{value}\u0026#34;\u0026#39; html_tag += \u0026#34;/\u0026gt;\u0026#34; markdown_text = markdown_text.replace(f\u0026#34;![{title}]({src}){{{match[2]}}}\u0026#34;, html_tag) return markdown_text def convert_latex_to_md(markdown_text): html_text=re.sub(r\u0026#39;`\\\\\\((.*?)\\\\\\)`\u0026#39;,r\u0026#39;$\\1$\u0026#39;,markdown_text) return html_text def convert_markdown_file_to_html(file_path): # 读取Markdown文件 with open(file_path, \u0026#34;r\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: markdown_text = f.read() # 将Markdown语法转换为HTML语法 html_text = convert_markdown_to_html(markdown_text) html_text = convert_latex_to_md(html_text) # 将HTML文本写入文件 with open(file_path, \u0026#34;w\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f: f.write(html_text) if __name__ == \u0026#34;__main__\u0026#34;: file_path = \u0026#34;index.md\u0026#34; convert_markdown_file_to_html(file_path) 牛牛牛！ 再问一下，可以用R语言写一下吗？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 convert_markdown_to_html \u0026lt;- function(markdown_text) { # 通过正则表达式匹配图片语法 matches \u0026lt;- gregexpr(\u0026#34;!\\\\[(.*?)\\\\]\\\\((.*?)\\\\){(.*?)}\u0026#34;, markdown_text, perl = TRUE) # 遍历匹配结果，将Markdown语法替换为HTML语法 for (i in seq_along(matches[[1]])) { # 判断匹配结果是否为空列表 if (length(matches[[1]][i]) == 0) { next } match \u0026lt;- regmatches(markdown_text, matches[[1]][i]) title \u0026lt;- match[[2]] src \u0026lt;- match[[3]] attributes \u0026lt;- strsplit(match[[4]], \u0026#34;,\u0026#34;)[[1]] attr_dict \u0026lt;- setNames(sapply(strsplit(attributes, \u0026#34;=\u0026#34;), \u0026#34;[\u0026#34;, 2), sapply(strsplit(attributes, \u0026#34;=\u0026#34;), \u0026#34;[\u0026#34;, 1)) # 构造HTML标签 html_tag \u0026lt;- sprintf(\u0026#39;\u0026lt;img src=\u0026#34;%s\u0026#34; title=\u0026#34;%s\u0026#34;\u0026#39;, src, title) for (key in names(attr_dict)) { value \u0026lt;- attr_dict[[key]] html_tag \u0026lt;- paste(html_tag, sprintf(\u0026#39;%s=\u0026#34;%s\u0026#34;\u0026#39;, key, value), sep = \u0026#34; \u0026#34;) } html_tag \u0026lt;- paste(html_tag, \u0026#34;/\u0026gt;\u0026#34;, sep = \u0026#34;\u0026#34;) # 将Markdown语法替换为HTML语法 markdown_text \u0026lt;- sub(\u0026#34;!\\\\[(.*?)\\\\]\\\\((.*?)\\\\){(.*?)}\u0026#34;, html_tag, markdown_text, fixed = TRUE) } return(markdown_text) } markdown_text \u0026lt;- \u0026#34;![A](B.png){width=60%}\u0026#34; html_text \u0026lt;- convert_markdown_to_html(markdown_text) print(html_text) 唉，实际上这个代码没有用，我也不知道bug怎么搞，R的正则表达式一直感觉没有python好用。\n还是用写好的python脚本吧。\n修改新的md文件 我们还需要找到最新render出来的md文件按上述规则进行修改（否则一口气改全部的话，害怕会越来越慢，甚至损坏以前的md文件）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import os import datetime # 定义要查找的目录 directory = \u0026#39;./content/post/\u0026#39; # 存储所有的md文件 md_files = [] # 递归查找目录下的所有文件 for root, dirs, files in os.walk(directory): for file in files: if file.endswith(\u0026#39;.md\u0026#39;): file_path = os.path.join(root, file) md_files.append((file_path, os.path.getmtime(file_path))) # 找到最新修改的文件 latest_file = max(md_files, key=lambda x: x[1])[0] print(\u0026#34;最新保存的.md文件是：\u0026#34;, latest_file) 再问问，可以找到目录下所有新保存的.md文件吗，就是修改时间与上次不一致的？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 import os import datetime # 定义要查找的目录 directory = \u0026#39;./content/\u0026#39; # 存储所有新保存的md文件 new_md_files = [] # 读取上一次检查的时间戳 if os.path.isfile(\u0026#39;last_check_time.txt\u0026#39;): with open(\u0026#39;last_check_time.txt\u0026#39;, \u0026#39;r\u0026#39;) as f: last_check_time = datetime.datetime.strptime(f.read(), \u0026#39;%Y-%m-%d %H:%M:%S.%f\u0026#39;) else: last_check_time = datetime.datetime.now() # 递归查找目录下的所有文件 for root, dirs, files in os.walk(directory): for file in files: if file.endswith(\u0026#39;.md\u0026#39;): file_path = os.path.join(root, file) mod_time = datetime.datetime.fromtimestamp(os.path.getmtime(file_path)) if mod_time \u0026gt; last_check_time: new_md_files.append(file_path) # 更新上一次检查的时间戳 last_check_time = datetime.datetime.now() # 将上一次检查的时间戳保存到文件中 with open(\u0026#39;last_check_time.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: f.write(last_check_time.strftime(\u0026#39;%Y-%m-%d %H:%M:%S.%f\u0026#39;)) # 打印所有新保存的md文件 for file_path in new_md_files: print(\u0026#34;新保存的.md文件：\u0026#34;, file_path) #更新所有新保存的md文件 for file_path in new_md_files: convert_markdown_file_to_html(latest_file) 这个思路真不错，哈哈\n解决方法 调教了一下ChatGPT后，就得到了整个更新问题的方法了： 首先整理一个refresh_md_to_fit_stack.py放在网站根目录下， 然后在R文件夹的（如果你是用Rblogdown生成的网站，那就会有这个文件夹）的build2.R中加入一行：\nsystem(\u0026quot;python refresh_md_to_fit_stack.py\u0026quot;)\n即可。 因为Rblogdown会在每次实时渲染我们的网站后运行build2.R文件，相当于运行了refresh_md_to_fit_stack.py文件，而refresh_md_to_fit_stack.py文件将搜索所有更新的md文件并修改以上两个问题，这样hugo建立的网站就能够契合stack-theme。\n看看结果： 如果调试成功的话，下面显示的即是正常的latex公式:\n$y=\\frac{1}{2} $\n如果不是使用的Rblogdown生成的网站，这种思路的方法也可以帮助改变stack-theme。\n此外，如果是Rblogdown生成的其他主题的网站有类似问题，也可以这样修改。\n最后，ChatGPT真不错！再来一个攻略\n","date":"2023-03-23T00:00:00Z","image":"/p/chatgpt-stack/ChatGPT_huce8d906dd473ab038e4f784f810328ac_7886_120x120_fill_q75_box_smart1.jpg","permalink":"/p/chatgpt-stack/","title":"ChatGPT帮我调整stack主题"},{"content":"Introduction Zhou, J. \u0026amp; Ning, D. Stochastic Community Assembly: Does It Matter in Microbial Ecology? Microbiol Mol Biol Rev 81, e00002-17 (2017). This review is very comprehensive (1)！\n周集中老师实验室的长期研究兴趣集中在从基因组到生态系统的不同组织层面的环境微生物学，其中一项就是宏基因组学和微生物生态学：利用高通量基因组测序和相关基因组学技术检查不同栖息地的微生物群落多样性、微生物生物地理学和形成微生物多样性模式、分布和动态的机制；\nUnderstanding the mechanisms controlling community diversity, functions, succession, and biogeography is a central, but poorly understood, topic in ecology, particularly in microbial ecology. Traditional niche-based theory hypothesizes that deterministic factors such as species traits, inter-species interactions (e.g., competition, predation, mutualisms, and trade-offs), and environmental conditions (e.g., pH, temperature, salt, and moisture) govern community structure, which are often referred to as deterministic processes.\nIn contrast, neutral theory assumes that community structures are independent of species traits and governed by stochastic processes of birth, death, colonization, extinction, and speciation.\nAlthough, recently, it has been generally accepted that both deterministic and stochastic processes occur simultaneously in the assembly of local communities, a central debate is on their relative importance in controlling community structure, succession, and biogeography.\nMethods 目前在文章中普遍出现的计算群落构建的方法主要有三套：\n1.Stegen （βNTI \u0026amp; RCbray-based） 原始的文章 (2), (3)\n在确定性与随机性二分法的背景下塑造微生物群落多样性的生态过程。该方案显示了在文中讨论的假设下，基于系统发育和分类多样性划分各种生态过程的不同步骤。 NTI（最近分类单元指数）基于系统发育多样性指数 MNTD（平均最近分类单元距离）的空模型检验，RCBray（修正的 Raup-Crick 指数）基于 Bray-Curtis 的空模型检验分类多样性指数。这两个框分别表示确定性选择和未支配部分的主要组成部分。除了影响较小的选择外，未支配部分的弱选择也可能是由于抵消了有影响的选择因素和/或不同分类群的对比选择。该图主要是根据 Stegen 等人先前报告的数据制作的。\nbeta-NTI（nearest taxon index）： 使用 NTI/NRI 指示单个群落内共存的分类单元相比偶然预期的关系更为紧密还是分散，使用 βNTI/βNRI 指示两两群落间的变化受确定性或随机性因素影响的大小。 MNTD 即mean-nearest-taxon-distance (最近种间平均进化距离) ， 关于 NTI/NRI、βNTI/βNRI 的结果解释时其显著性的判断依据是其临界值是否大于|2|，实际上这是依据标准正态分布的 95%置信区间得到的，一般认为 NRI 或者 NTI 大于 1.96 或者小于-1.96 的结果，在 95%的水平是显著的。\nRCbray: 相异指数的一种。\ncode https://blog.csdn.net/weixin_43367441/article/details/118515090\n非常重要的一点：这类方法是基于系统发育树推断的，所以一定要有跟tax表对应的系统发育树。 但事实上，除非用的是16S/ITS测序，否则我们很难给自己的数据建一个树。 所以，替代方法是利用阶层分类关系（界门纲目科属种）来做一个拟系统发育树（枝长都为1） 参见自己写的df2tree函数\n1 2 3 4 5 data(otutab) df2tree(taxonomy)-\u0026gt;phylo #计算 nti_rc(otutab,phylo,metadata[,\u0026#34;Group\u0026#34;,drop=F])-\u0026gt;nti_res ## [1] \u0026quot;Result saved as nti_rc_res.rda\u0026quot; 1 2 3 4 5 #可视化 nti_res$type=factor(nti_res$type,levels = c(\u0026#34;Homo_S\u0026#34;,\u0026#34;Heter_S\u0026#34;,\u0026#34;Homo_D\u0026#34;,\u0026#34;D_limit\u0026#34;,\u0026#34;Undominated\u0026#34;)) table(nti_res$type,nti_res$variable)%\u0026gt;%reshape2::melt()-\u0026gt;com_p colnames(com_p)=c(\u0026#34;type\u0026#34;,\u0026#34;variable\u0026#34;,\u0026#34;n\u0026#34;) ggplot(com_p,aes(x=variable,y=n))+geom_bar(stat = \u0026#34;identity\u0026#34;,aes(fill=type),position = \u0026#34;fill\u0026#34;) iCAMP 现在大家经常用的iCAMP包就是基于这个理论框架进行分析的 (4)。\n2.ST，NST，MST （stochasticity ratio） PNAS：NST方法定量生态过程中的随机性\n周老师的文章，开发出新的方法对生态过程中的随机性进行了定量。提出了一个新的指数，normalized stochasticity ratio (NST)，作为确定性主导（deterministic, \u0026lt;50%）和随机性主导（stochastic, \u0026gt;50%）的边界点 (5)。\ncode 已经有相应的包了,NST\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #install.packages(\u0026#34;NST\u0026#34;) library(NST) data(tda) comm=tda$comm bray=beta.g(comm,dist.method=\u0026#34;bray\u0026#34;) bray.3col=dist.3col(bray) group=tda$group tnst=tNST(comm=comm, group=group, rand=20, output.rand=TRUE, nworker=1) #检验各组ST、NST的分布情况及各组ST、NST差异的显著性。 nst.bt=nst.boot(nst.result=tnst, group=NULL, rand=99, trace=TRUE, two.tail=FALSE, out.detail=FALSE, between.group=FALSE, nworker=1) #ST和NST组间进行Permutational multivariate ANOVA nst.pova=nst.panova(nst.result=tnst, rand=99) #可视化 pcutils::group_box(tnst$index.pair.grp,col = 8,group = tnst$index.pair.grp$group) example 地下水微生物群落演替过程中估计的 NST 动态变化对乳化植物油注入的响应。 NST 是基于 (A) Jaccard 和 (B) Ru ziˇ cka 指标使用空模型算法 PF 计算的。在零模型 PF 中，类群发生的概率与观察到的发生频率成正比，并且每个样本中的类群丰富度是固定的（19）。当使用基于丰度的指标 Ru ziˇ cka 时，每个样本中的空分类群丰度被计算为观察到的个体数量的随机抽取，其概率与样本中空分类群的区域相对丰度成比例（26）。 W8 是植物油对其没有影响或影响最小的对照井。\n3.Solan NCM 只有当物种死亡或离开这个系统时，群落结构才会发生改变。此时，离开个体的生态位就会空余出来，其它个体会通过来自群落外的迁移或群落内部的繁殖来填补空出的生态位。因此可以把群落的动态描述为死亡——繁殖/扩散——死亡这样的循环 (6)。\n计算公式：\n-$Pr(\\frac{N_i+1}{N_i})=(\\frac{N_T-N_i}{N_T})[mp_i+(1+\\alpha_i)(1-m)(\\frac{N_i}{N_T-1})$\n-$Pr(\\frac{N_i}{N_i})=\\frac{N_i}{N_T}[mp_i+{(1+\\alpha_i)}(1-m)(\\frac{N_i-1}{N_T-1})]+(\\frac{N_T-N_i}{N_T})[m(1-p_i)+{red}{(1-\\alpha_i)}(1-m)(\\frac{N_T-N_i-1}{N_T-1})]$\n-$Pr(\\frac{N_i-1}{N_i})=\\frac{N_i}{N_T}[m(1-p_i)+(1-\\alpha_i)(1-m)(\\frac{N_T-N_i}{N_T-1})]$\n物种 i 占居的频率（occurrence frequency: row sums of binary OTU table/number of sites）为其概率密度函数的积分。 此时该分布是一个beta分布，我们就可以在R语言中利用beta分布对其进行[拟合]，获得参数m的评估值。\ncode 1 2 3 4 library(devtools) install_github(\u0026#34;Russel88/MicEco\u0026#34;) library(MicEco) neutral.fit(t(otutab))#使用的是最大似然估计拟合模型，R2计算方法也不同 另一个代码来自https://mp.weixin.qq.com/s/opFXl-TvkJfmPcWKFwhCFA，比较经典，用的是非线性模型:\nN描述了宏群落规模（metacommunity size），在本文中为每个样本中所有OTU的总丰度。 m量化了群落层面的迁移率（migration rate），该值对于每个群落成员都是统一的（与物种无关），m值越小说明整个群落中物种扩散越受限制，反之m值越高则表明物种受到扩散限制越低。 Nm是元群落规模（N）与迁移率（m）的乘积 (Nm = N*m)，量化了对群落之间扩散的估计，决定了发生频率和区域相对丰度之间的相关性。\n自己的绘图代码：\n1 2 3 data(otutab) ncm(otutab)-\u0026gt;ncm_res plot(ncm_res) R2代表了中性群落模型的整体拟合优度，R2越高表明越接近中性模型，即群落的构建受随机性过程的影响越大，受确定性过程的影响越小。\n值得注意，R方不是某个数值的平方，可以是负值。因为拟合程度没有下限，可以无限差，R方的范围是(−∞,1]。R方的取值，有以下的可能性：\n等于1。理想状况，该模型对所有的真值预测准确，没有偏差。泼个冷水，如果某篇文章里出现了R方=1，要么是问题过于简单没有研究价值，要么是模型过于复杂，对数据进行了过度拟合。\n小于1大于0。这是常见状况，表明该模型的拟合水平比均值模型好。\n等于0。该模型的拟合水平接近于均值模型。该模型没有价值。\n小于0。该模型的拟合水平不如均值模型。同样，该模型没有价值。\nexample **随机过程，例如散布、出生、死亡、灭绝和移民，在呼气细菌和真菌群落的组装中发挥作用。**真菌微生物群的 SNM 拟合性能（图 2）优于细菌（细菌 R2 = 0.353，真菌 R2 = 0.683）。这种差异表明随机过程对于 EBC 真菌群落的组装可能相对更重要，而对 EBC 细菌群落的组装则不太重要。这种现象可能与细菌和真菌之间的大小差异有关，较小的细菌受扩散限制的影响较小，而受确定性过程的影响更大 (7)。\nStochastic processes played a role in assembling expiratory bacterial (A) and fungal (B) communities based on Sloan neutral model fitting. The black solid line represents the best fit, and the dotted lines represent the 95% CI (confidence interval) around the model fit. The blue dots refer to taxa that occur more frequently than predicted, and the red dots refer to taxa that occur less frequently than predicted. The green dots refer to taxa that occur in a manner consistent with predicted values.\n原核生物细胞直径大概在0.5 ~ 2.0 μm； 微真核生物个体大小大概在1 ~ 200 mm； 之前的研究已经报道了较小的生物不太可能受到扩散限制的影响，因为它们与较大的生物相比具有更高的扩散能力。因此假设在细菌群落中生态位过程的相对影响可能比在微真核生物群落中更强。微真核生物个体大，可能会影响其扩散过程。\nOthers 参考自历神公众号文章：https://mp.weixin.qq.com/s/nwNuPlY7x6VScJA44c0MjQ\nCompetitive lottery 基于竞争彩票模型(competitive lottery model)的群落构建 假设一个两步模型:在第一步中，样本的总丰度(100%)根据某个未知的过程在组之间分配。 然后在第二步中，分配给每个小组的丰度会根据一个竞争彩票模式在小组成员之间进行分配。 竞争彩票模型的概念说明:\n在第一阶段，每个样本的总丰度(100%)在一组预定义的组之间进行分割。\n在第二阶段，每一组的丰度分配根据竞争彩票模型在子组之间进行分配，其中一个子组获得了大部分的丰度。\nDNCI 在PER-SIMPER方法的基础上，提出了一个新的度量指标: dispersal–niche continuum index (DNCI)，该指数可估计是扩散过程还是生态位过程主导群落的构建，并便于不同数据集之间的比较。\nPER-SIMPER利用物种在不同站点之间的矩阵，在排列过程中生成三种不同的零模型： 通过约束行(生态位构建)、约束列(扩散构建)或两者都约束。 PER-SIMPER利用SIMPER方法对原始群落矩阵组成相似度模式进行建模，并与三个零模型比较。 PER-SIMPER通过识别哪个零模型与经验分析最匹配来进行定性评估。然而，大多数群落都是由生态位和扩散过程共同构成的，这限制了构建机制定性方法的敏感性。此外简单决策过程的定性特性使不同群落之间的构建过程难以进行精确比较。\nPER-SIMPER分析返回三个E-metric分布,这与SIMPER经验值与三个PER-SIMPER零模型之间的偏差相关。本文提出的新的DNCI是由这些计算的E值推导而来的。 定量结果是基于标准效应量En(即来自”生态位”模型的E-metric分布)减去标准效应量Ed (即来自”扩散”模型的E-metric分布)。 DNCI提供了一种方法来量化和比较跨数据集构建过程的强度。DNCI值正或负表明生态位或分散过程分别是群组构建的主要过程。指数的绝对值越高，代表占主导地位的构建过程的潜力越大。\n$DNCI=SES_d-SES_n=\\frac{1}{n}\\sum_{i=1}^n\\left(\\frac{E_{d(i)}-\\overline {E_{dn}}}{\\sigma E_{dn}}\\right)-\\frac{1}{n}\\sum_{i=1}^n\\left(\\frac{E_{n(i)}-\\overline {E_{dn}}}{\\sigma E_{dn}}\\right)$\n如果DNCI与0差异不显著，则可以认为扩散过程和生态位过程对群落构建的影响是相等的。 当DNCI显著低于0时，扩散过程是群落构建的主导驱动因素; 如果DNCI显著高于0，生态位过程是群落构建的主要决定因素。 注意，表明扩散过程优势的负DNCI值并不能提供实际扩散速率的信息。\nReferences 1. J. Zhou, D. Ning, Stochastic Community Assembly: Does It Matter in Microbial Ecology? Microbiology and Molecular Biology Reviews. 81, e00002–17 (2017).\n2. J. C. Stegen, X. Lin, J. K. Fredrickson, X. Chen, D. W. Kennedy, C. J. Murray, M. L. Rockhold, A. Konopka, Quantifying community assembly processes and identifying features that impose them. The ISME Journal. 7, 2069–2079 (2013).\n3. J. C. Stegen, X. Lin, A. E. Konopka, J. K. Fredrickson, Stochastic and deterministic assembly processes in subsurface microbial communities. The ISME Journal. 6, 1653–1664 (2012).\n4. D. Ning, M. Yuan, L. Wu, Y. Zhang, X. Guo, X. Zhou, Y. Yang, A. P. Arkin, M. K. Firestone, J. Zhou, A quantitative framework reveals ecological drivers of grassland microbial community assembly in response to warming. Nature Communications. 11, 4717 (2020).\n5. D. Ning, Y. Deng, J. M. Tiedje, J. Zhou, A general framework for quantitatively assessing ecological stochasticity. Proceedings of the National Academy of Sciences. 116, 16892–16898 (2019).\n6. W. T. Sloan, M. Lunn, S. Woodcock, I. M. Head, S. Nee, T. P. Curtis, Quantifying the roles of immigration and chance in shaping prokaryote community structure. Environmental Microbiology. 8, 732–740 (2006).\n7. Y. Zhang, F. Shen, Y. Yang, M. Niu, D. Chen, L. Chen, S. Wang, Y. Zheng, Y. Sun, F. Zhou, H. Qian, Y. Wu, T. Zhu, Insights into the Profile of the Human Expiratory Microbiota and Its Associations with Indoor Microbiotas. Environmental Science \u0026amp; Technology. 56, 6282–6293 (2022).\n","date":"2023-03-17T00:00:00Z","image":"/p/community-assembly/comm_hub260f10f12bf64e0acb74c7ee8e930d5_36974_120x120_fill_q75_box_smart1.jpg","permalink":"/p/community-assembly/","title":"微生物群落构建（community assembly）"},{"content":"简介 linux, python和R语言应该是生信学习中最重要的几个部分。\nlinux是一种操作系统，由于许多生物信息学软件仅提供支持linux平台的命令行版本，而不是图形化界面，所以掌握该操作系统的基础文件管理，安装使用软件，输入输出逻辑，简单shell脚本编写等十分重要。\npython与R都是免费开源多平台的编程语言，并且都是较为容易学习上手的模仿自然语言语法的编程语言，且支持面向对象编程，两者在数据科学上都有着非常重要的应用。Python的生态系统非常丰富，拥有大量的数据科学库和框架，例如：NumPy、Pandas、Matplotlib、Seaborn、Scikit-learn、PyTorch、TensorFlow等，这些库可以帮助数据科学家快速处理和分析数据，构建模型。\nR是一种专门用于统计分析和数据可视化的语言，其生态系统也非常丰富，拥有大量的统计分析库和可视化工具，例如：ggplot2、dplyr、tidyr、shiny等。 R拥有非常强大的数据分析和可视化能力，它提供了很多专业的统计分析函数和图形，这些函数和图形可以直接用于数据分析和可视化，使分析和可视化变得更加轻松和高效。\n在此，我想先记录一下我使用的最多的R语言。\n常用功能 全面教程 小白上手首推北大李老师的课程讲义《R语言教程》，中文讲义，简单易读，甚至整本书就是用Rbookdown编写的，电子书也比较好复制代码进行学习。\n《R语言实战》,也有中文版，介绍地更加全面且有不少进阶知识，值得一看！\n然后是著名的英文书和参考手册：\n《An Introduction to R》 《R Cookbook》 更多关于R的书可以在Home | Bookdown这里找到。\n数据处理 我目前用的最多的是dplyr包进行数据处理，最开始是冲着类似linux下的|管道符去的，%\u0026gt;%符号真的挺好用的，可以让我们无需产生许多中间结果 (准确来说%\u0026gt;%来自magrittr包，并且R4.1+也支持了原生管道符|\u0026gt;，但用起来还是%\u0026gt;%顺手，还有%\u0026lt;\u0026gt;%等变体)：\n1 2 library(dplyr) head(iris)%\u0026gt;%select(Species)%\u0026gt;%unique() 随后便发现了tidyverse全家桶，其中包含ggplot2，tibble，dplyr，readr，stringr等常用的全面的数据处理包，能够很好的满足我们下有数据处理需求：\n读取数据\n清洗数据\n转换数据\n合并数据\n筛选数据\n可视化\n这里给出官方教程：《R for Data Science》，非常建议熟读并使用。\n可视化 可视化一直是R的突出优点，basic graphic和ggplot是我最常用的绘图系统（偶尔会用plotly画一些交互图形，但大多数是只需要presentation和文章里要用的静态图形），两者的绘图逻辑有所差异，推荐在学会R的基础使用和数据处理后就体验ggplot。\nggplot是由Hadley Wickham创建的，并被包含在R语言的ggplot2包中。主要思想是将数据可视化看作是图层的堆叠，其中每个图层代表了一个数据属性的可视化。ggplot提供了一系列的函数和参数，让用户能够轻松地组合这些图层，以及调整颜色、标签、轴等其他属性。\nggplot支持的图形类型包括散点图、折线图、直方图、密度图、箱线图等等，可以满足大多数数据可视化的需求。优点在于其语法简洁、易于理解和使用，并且生成的图表质量高、美观、易于理解。它也被广泛地应用于学术研究、数据分析、商业报告等领域。\n同样给出官方教程：《ggplot2: Elegant Graphics for Data Analysis》，优雅，太优雅了。这本书也是可以找到大佬们翻译的中文版的，可以当作作图工具书使用，许多无法直接Google到的细节问题可能能在书中找到。\n此外要提一下ggpubr包，其名为Publication Ready Plots，提供一些方便的做出出版级figure的函数。ggpubr: Publication Ready Plots - Articles - STHDA 这个网站提供了不少好看图的绘制流程。\n当掌握了基本的ggplot绘制逻辑后，还可以尝试各种基于同样逻辑的扩展包，如ggcor，ggtree等等。\ngg_extensions 这个网站收集了很多此类拓展包并支持制作上传自创的gg拓展（当然暂时有点难😮‍💨）\n最后，强烈推荐一个为可视化而建的网站From data to Viz | Find the graphic you need (data-to-viz.com)，就像网站名一样，丰富多彩的可视化形式帮我们找到适合自己数据的样式，并提供画某一类图的python，R甚至D3.js代码，真的非常方便地copy代码，替换我们的数据，少量的修改就能有很不错的效果😄。\nR编程 R是一个宝库，几乎总能在上面找到合适的包实现我们想要的功能，但他也是一种编程语言，熟悉其编程语法对进阶使用十分重要。\n基本的数据读取与输出，if else、switch、for循环与简单函数编写需要掌握。\n同时因为R是一个比较\u0026quot;慢\u0026quot;的语言，尽量使用向量式编程、apply替代for循环、RCpp编写函数等方法提高其效率（后面可能会专门讲讲）。\n这里推荐大佬的《Advanced R》，对R高级编程技术进行讲解。\nRmarkdown R Markdown是一种文本格式和工具，用于创建具有代码、文本、图形和输出结果的可重复性报告。它是在R语言环境中开发的，但也可以与其他编程语言（如Python）结合使用。\n使用R Markdown，您可以将代码、文本和图形组合到一个文件中，并使用R Markdown语法将它们组织成结构化的文档。然后，您可以使用R Markdown编译器将文档转换为HTML、PDF、Word或其他格式的报告。\nR Markdown具有以下优点：\n可重复性：报告中的所有代码和结果都是可重复的，这有助于确保研究结果的可靠性和透明度。\n效率：使用R Markdown，您可以在单个文件中组织和记录所有内容，从而节省时间和精力。\n灵活性：R Markdown支持多种格式和输出选项，因此您可以根据需要自定义报告的样式和布局。\nYihui Xie大佬的官方文档介绍：R Markdown: The Definitive Guide (bookdown.org)\n以及参考书：R Markdown Cookbook (bookdown.org)\nRbookdown R的bookdown扩展包(https://github.com/rstudio/bookdown) 是继knitr和rmarkdown扩展包之后， 另一个增强markdown格式的扩展， 使得Rmd格式可以支持公式、定理、图表自动编号和引用、链接， 文献引用和链接等适用于编写书籍的功能。相当方便，我也稍微尝试写了一下：MetaNet Tutorial (asa12138.github.io)。\n参考书：bookdown: Authoring Books and Technical Documents with R Markdown\nRblogdown R扩展包blogdown可以与Hugo软件配合制作简单的静态网站。 网站的所有文件都存在于一个目录中， 只要上传到任意的网站服务器就可以发布， 没有任何限制。这篇博客就是基于Rblogdown写的，还是非常友好易上手的。\n参考书：blogdown: Creating Websites with R Markdown (bookdown.org)\n3.21更新：\n大多数网站的修改要在themes中实现，比如我现在使用的主题不支持latex渲染，想要加上这个功能，我先找到了yihui大佬的主题实现这个功能的Javascript代码，即hugo-lithium/layouts/partials/footer_mathjax.html，然后把它复制到目前用的主题的footer目录下（可能没有这个目录，而是footer.html同目录下），记得在include.html或者其他layout文件中加入{{ partial \u0026quot;footer/footer_mathjax.html\u0026quot; . }}，这样就能顺利调用mathjax了。\nR Presentation R Markdown文件(.Rmd)支持生成网页格式的幻灯片(slidy_presentation)， 以及LaTeX beamer格式的PDF幻灯片(beamer_presentation)， 和Microsoft Office的PowerPoint幻灯片(powerpoint_presentation)格式。\n目前稍微尝试了一些Yihui大佬的\u0026quot;写轮眼\u0026quot;包，但没有试着做自己的slides，以后有机会一定试试。\n写R包 包是可重现 R 代码的基本单元，包括可重用的 R 函数、描述如何使用它们的文档和示例数据。一个包将代码、数据、文档和测试捆绑在一起，并且很容易与他人共享。\n积极尝试（以后讲讲）\n参考书：R Packages (2e) (r-pkgs.org)\n制作shiny应用 Shiny 是一个 R 包，可轻松地直接从 R 构建交互式 Web 应用程序。还可以在网页上托管独立应用程序或将它们嵌入 R Markdown 文档或构建仪表板，还可以使用 CSS 主题、html 小部件和 JavaScript 操作扩展您的 Shiny 应用程序。\n积极尝试（以后讲讲）\n官方教程：Shiny Learning Resources\n参考书：Mastering Shiny\n","date":"2023-03-16T00:00:00Z","image":"/p/r-learning/images/data2viz_hu2949f787b14e5432e8dbe93255a87ee8_671473_120x120_fill_box_smart1_3.png","permalink":"/p/r-learning/","title":"R语言学习"},{"content":"最近倒腾了不少新玩意，比如这个博客系统，在此写下第一篇博客。\n从刚开始接触生信到现在已经3年了，我也从本科生变成了博士生，专业从生物科学变成了生物信息学。走上科研道路，可能是种种巧合与选择的结果，但现在脑子里想的就是将二十来年的各种知识运用在研究上，做一些有意思的东西。\n希望自己有空可以多更新，帮助自己整理思路，记录一些实验和数据分析的方法技巧，调节一下心情😂。\n","date":"2023-03-14T00:00:00Z","image":"/p/%E6%98%A5%E4%B9%8B%E4%BC%8A%E5%A7%8B/spring_hu0533df8c600b6ebf5e775c57536fef00_394558_120x120_fill_q75_box_smart1.jpeg","permalink":"/p/%E6%98%A5%E4%B9%8B%E4%BC%8A%E5%A7%8B/","title":"春之伊始"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nFormula $a=sum_i^2$ $a=sum_i$\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-03-11T00:00:00Z","image":"/p/markdown-syntax-guide/pawel-czerwinski-8uZPynIu-rQ-unsplash_hud7e36f7e20e71be184458283bdae4646_55974_120x120_fill_q75_box_smart1.jpg","permalink":"/p/markdown-syntax-guide/","title":"Markdown Syntax Guide"}]